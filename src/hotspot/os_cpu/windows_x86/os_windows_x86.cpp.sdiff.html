<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src\hotspot\os_cpu\windows_x86\os_windows_x86.cpp</title>
    <link rel="stylesheet" href="..\..\..\..\style.css" />
  </head>
<body>
<center><a href="bytes_windows_x86.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="..\..\..\..\index.html" target="_top">index</a> <a href="os_windows_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src\hotspot\os_cpu\windows_x86\os_windows_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 52 #include &quot;symbolengine.hpp&quot;
 53 #include &quot;unwind_windows_x86.hpp&quot;
 54 #include &quot;utilities/events.hpp&quot;
 55 #include &quot;utilities/vmError.hpp&quot;
 56 #include &quot;windbghelp.hpp&quot;
 57 
 58 
 59 #undef REG_SP
 60 #undef REG_FP
 61 #undef REG_PC
 62 #ifdef AMD64
 63 #define REG_SP Rsp
 64 #define REG_FP Rbp
 65 #define REG_PC Rip
 66 #else
 67 #define REG_SP Esp
 68 #define REG_FP Ebp
 69 #define REG_PC Eip
 70 #endif // AMD64
 71 
<span class="line-removed"> 72 extern LONG WINAPI topLevelExceptionFilter(_EXCEPTION_POINTERS* );</span>
<span class="line-removed"> 73 </span>
 74 // Install a win32 structured exception handler around thread.
 75 void os::os_exception_wrapper(java_call_t f, JavaValue* value, const methodHandle&amp; method, JavaCallArguments* args, Thread* thread) {
<span class="line-removed"> 76   __try {</span>
<span class="line-removed"> 77 </span>
 78 #ifndef AMD64

 79     // We store the current thread in this wrapperthread location
 80     // and determine how far away this address is from the structured
 81     // execption pointer that FS:[0] points to.  This get_thread
 82     // code can then get the thread pointer via FS.
 83     //
 84     // Warning:  This routine must NEVER be inlined since we&#39;d end up with
 85     //           multiple offsets.
 86     //
 87     volatile Thread* wrapperthread = thread;
 88 
 89     if (os::win32::get_thread_ptr_offset() == 0) {
 90       int thread_ptr_offset;
 91       __asm {
 92         lea eax, dword ptr wrapperthread;
 93         sub eax, dword ptr FS:[0H];
 94         mov thread_ptr_offset, eax
 95       };
 96       os::win32::set_thread_ptr_offset(thread_ptr_offset);
 97     }
 98 #ifdef ASSERT
 99     // Verify that the offset hasn&#39;t changed since we initally captured
100     // it. This might happen if we accidentally ended up with an
101     // inlined version of this routine.
102     else {
103       int test_thread_ptr_offset;
104       __asm {
105         lea eax, dword ptr wrapperthread;
106         sub eax, dword ptr FS:[0H];
107         mov test_thread_ptr_offset, eax
108       };
109       assert(test_thread_ptr_offset == os::win32::get_thread_ptr_offset(),
110              &quot;thread pointer offset from SEH changed&quot;);
111     }
112 #endif // ASSERT
113 #endif // !AMD64
114 
115     f(value, method, args, thread);
<span class="line-modified">116   } __except(topLevelExceptionFilter((_EXCEPTION_POINTERS*)_exception_info())) {</span>

117       // Nothing to do.
118   }

119 }
120 
<span class="line-removed">121 #ifdef AMD64</span>
<span class="line-removed">122 </span>
<span class="line-removed">123 // This is the language specific handler for exceptions</span>
<span class="line-removed">124 // originating from dynamically generated code.</span>
<span class="line-removed">125 // We call the standard structured exception handler</span>
<span class="line-removed">126 // We only expect Continued Execution since we cannot unwind</span>
<span class="line-removed">127 // from generated code.</span>
<span class="line-removed">128 LONG HandleExceptionFromCodeCache(</span>
<span class="line-removed">129   IN PEXCEPTION_RECORD ExceptionRecord,</span>
<span class="line-removed">130   IN ULONG64 EstablisherFrame,</span>
<span class="line-removed">131   IN OUT PCONTEXT ContextRecord,</span>
<span class="line-removed">132   IN OUT PDISPATCHER_CONTEXT DispatcherContext) {</span>
<span class="line-removed">133   EXCEPTION_POINTERS ep;</span>
<span class="line-removed">134   LONG result;</span>
<span class="line-removed">135 </span>
<span class="line-removed">136   ep.ExceptionRecord = ExceptionRecord;</span>
<span class="line-removed">137   ep.ContextRecord = ContextRecord;</span>
<span class="line-removed">138 </span>
<span class="line-removed">139   result = topLevelExceptionFilter(&amp;ep);</span>
<span class="line-removed">140 </span>
<span class="line-removed">141   // We better only get a CONTINUE_EXECUTION from our handler</span>
<span class="line-removed">142   // since we don&#39;t have unwind information registered.</span>
<span class="line-removed">143 </span>
<span class="line-removed">144   guarantee( result == EXCEPTION_CONTINUE_EXECUTION,</span>
<span class="line-removed">145              &quot;Unexpected result from topLevelExceptionFilter&quot;);</span>
<span class="line-removed">146 </span>
<span class="line-removed">147   return(ExceptionContinueExecution);</span>
<span class="line-removed">148 }</span>
<span class="line-removed">149 </span>
<span class="line-removed">150 </span>
<span class="line-removed">151 // Structure containing the Windows Data Structures required</span>
<span class="line-removed">152 // to register our Code Cache exception handler.</span>
<span class="line-removed">153 // We put these in the CodeCache since the API requires</span>
<span class="line-removed">154 // all addresses in these structures are relative to the Code</span>
<span class="line-removed">155 // area registered with RtlAddFunctionTable.</span>
<span class="line-removed">156 typedef struct {</span>
<span class="line-removed">157   char ExceptionHandlerInstr[16];  // jmp HandleExceptionFromCodeCache</span>
<span class="line-removed">158   RUNTIME_FUNCTION rt;</span>
<span class="line-removed">159   UNWIND_INFO_EH_ONLY unw;</span>
<span class="line-removed">160 } DynamicCodeData, *pDynamicCodeData;</span>
<span class="line-removed">161 </span>
<span class="line-removed">162 #endif // AMD64</span>
<span class="line-removed">163 //</span>
<span class="line-removed">164 // Register our CodeCache area with the OS so it will dispatch exceptions</span>
<span class="line-removed">165 // to our topLevelExceptionFilter when we take an exception in our</span>
<span class="line-removed">166 // dynamically generated code.</span>
<span class="line-removed">167 //</span>
<span class="line-removed">168 // Arguments:  low and high are the address of the full reserved</span>
<span class="line-removed">169 // codeCache area</span>
<span class="line-removed">170 //</span>
<span class="line-removed">171 bool os::register_code_area(char *low, char *high) {</span>
<span class="line-removed">172 #ifdef AMD64</span>
<span class="line-removed">173 </span>
<span class="line-removed">174   ResourceMark rm;</span>
<span class="line-removed">175 </span>
<span class="line-removed">176   pDynamicCodeData pDCD;</span>
<span class="line-removed">177   PRUNTIME_FUNCTION prt;</span>
<span class="line-removed">178   PUNWIND_INFO_EH_ONLY punwind;</span>
<span class="line-removed">179 </span>
<span class="line-removed">180   BufferBlob* blob = BufferBlob::create(&quot;CodeCache Exception Handler&quot;, sizeof(DynamicCodeData));</span>
<span class="line-removed">181   CodeBuffer cb(blob);</span>
<span class="line-removed">182   MacroAssembler* masm = new MacroAssembler(&amp;cb);</span>
<span class="line-removed">183   pDCD = (pDynamicCodeData) masm-&gt;pc();</span>
<span class="line-removed">184 </span>
<span class="line-removed">185   masm-&gt;jump(ExternalAddress((address)&amp;HandleExceptionFromCodeCache));</span>
<span class="line-removed">186   masm-&gt;flush();</span>
<span class="line-removed">187 </span>
<span class="line-removed">188   // Create an Unwind Structure specifying no unwind info</span>
<span class="line-removed">189   // other than an Exception Handler</span>
<span class="line-removed">190   punwind = &amp;pDCD-&gt;unw;</span>
<span class="line-removed">191   punwind-&gt;Version = 1;</span>
<span class="line-removed">192   punwind-&gt;Flags = UNW_FLAG_EHANDLER;</span>
<span class="line-removed">193   punwind-&gt;SizeOfProlog = 0;</span>
<span class="line-removed">194   punwind-&gt;CountOfCodes = 0;</span>
<span class="line-removed">195   punwind-&gt;FrameRegister = 0;</span>
<span class="line-removed">196   punwind-&gt;FrameOffset = 0;</span>
<span class="line-removed">197   punwind-&gt;ExceptionHandler = (char *)(&amp;(pDCD-&gt;ExceptionHandlerInstr[0])) -</span>
<span class="line-removed">198                               (char*)low;</span>
<span class="line-removed">199   punwind-&gt;ExceptionData[0] = 0;</span>
<span class="line-removed">200 </span>
<span class="line-removed">201   // This structure describes the covered dynamic code area.</span>
<span class="line-removed">202   // Addresses are relative to the beginning on the code cache area</span>
<span class="line-removed">203   prt = &amp;pDCD-&gt;rt;</span>
<span class="line-removed">204   prt-&gt;BeginAddress = 0;</span>
<span class="line-removed">205   prt-&gt;EndAddress = (ULONG)(high - low);</span>
<span class="line-removed">206   prt-&gt;UnwindData = ((char *)punwind - low);</span>
<span class="line-removed">207 </span>
<span class="line-removed">208   guarantee(RtlAddFunctionTable(prt, 1, (ULONGLONG)low),</span>
<span class="line-removed">209             &quot;Failed to register Dynamic Code Exception Handler with RtlAddFunctionTable&quot;);</span>
<span class="line-removed">210 </span>
<span class="line-removed">211 #endif // AMD64</span>
<span class="line-removed">212   return true;</span>
<span class="line-removed">213 }</span>
<span class="line-removed">214 </span>
<span class="line-removed">215 // Atomics and Stub Functions</span>
<span class="line-removed">216 </span>
<span class="line-removed">217 typedef int32_t   xchg_func_t            (int32_t,  volatile int32_t*);</span>
<span class="line-removed">218 typedef int64_t   xchg_long_func_t       (int64_t,  volatile int64_t*);</span>
<span class="line-removed">219 typedef int32_t   cmpxchg_func_t         (int32_t,  volatile int32_t*, int32_t);</span>
<span class="line-removed">220 typedef int8_t    cmpxchg_byte_func_t    (int8_t,   volatile int8_t*,  int8_t);</span>
<span class="line-removed">221 typedef int64_t   cmpxchg_long_func_t    (int64_t,  volatile int64_t*, int64_t);</span>
<span class="line-removed">222 typedef int32_t   add_func_t             (int32_t,  volatile int32_t*);</span>
<span class="line-removed">223 typedef int64_t   add_long_func_t        (int64_t,  volatile int64_t*);</span>
<span class="line-removed">224 </span>
<span class="line-removed">225 #ifdef AMD64</span>
<span class="line-removed">226 </span>
<span class="line-removed">227 int32_t os::atomic_xchg_bootstrap(int32_t exchange_value, volatile int32_t* dest) {</span>
<span class="line-removed">228   // try to use the stub:</span>
<span class="line-removed">229   xchg_func_t* func = CAST_TO_FN_PTR(xchg_func_t*, StubRoutines::atomic_xchg_entry());</span>
<span class="line-removed">230 </span>
<span class="line-removed">231   if (func != NULL) {</span>
<span class="line-removed">232     os::atomic_xchg_func = func;</span>
<span class="line-removed">233     return (*func)(exchange_value, dest);</span>
<span class="line-removed">234   }</span>
<span class="line-removed">235   assert(Threads::number_of_threads() == 0, &quot;for bootstrap only&quot;);</span>
<span class="line-removed">236 </span>
<span class="line-removed">237   int32_t old_value = *dest;</span>
<span class="line-removed">238   *dest = exchange_value;</span>
<span class="line-removed">239   return old_value;</span>
<span class="line-removed">240 }</span>
<span class="line-removed">241 </span>
<span class="line-removed">242 int64_t os::atomic_xchg_long_bootstrap(int64_t exchange_value, volatile int64_t* dest) {</span>
<span class="line-removed">243   // try to use the stub:</span>
<span class="line-removed">244   xchg_long_func_t* func = CAST_TO_FN_PTR(xchg_long_func_t*, StubRoutines::atomic_xchg_long_entry());</span>
<span class="line-removed">245 </span>
<span class="line-removed">246   if (func != NULL) {</span>
<span class="line-removed">247     os::atomic_xchg_long_func = func;</span>
<span class="line-removed">248     return (*func)(exchange_value, dest);</span>
<span class="line-removed">249   }</span>
<span class="line-removed">250   assert(Threads::number_of_threads() == 0, &quot;for bootstrap only&quot;);</span>
<span class="line-removed">251 </span>
<span class="line-removed">252   int64_t old_value = *dest;</span>
<span class="line-removed">253   *dest = exchange_value;</span>
<span class="line-removed">254   return old_value;</span>
<span class="line-removed">255 }</span>
<span class="line-removed">256 </span>
<span class="line-removed">257 </span>
<span class="line-removed">258 int32_t os::atomic_cmpxchg_bootstrap(int32_t exchange_value, volatile int32_t* dest, int32_t compare_value) {</span>
<span class="line-removed">259   // try to use the stub:</span>
<span class="line-removed">260   cmpxchg_func_t* func = CAST_TO_FN_PTR(cmpxchg_func_t*, StubRoutines::atomic_cmpxchg_entry());</span>
<span class="line-removed">261 </span>
<span class="line-removed">262   if (func != NULL) {</span>
<span class="line-removed">263     os::atomic_cmpxchg_func = func;</span>
<span class="line-removed">264     return (*func)(exchange_value, dest, compare_value);</span>
<span class="line-removed">265   }</span>
<span class="line-removed">266   assert(Threads::number_of_threads() == 0, &quot;for bootstrap only&quot;);</span>
<span class="line-removed">267 </span>
<span class="line-removed">268   int32_t old_value = *dest;</span>
<span class="line-removed">269   if (old_value == compare_value)</span>
<span class="line-removed">270     *dest = exchange_value;</span>
<span class="line-removed">271   return old_value;</span>
<span class="line-removed">272 }</span>
<span class="line-removed">273 </span>
<span class="line-removed">274 int8_t os::atomic_cmpxchg_byte_bootstrap(int8_t exchange_value, volatile int8_t* dest, int8_t compare_value) {</span>
<span class="line-removed">275   // try to use the stub:</span>
<span class="line-removed">276   cmpxchg_byte_func_t* func = CAST_TO_FN_PTR(cmpxchg_byte_func_t*, StubRoutines::atomic_cmpxchg_byte_entry());</span>
<span class="line-removed">277 </span>
<span class="line-removed">278   if (func != NULL) {</span>
<span class="line-removed">279     os::atomic_cmpxchg_byte_func = func;</span>
<span class="line-removed">280     return (*func)(exchange_value, dest, compare_value);</span>
<span class="line-removed">281   }</span>
<span class="line-removed">282   assert(Threads::number_of_threads() == 0, &quot;for bootstrap only&quot;);</span>
<span class="line-removed">283 </span>
<span class="line-removed">284   int8_t old_value = *dest;</span>
<span class="line-removed">285   if (old_value == compare_value)</span>
<span class="line-removed">286     *dest = exchange_value;</span>
<span class="line-removed">287   return old_value;</span>
<span class="line-removed">288 }</span>
<span class="line-removed">289 </span>
<span class="line-removed">290 #endif // AMD64</span>
<span class="line-removed">291 </span>
<span class="line-removed">292 int64_t os::atomic_cmpxchg_long_bootstrap(int64_t exchange_value, volatile int64_t* dest, int64_t compare_value) {</span>
<span class="line-removed">293   // try to use the stub:</span>
<span class="line-removed">294   cmpxchg_long_func_t* func = CAST_TO_FN_PTR(cmpxchg_long_func_t*, StubRoutines::atomic_cmpxchg_long_entry());</span>
<span class="line-removed">295 </span>
<span class="line-removed">296   if (func != NULL) {</span>
<span class="line-removed">297     os::atomic_cmpxchg_long_func = func;</span>
<span class="line-removed">298     return (*func)(exchange_value, dest, compare_value);</span>
<span class="line-removed">299   }</span>
<span class="line-removed">300   assert(Threads::number_of_threads() == 0, &quot;for bootstrap only&quot;);</span>
<span class="line-removed">301 </span>
<span class="line-removed">302   int64_t old_value = *dest;</span>
<span class="line-removed">303   if (old_value == compare_value)</span>
<span class="line-removed">304     *dest = exchange_value;</span>
<span class="line-removed">305   return old_value;</span>
<span class="line-removed">306 }</span>
<span class="line-removed">307 </span>
<span class="line-removed">308 #ifdef AMD64</span>
<span class="line-removed">309 </span>
<span class="line-removed">310 int32_t os::atomic_add_bootstrap(int32_t add_value, volatile int32_t* dest) {</span>
<span class="line-removed">311   // try to use the stub:</span>
<span class="line-removed">312   add_func_t* func = CAST_TO_FN_PTR(add_func_t*, StubRoutines::atomic_add_entry());</span>
<span class="line-removed">313 </span>
<span class="line-removed">314   if (func != NULL) {</span>
<span class="line-removed">315     os::atomic_add_func = func;</span>
<span class="line-removed">316     return (*func)(add_value, dest);</span>
<span class="line-removed">317   }</span>
<span class="line-removed">318   assert(Threads::number_of_threads() == 0, &quot;for bootstrap only&quot;);</span>
<span class="line-removed">319 </span>
<span class="line-removed">320   return (*dest) += add_value;</span>
<span class="line-removed">321 }</span>
<span class="line-removed">322 </span>
<span class="line-removed">323 int64_t os::atomic_add_long_bootstrap(int64_t add_value, volatile int64_t* dest) {</span>
<span class="line-removed">324   // try to use the stub:</span>
<span class="line-removed">325   add_long_func_t* func = CAST_TO_FN_PTR(add_long_func_t*, StubRoutines::atomic_add_long_entry());</span>
<span class="line-removed">326 </span>
<span class="line-removed">327   if (func != NULL) {</span>
<span class="line-removed">328     os::atomic_add_long_func = func;</span>
<span class="line-removed">329     return (*func)(add_value, dest);</span>
<span class="line-removed">330   }</span>
<span class="line-removed">331   assert(Threads::number_of_threads() == 0, &quot;for bootstrap only&quot;);</span>
<span class="line-removed">332 </span>
<span class="line-removed">333   return (*dest) += add_value;</span>
<span class="line-removed">334 }</span>
<span class="line-removed">335 </span>
<span class="line-removed">336 xchg_func_t*         os::atomic_xchg_func         = os::atomic_xchg_bootstrap;</span>
<span class="line-removed">337 xchg_long_func_t*    os::atomic_xchg_long_func    = os::atomic_xchg_long_bootstrap;</span>
<span class="line-removed">338 cmpxchg_func_t*      os::atomic_cmpxchg_func      = os::atomic_cmpxchg_bootstrap;</span>
<span class="line-removed">339 cmpxchg_byte_func_t* os::atomic_cmpxchg_byte_func = os::atomic_cmpxchg_byte_bootstrap;</span>
<span class="line-removed">340 add_func_t*          os::atomic_add_func          = os::atomic_add_bootstrap;</span>
<span class="line-removed">341 add_long_func_t*     os::atomic_add_long_func     = os::atomic_add_long_bootstrap;</span>
<span class="line-removed">342 </span>
<span class="line-removed">343 #endif // AMD64</span>
<span class="line-removed">344 </span>
<span class="line-removed">345 cmpxchg_long_func_t* os::atomic_cmpxchg_long_func = os::atomic_cmpxchg_long_bootstrap;</span>
<span class="line-removed">346 </span>
347 #ifdef AMD64
348 /*
349  * Windows/x64 does not use stack frames the way expected by Java:
350  * [1] in most cases, there is no frame pointer. All locals are addressed via RSP
351  * [2] in rare cases, when alloca() is used, a frame pointer is used, but this may
352  *     not be RBP.
353  * See http://msdn.microsoft.com/en-us/library/ew5tede7.aspx
354  *
355  * So it&#39;s not possible to print the native stack using the
356  *     while (...) {...  fr = os::get_sender_for_C_frame(&amp;fr); }
357  * loop in vmError.cpp. We need to roll our own loop.
358  */
359 bool os::platform_print_native_stack(outputStream* st, const void* context,
360                                      char *buf, int buf_size)
361 {
362   CONTEXT ctx;
363   if (context != NULL) {
364     memcpy(&amp;ctx, context, sizeof(ctx));
365   } else {
366     RtlCaptureContext(&amp;ctx);
</pre>
<hr />
<pre>
471 // Returns an estimate of the current stack pointer. Result must be guaranteed
472 // to point into the calling threads stack, and be no lower than the current
473 // stack pointer.
474 address os::current_stack_pointer() {
475   int dummy;
476   address sp = (address)&amp;dummy;
477   return sp;
478 }
479 PRAGMA_DIAG_POP
480 #else
481 // Returns the current stack pointer. Accurate value needed for
482 // os::verify_stack_alignment().
483 address os::current_stack_pointer() {
484   typedef address get_sp_func();
485   get_sp_func* func = CAST_TO_FN_PTR(get_sp_func*,
486                                      StubRoutines::x86::get_previous_sp_entry());
487   return (*func)();
488 }
489 #endif
490 



































491 
492 #ifndef AMD64
493 intptr_t* _get_previous_fp() {
494   intptr_t **frameptr;
495   __asm {
496     mov frameptr, ebp
497   };
498   // ebp (frameptr) is for this frame (_get_previous_fp). We want the ebp for the
499   // caller of os::current_frame*(), so go up two frames. However, for
500   // optimized builds, _get_previous_fp() will be inlined, so only go
501   // up 1 frame in that case.
502 #ifdef _NMT_NOINLINE_
503   return **(intptr_t***)frameptr;
504 #else
505   return *frameptr;
506 #endif
507 }
508 #endif // !AMD64
509 
510 frame os::current_frame() {
</pre>
</td>
<td>
<hr />
<pre>
 52 #include &quot;symbolengine.hpp&quot;
 53 #include &quot;unwind_windows_x86.hpp&quot;
 54 #include &quot;utilities/events.hpp&quot;
 55 #include &quot;utilities/vmError.hpp&quot;
 56 #include &quot;windbghelp.hpp&quot;
 57 
 58 
 59 #undef REG_SP
 60 #undef REG_FP
 61 #undef REG_PC
 62 #ifdef AMD64
 63 #define REG_SP Rsp
 64 #define REG_FP Rbp
 65 #define REG_PC Rip
 66 #else
 67 #define REG_SP Esp
 68 #define REG_FP Ebp
 69 #define REG_PC Eip
 70 #endif // AMD64
 71 


 72 // Install a win32 structured exception handler around thread.
 73 void os::os_exception_wrapper(java_call_t f, JavaValue* value, const methodHandle&amp; method, JavaCallArguments* args, Thread* thread) {


 74 #ifndef AMD64
<span class="line-added"> 75   __try {</span>
 76     // We store the current thread in this wrapperthread location
 77     // and determine how far away this address is from the structured
 78     // execption pointer that FS:[0] points to.  This get_thread
 79     // code can then get the thread pointer via FS.
 80     //
 81     // Warning:  This routine must NEVER be inlined since we&#39;d end up with
 82     //           multiple offsets.
 83     //
 84     volatile Thread* wrapperthread = thread;
 85 
 86     if (os::win32::get_thread_ptr_offset() == 0) {
 87       int thread_ptr_offset;
 88       __asm {
 89         lea eax, dword ptr wrapperthread;
 90         sub eax, dword ptr FS:[0H];
 91         mov thread_ptr_offset, eax
 92       };
 93       os::win32::set_thread_ptr_offset(thread_ptr_offset);
 94     }
 95 #ifdef ASSERT
 96     // Verify that the offset hasn&#39;t changed since we initally captured
 97     // it. This might happen if we accidentally ended up with an
 98     // inlined version of this routine.
 99     else {
100       int test_thread_ptr_offset;
101       __asm {
102         lea eax, dword ptr wrapperthread;
103         sub eax, dword ptr FS:[0H];
104         mov test_thread_ptr_offset, eax
105       };
106       assert(test_thread_ptr_offset == os::win32::get_thread_ptr_offset(),
107              &quot;thread pointer offset from SEH changed&quot;);
108     }
109 #endif // ASSERT
110 #endif // !AMD64
111 
112     f(value, method, args, thread);
<span class="line-modified">113 #ifndef AMD64</span>
<span class="line-added">114   } __except(EXCEPTION_CONTINUE_EXECUTION) {</span>
115       // Nothing to do.
116   }
<span class="line-added">117 #endif</span>
118 }
119 


































































































































































































































120 #ifdef AMD64
121 /*
122  * Windows/x64 does not use stack frames the way expected by Java:
123  * [1] in most cases, there is no frame pointer. All locals are addressed via RSP
124  * [2] in rare cases, when alloca() is used, a frame pointer is used, but this may
125  *     not be RBP.
126  * See http://msdn.microsoft.com/en-us/library/ew5tede7.aspx
127  *
128  * So it&#39;s not possible to print the native stack using the
129  *     while (...) {...  fr = os::get_sender_for_C_frame(&amp;fr); }
130  * loop in vmError.cpp. We need to roll our own loop.
131  */
132 bool os::platform_print_native_stack(outputStream* st, const void* context,
133                                      char *buf, int buf_size)
134 {
135   CONTEXT ctx;
136   if (context != NULL) {
137     memcpy(&amp;ctx, context, sizeof(ctx));
138   } else {
139     RtlCaptureContext(&amp;ctx);
</pre>
<hr />
<pre>
244 // Returns an estimate of the current stack pointer. Result must be guaranteed
245 // to point into the calling threads stack, and be no lower than the current
246 // stack pointer.
247 address os::current_stack_pointer() {
248   int dummy;
249   address sp = (address)&amp;dummy;
250   return sp;
251 }
252 PRAGMA_DIAG_POP
253 #else
254 // Returns the current stack pointer. Accurate value needed for
255 // os::verify_stack_alignment().
256 address os::current_stack_pointer() {
257   typedef address get_sp_func();
258   get_sp_func* func = CAST_TO_FN_PTR(get_sp_func*,
259                                      StubRoutines::x86::get_previous_sp_entry());
260   return (*func)();
261 }
262 #endif
263 
<span class="line-added">264 bool os::win32::get_frame_at_stack_banging_point(JavaThread* thread,</span>
<span class="line-added">265         struct _EXCEPTION_POINTERS* exceptionInfo, address pc, frame* fr) {</span>
<span class="line-added">266   PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;</span>
<span class="line-added">267   address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];</span>
<span class="line-added">268   if (Interpreter::contains(pc)) {</span>
<span class="line-added">269     *fr = os::fetch_frame_from_context((void*)exceptionInfo-&gt;ContextRecord);</span>
<span class="line-added">270     if (!fr-&gt;is_first_java_frame()) {</span>
<span class="line-added">271       // get_frame_at_stack_banging_point() is only called when we</span>
<span class="line-added">272       // have well defined stacks so java_sender() calls do not need</span>
<span class="line-added">273       // to assert safe_for_sender() first.</span>
<span class="line-added">274       *fr = fr-&gt;java_sender();</span>
<span class="line-added">275     }</span>
<span class="line-added">276   } else {</span>
<span class="line-added">277     // more complex code with compiled code</span>
<span class="line-added">278     assert(!Interpreter::contains(pc), &quot;Interpreted methods should have been handled above&quot;);</span>
<span class="line-added">279     CodeBlob* cb = CodeCache::find_blob(pc);</span>
<span class="line-added">280     if (cb == NULL || !cb-&gt;is_nmethod() || cb-&gt;is_frame_complete_at(pc)) {</span>
<span class="line-added">281       // Not sure where the pc points to, fallback to default</span>
<span class="line-added">282       // stack overflow handling</span>
<span class="line-added">283       return false;</span>
<span class="line-added">284     } else {</span>
<span class="line-added">285       // in compiled code, the stack banging is performed just after the return pc</span>
<span class="line-added">286       // has been pushed on the stack</span>
<span class="line-added">287       intptr_t* fp = (intptr_t*)exceptionInfo-&gt;ContextRecord-&gt;REG_FP;</span>
<span class="line-added">288       intptr_t* sp = (intptr_t*)exceptionInfo-&gt;ContextRecord-&gt;REG_SP;</span>
<span class="line-added">289       *fr = frame(sp + 1, fp, (address)*sp);</span>
<span class="line-added">290       if (!fr-&gt;is_java_frame()) {</span>
<span class="line-added">291         // See java_sender() comment above.</span>
<span class="line-added">292         *fr = fr-&gt;java_sender();</span>
<span class="line-added">293       }</span>
<span class="line-added">294     }</span>
<span class="line-added">295   }</span>
<span class="line-added">296   assert(fr-&gt;is_java_frame(), &quot;Safety check&quot;);</span>
<span class="line-added">297   return true;</span>
<span class="line-added">298 }</span>
299 
300 #ifndef AMD64
301 intptr_t* _get_previous_fp() {
302   intptr_t **frameptr;
303   __asm {
304     mov frameptr, ebp
305   };
306   // ebp (frameptr) is for this frame (_get_previous_fp). We want the ebp for the
307   // caller of os::current_frame*(), so go up two frames. However, for
308   // optimized builds, _get_previous_fp() will be inlined, so only go
309   // up 1 frame in that case.
310 #ifdef _NMT_NOINLINE_
311   return **(intptr_t***)frameptr;
312 #else
313   return *frameptr;
314 #endif
315 }
316 #endif // !AMD64
317 
318 frame os::current_frame() {
</pre>
</td>
</tr>
</table>
<center><a href="bytes_windows_x86.inline.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="..\..\..\..\index.html" target="_top">index</a> <a href="os_windows_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>