<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src\hotspot\cpu\aarch64\aarch64.ad</title>
    <link rel="stylesheet" href="..\..\..\..\style.css" />
    <script type="text/javascript" src="..\..\..\..\navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
<a name="1" id="anc1"></a><span class="line-added">  535 #ifdef _WIN64</span>
<span class="line-added">  536     R18,                        // tls on Windows</span>
<span class="line-added">  537 #endif</span>
  538     R28,                        // thread
  539     R30,                        // lr
  540     R31                         // sp
  541 );
  542 
  543 // Class for non-allocatable 64 bit registers
  544 reg_class non_allocatable_reg(
<a name="2" id="anc2"></a><span class="line-added">  545 #ifdef _WIN64</span>
<span class="line-added">  546     R18, R18_H,                 // tls on Windows</span>
<span class="line-added">  547 #endif</span>
  548     R28, R28_H,                 // thread
  549     R30, R30_H,                 // lr
  550     R31, R31_H                  // sp
  551 );
  552 
  553 // Class for all non-special integer registers
  554 reg_class no_special_reg32 %{
  555   return _NO_SPECIAL_REG32_mask;
  556 %}
  557 
  558 // Class for all non-special long integer registers
  559 reg_class no_special_reg %{
  560   return _NO_SPECIAL_REG_mask;
  561 %}
  562 
  563 // Class for 64 bit register r0
  564 reg_class r0_reg(
  565     R0, R0_H
  566 );
  567 
  568 // Class for 64 bit register r1
  569 reg_class r1_reg(
  570     R1, R1_H
  571 );
  572 
  573 // Class for 64 bit register r2
  574 reg_class r2_reg(
  575     R2, R2_H
  576 );
  577 
  578 // Class for 64 bit register r3
  579 reg_class r3_reg(
  580     R3, R3_H
  581 );
  582 
  583 // Class for 64 bit register r4
  584 reg_class r4_reg(
  585     R4, R4_H
  586 );
  587 
  588 // Class for 64 bit register r5
  589 reg_class r5_reg(
  590     R5, R5_H
  591 );
  592 
  593 // Class for 64 bit register r10
  594 reg_class r10_reg(
  595     R10, R10_H
  596 );
  597 
  598 // Class for 64 bit register r11
  599 reg_class r11_reg(
  600     R11, R11_H
  601 );
  602 
  603 // Class for method register
  604 reg_class method_reg(
  605     R12, R12_H
  606 );
  607 
  608 // Class for heapbase register
  609 reg_class heapbase_reg(
  610     R27, R27_H
  611 );
  612 
  613 // Class for thread register
  614 reg_class thread_reg(
  615     R28, R28_H
  616 );
  617 
  618 // Class for frame pointer register
  619 reg_class fp_reg(
  620     R29, R29_H
  621 );
  622 
  623 // Class for link register
  624 reg_class lr_reg(
  625     R30, R30_H
  626 );
  627 
  628 // Class for long sp register
  629 reg_class sp_reg(
  630   R31, R31_H
  631 );
  632 
  633 // Class for all pointer registers
  634 reg_class ptr_reg %{
  635   return _PTR_REG_mask;
  636 %}
  637 
  638 // Class for all non_special pointer registers
  639 reg_class no_special_ptr_reg %{
  640   return _NO_SPECIAL_PTR_REG_mask;
  641 %}
  642 
  643 // Class for all float registers
  644 reg_class float_reg(
  645     V0,
  646     V1,
  647     V2,
  648     V3,
  649     V4,
  650     V5,
  651     V6,
  652     V7,
  653     V8,
  654     V9,
  655     V10,
  656     V11,
  657     V12,
  658     V13,
  659     V14,
  660     V15,
  661     V16,
  662     V17,
  663     V18,
  664     V19,
  665     V20,
  666     V21,
  667     V22,
  668     V23,
  669     V24,
  670     V25,
  671     V26,
  672     V27,
  673     V28,
  674     V29,
  675     V30,
  676     V31
  677 );
  678 
  679 // Double precision float registers have virtual `high halves&#39; that
  680 // are needed by the allocator.
  681 // Class for all double registers
  682 reg_class double_reg(
  683     V0, V0_H,
  684     V1, V1_H,
  685     V2, V2_H,
  686     V3, V3_H,
  687     V4, V4_H,
  688     V5, V5_H,
  689     V6, V6_H,
  690     V7, V7_H,
  691     V8, V8_H,
  692     V9, V9_H,
  693     V10, V10_H,
  694     V11, V11_H,
  695     V12, V12_H,
  696     V13, V13_H,
  697     V14, V14_H,
  698     V15, V15_H,
  699     V16, V16_H,
  700     V17, V17_H,
  701     V18, V18_H,
  702     V19, V19_H,
  703     V20, V20_H,
  704     V21, V21_H,
  705     V22, V22_H,
  706     V23, V23_H,
  707     V24, V24_H,
  708     V25, V25_H,
  709     V26, V26_H,
  710     V27, V27_H,
  711     V28, V28_H,
  712     V29, V29_H,
  713     V30, V30_H,
  714     V31, V31_H
  715 );
  716 
  717 // Class for all 64bit vector registers
  718 reg_class vectord_reg(
  719     V0, V0_H,
  720     V1, V1_H,
  721     V2, V2_H,
  722     V3, V3_H,
  723     V4, V4_H,
  724     V5, V5_H,
  725     V6, V6_H,
  726     V7, V7_H,
  727     V8, V8_H,
  728     V9, V9_H,
  729     V10, V10_H,
  730     V11, V11_H,
  731     V12, V12_H,
  732     V13, V13_H,
  733     V14, V14_H,
  734     V15, V15_H,
  735     V16, V16_H,
  736     V17, V17_H,
  737     V18, V18_H,
  738     V19, V19_H,
  739     V20, V20_H,
  740     V21, V21_H,
  741     V22, V22_H,
  742     V23, V23_H,
  743     V24, V24_H,
  744     V25, V25_H,
  745     V26, V26_H,
  746     V27, V27_H,
  747     V28, V28_H,
  748     V29, V29_H,
  749     V30, V30_H,
  750     V31, V31_H
  751 );
  752 
  753 // Class for all 128bit vector registers
  754 reg_class vectorx_reg(
  755     V0, V0_H, V0_J, V0_K,
  756     V1, V1_H, V1_J, V1_K,
  757     V2, V2_H, V2_J, V2_K,
  758     V3, V3_H, V3_J, V3_K,
  759     V4, V4_H, V4_J, V4_K,
  760     V5, V5_H, V5_J, V5_K,
  761     V6, V6_H, V6_J, V6_K,
  762     V7, V7_H, V7_J, V7_K,
  763     V8, V8_H, V8_J, V8_K,
  764     V9, V9_H, V9_J, V9_K,
  765     V10, V10_H, V10_J, V10_K,
  766     V11, V11_H, V11_J, V11_K,
  767     V12, V12_H, V12_J, V12_K,
  768     V13, V13_H, V13_J, V13_K,
  769     V14, V14_H, V14_J, V14_K,
  770     V15, V15_H, V15_J, V15_K,
  771     V16, V16_H, V16_J, V16_K,
  772     V17, V17_H, V17_J, V17_K,
  773     V18, V18_H, V18_J, V18_K,
  774     V19, V19_H, V19_J, V19_K,
  775     V20, V20_H, V20_J, V20_K,
  776     V21, V21_H, V21_J, V21_K,
  777     V22, V22_H, V22_J, V22_K,
  778     V23, V23_H, V23_J, V23_K,
  779     V24, V24_H, V24_J, V24_K,
  780     V25, V25_H, V25_J, V25_K,
  781     V26, V26_H, V26_J, V26_K,
  782     V27, V27_H, V27_J, V27_K,
  783     V28, V28_H, V28_J, V28_K,
  784     V29, V29_H, V29_J, V29_K,
  785     V30, V30_H, V30_J, V30_K,
  786     V31, V31_H, V31_J, V31_K
  787 );
  788 
  789 // Class for 128 bit register v0
  790 reg_class v0_reg(
  791     V0, V0_H
  792 );
  793 
  794 // Class for 128 bit register v1
  795 reg_class v1_reg(
  796     V1, V1_H
  797 );
  798 
  799 // Class for 128 bit register v2
  800 reg_class v2_reg(
  801     V2, V2_H
  802 );
  803 
  804 // Class for 128 bit register v3
  805 reg_class v3_reg(
  806     V3, V3_H
  807 );
  808 
  809 // Class for 128 bit register v4
  810 reg_class v4_reg(
  811     V4, V4_H
  812 );
  813 
  814 // Class for 128 bit register v5
  815 reg_class v5_reg(
  816     V5, V5_H
  817 );
  818 
  819 // Class for 128 bit register v6
  820 reg_class v6_reg(
  821     V6, V6_H
  822 );
  823 
  824 // Class for 128 bit register v7
  825 reg_class v7_reg(
  826     V7, V7_H
  827 );
  828 
  829 // Class for 128 bit register v8
  830 reg_class v8_reg(
  831     V8, V8_H
  832 );
  833 
  834 // Class for 128 bit register v9
  835 reg_class v9_reg(
  836     V9, V9_H
  837 );
  838 
  839 // Class for 128 bit register v10
  840 reg_class v10_reg(
  841     V10, V10_H
  842 );
  843 
  844 // Class for 128 bit register v11
  845 reg_class v11_reg(
  846     V11, V11_H
  847 );
  848 
  849 // Class for 128 bit register v12
  850 reg_class v12_reg(
  851     V12, V12_H
  852 );
  853 
  854 // Class for 128 bit register v13
  855 reg_class v13_reg(
  856     V13, V13_H
  857 );
  858 
  859 // Class for 128 bit register v14
  860 reg_class v14_reg(
  861     V14, V14_H
  862 );
  863 
  864 // Class for 128 bit register v15
  865 reg_class v15_reg(
  866     V15, V15_H
  867 );
  868 
  869 // Class for 128 bit register v16
  870 reg_class v16_reg(
  871     V16, V16_H
  872 );
  873 
  874 // Class for 128 bit register v17
  875 reg_class v17_reg(
  876     V17, V17_H
  877 );
  878 
  879 // Class for 128 bit register v18
  880 reg_class v18_reg(
  881     V18, V18_H
  882 );
  883 
  884 // Class for 128 bit register v19
  885 reg_class v19_reg(
  886     V19, V19_H
  887 );
  888 
  889 // Class for 128 bit register v20
  890 reg_class v20_reg(
  891     V20, V20_H
  892 );
  893 
  894 // Class for 128 bit register v21
  895 reg_class v21_reg(
  896     V21, V21_H
  897 );
  898 
  899 // Class for 128 bit register v22
  900 reg_class v22_reg(
  901     V22, V22_H
  902 );
  903 
  904 // Class for 128 bit register v23
  905 reg_class v23_reg(
  906     V23, V23_H
  907 );
  908 
  909 // Class for 128 bit register v24
  910 reg_class v24_reg(
  911     V24, V24_H
  912 );
  913 
  914 // Class for 128 bit register v25
  915 reg_class v25_reg(
  916     V25, V25_H
  917 );
  918 
  919 // Class for 128 bit register v26
  920 reg_class v26_reg(
  921     V26, V26_H
  922 );
  923 
  924 // Class for 128 bit register v27
  925 reg_class v27_reg(
  926     V27, V27_H
  927 );
  928 
  929 // Class for 128 bit register v28
  930 reg_class v28_reg(
  931     V28, V28_H
  932 );
  933 
  934 // Class for 128 bit register v29
  935 reg_class v29_reg(
  936     V29, V29_H
  937 );
  938 
  939 // Class for 128 bit register v30
  940 reg_class v30_reg(
  941     V30, V30_H
  942 );
  943 
  944 // Class for 128 bit register v31
  945 reg_class v31_reg(
  946     V31, V31_H
  947 );
  948 
  949 // Singleton class for condition codes
  950 reg_class int_flags(RFLAGS);
  951 
  952 %}
  953 
  954 //----------DEFINITION BLOCK---------------------------------------------------
  955 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  956 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  957 // Format:
  958 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  959 // Generated Code in ad_&lt;arch&gt;.hpp
  960 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  961 //        // value == &lt;int_value&gt;
  962 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  963 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  964 //
  965 
  966 // we follow the ppc-aix port in using a simple cost model which ranks
  967 // register operations as cheap, memory ops as more expensive and
  968 // branches as most expensive. the first two have a low as well as a
  969 // normal cost. huge cost appears to be a way of saying don&#39;t do
  970 // something
  971 
  972 definitions %{
  973   // The default cost (of a register move instruction).
  974   int_def INSN_COST            (    100,     100);
  975   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  976   int_def CALL_COST            (    200,     2 * INSN_COST);
  977   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  978 %}
  979 
  980 
  981 //----------SOURCE BLOCK-------------------------------------------------------
  982 // This is a block of C++ code which provides values, functions, and
  983 // definitions necessary in the rest of the architecture description
  984 
  985 source_hpp %{
  986 
  987 #include &quot;asm/macroAssembler.hpp&quot;
  988 #include &quot;gc/shared/cardTable.hpp&quot;
  989 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  990 #include &quot;gc/shared/collectedHeap.hpp&quot;
  991 #include &quot;opto/addnode.hpp&quot;
  992 #include &quot;opto/convertnode.hpp&quot;
  993 
  994 extern RegMask _ANY_REG32_mask;
  995 extern RegMask _ANY_REG_mask;
  996 extern RegMask _PTR_REG_mask;
  997 extern RegMask _NO_SPECIAL_REG32_mask;
  998 extern RegMask _NO_SPECIAL_REG_mask;
  999 extern RegMask _NO_SPECIAL_PTR_REG_mask;
 1000 
 1001 class CallStubImpl {
 1002 
 1003   //--------------------------------------------------------------
 1004   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
 1005   //--------------------------------------------------------------
 1006 
 1007  public:
 1008   // Size of call trampoline stub.
 1009   static uint size_call_trampoline() {
 1010     return 0; // no call trampolines on this platform
 1011   }
 1012 
 1013   // number of relocations needed by a call trampoline stub
 1014   static uint reloc_call_trampoline() {
 1015     return 0; // no call trampolines on this platform
 1016   }
 1017 };
 1018 
 1019 class HandlerImpl {
 1020 
 1021  public:
 1022 
 1023   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1024   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1025 
 1026   static uint size_exception_handler() {
 1027     return MacroAssembler::far_branch_size();
 1028   }
 1029 
 1030   static uint size_deopt_handler() {
 1031     // count one adr and one far branch instruction
 1032     return 4 * NativeInstruction::instruction_size;
 1033   }
 1034 };
 1035 
 1036  bool is_CAS(int opcode, bool maybe_volatile);
 1037 
 1038   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1039 
 1040   bool unnecessary_acquire(const Node *barrier);
 1041   bool needs_acquiring_load(const Node *load);
 1042 
 1043   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1044 
 1045   bool unnecessary_release(const Node *barrier);
 1046   bool unnecessary_volatile(const Node *barrier);
 1047   bool needs_releasing_store(const Node *store);
 1048 
 1049   // predicate controlling translation of CompareAndSwapX
 1050   bool needs_acquiring_load_exclusive(const Node *load);
 1051 
 1052   // predicate controlling addressing modes
 1053   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1054 %}
 1055 
 1056 source %{
 1057 
 1058   // Derived RegMask with conditionally allocatable registers
 1059 
 1060   RegMask _ANY_REG32_mask;
 1061   RegMask _ANY_REG_mask;
 1062   RegMask _PTR_REG_mask;
 1063   RegMask _NO_SPECIAL_REG32_mask;
 1064   RegMask _NO_SPECIAL_REG_mask;
 1065   RegMask _NO_SPECIAL_PTR_REG_mask;
 1066 
 1067   void reg_mask_init() {
 1068     // We derive below RegMask(s) from the ones which are auto-generated from
 1069     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1070     // registers conditionally reserved.
 1071 
 1072     _ANY_REG32_mask = _ALL_REG32_mask;
 1073     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1074 
 1075     _ANY_REG_mask = _ALL_REG_mask;
 1076 
 1077     _PTR_REG_mask = _ALL_REG_mask;
 1078 
 1079     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1080     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1081 
 1082     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1083     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1084 
 1085     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1086     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1087 
 1088     // r27 is not allocatable when compressed oops is on, compressed klass
 1089     // pointers doesn&#39;t use r27 after JDK-8234794
 1090     if (UseCompressedOops) {
 1091       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1092       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1093       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1094     }
 1095 
 1096     // r29 is not allocatable when PreserveFramePointer is on
 1097     if (PreserveFramePointer) {
 1098       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1099       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1100       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1101     }
 1102   }
 1103 
 1104   // Optimizaton of volatile gets and puts
 1105   // -------------------------------------
 1106   //
 1107   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1108   // use to implement volatile reads and writes. For a volatile read
 1109   // we simply need
 1110   //
 1111   //   ldar&lt;x&gt;
 1112   //
 1113   // and for a volatile write we need
 1114   //
 1115   //   stlr&lt;x&gt;
 1116   //
 1117   // Alternatively, we can implement them by pairing a normal
 1118   // load/store with a memory barrier. For a volatile read we need
 1119   //
 1120   //   ldr&lt;x&gt;
 1121   //   dmb ishld
 1122   //
 1123   // for a volatile write
 1124   //
 1125   //   dmb ish
 1126   //   str&lt;x&gt;
 1127   //   dmb ish
 1128   //
 1129   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1130   // sequences. These are normally translated to an instruction
 1131   // sequence like the following
 1132   //
 1133   //   dmb      ish
 1134   // retry:
 1135   //   ldxr&lt;x&gt;   rval raddr
 1136   //   cmp       rval rold
 1137   //   b.ne done
 1138   //   stlxr&lt;x&gt;  rval, rnew, rold
 1139   //   cbnz      rval retry
 1140   // done:
 1141   //   cset      r0, eq
 1142   //   dmb ishld
 1143   //
 1144   // Note that the exclusive store is already using an stlxr
 1145   // instruction. That is required to ensure visibility to other
 1146   // threads of the exclusive write (assuming it succeeds) before that
 1147   // of any subsequent writes.
 1148   //
 1149   // The following instruction sequence is an improvement on the above
 1150   //
 1151   // retry:
 1152   //   ldaxr&lt;x&gt;  rval raddr
 1153   //   cmp       rval rold
 1154   //   b.ne done
 1155   //   stlxr&lt;x&gt;  rval, rnew, rold
 1156   //   cbnz      rval retry
 1157   // done:
 1158   //   cset      r0, eq
 1159   //
 1160   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1161   // visibility of prior writes in the case that the swap is
 1162   // successful. Crucially we don&#39;t have to worry about the case where
 1163   // the swap is not successful since no valid program should be
 1164   // relying on visibility of prior changes by the attempting thread
 1165   // in the case where the CAS fails.
 1166   //
 1167   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1168   // an ldaxr instruction since that will provide all the guarantees we
 1169   // require regarding observation of changes made by other threads
 1170   // before any change to the CAS address observed by the load.
 1171   //
 1172   // In order to generate the desired instruction sequence we need to
 1173   // be able to identify specific &#39;signature&#39; ideal graph node
 1174   // sequences which i) occur as a translation of a volatile reads or
 1175   // writes or CAS operations and ii) do not occur through any other
 1176   // translation or graph transformation. We can then provide
 1177   // alternative aldc matching rules which translate these node
 1178   // sequences to the desired machine code sequences. Selection of the
 1179   // alternative rules can be implemented by predicates which identify
 1180   // the relevant node sequences.
 1181   //
 1182   // The ideal graph generator translates a volatile read to the node
 1183   // sequence
 1184   //
 1185   //   LoadX[mo_acquire]
 1186   //   MemBarAcquire
 1187   //
 1188   // As a special case when using the compressed oops optimization we
 1189   // may also see this variant
 1190   //
 1191   //   LoadN[mo_acquire]
 1192   //   DecodeN
 1193   //   MemBarAcquire
 1194   //
 1195   // A volatile write is translated to the node sequence
 1196   //
 1197   //   MemBarRelease
 1198   //   StoreX[mo_release] {CardMark}-optional
 1199   //   MemBarVolatile
 1200   //
 1201   // n.b. the above node patterns are generated with a strict
 1202   // &#39;signature&#39; configuration of input and output dependencies (see
 1203   // the predicates below for exact details). The card mark may be as
 1204   // simple as a few extra nodes or, in a few GC configurations, may
 1205   // include more complex control flow between the leading and
 1206   // trailing memory barriers. However, whatever the card mark
 1207   // configuration these signatures are unique to translated volatile
 1208   // reads/stores -- they will not appear as a result of any other
 1209   // bytecode translation or inlining nor as a consequence of
 1210   // optimizing transforms.
 1211   //
 1212   // We also want to catch inlined unsafe volatile gets and puts and
 1213   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1214   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1215   //
 1216   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1217   // normal volatile put node sequence containing an extra cpuorder
 1218   // membar
 1219   //
 1220   //   MemBarRelease
 1221   //   MemBarCPUOrder
 1222   //   StoreX[mo_release] {CardMark}-optional
 1223   //   MemBarCPUOrder
 1224   //   MemBarVolatile
 1225   //
 1226   // n.b. as an aside, a cpuorder membar is not itself subject to
 1227   // matching and translation by adlc rules.  However, the rule
 1228   // predicates need to detect its presence in order to correctly
 1229   // select the desired adlc rules.
 1230   //
 1231   // Inlined unsafe volatile gets manifest as a slightly different
 1232   // node sequence to a normal volatile get because of the
 1233   // introduction of some CPUOrder memory barriers to bracket the
 1234   // Load. However, but the same basic skeleton of a LoadX feeding a
 1235   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1236   // present
 1237   //
 1238   //   MemBarCPUOrder
 1239   //        ||       \\
 1240   //   MemBarCPUOrder LoadX[mo_acquire]
 1241   //        ||            |
 1242   //        ||       {DecodeN} optional
 1243   //        ||       /
 1244   //     MemBarAcquire
 1245   //
 1246   // In this case the acquire membar does not directly depend on the
 1247   // load. However, we can be sure that the load is generated from an
 1248   // inlined unsafe volatile get if we see it dependent on this unique
 1249   // sequence of membar nodes. Similarly, given an acquire membar we
 1250   // can know that it was added because of an inlined unsafe volatile
 1251   // get if it is fed and feeds a cpuorder membar and if its feed
 1252   // membar also feeds an acquiring load.
 1253   //
 1254   // Finally an inlined (Unsafe) CAS operation is translated to the
 1255   // following ideal graph
 1256   //
 1257   //   MemBarRelease
 1258   //   MemBarCPUOrder
 1259   //   CompareAndSwapX {CardMark}-optional
 1260   //   MemBarCPUOrder
 1261   //   MemBarAcquire
 1262   //
 1263   // So, where we can identify these volatile read and write
 1264   // signatures we can choose to plant either of the above two code
 1265   // sequences. For a volatile read we can simply plant a normal
 1266   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1267   // also choose to inhibit translation of the MemBarAcquire and
 1268   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1269   //
 1270   // When we recognise a volatile store signature we can choose to
 1271   // plant at a dmb ish as a translation for the MemBarRelease, a
 1272   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1273   // Alternatively, we can inhibit translation of the MemBarRelease
 1274   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1275   // instruction.
 1276   //
 1277   // when we recognise a CAS signature we can choose to plant a dmb
 1278   // ish as a translation for the MemBarRelease, the conventional
 1279   // macro-instruction sequence for the CompareAndSwap node (which
 1280   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1281   // Alternatively, we can elide generation of the dmb instructions
 1282   // and plant the alternative CompareAndSwap macro-instruction
 1283   // sequence (which uses ldaxr&lt;x&gt;).
 1284   //
 1285   // Of course, the above only applies when we see these signature
 1286   // configurations. We still want to plant dmb instructions in any
 1287   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1288   // MemBarVolatile. For example, at the end of a constructor which
 1289   // writes final/volatile fields we will see a MemBarRelease
 1290   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1291   // constructed object being visible without making the
 1292   // final/volatile field writes visible.
 1293   //
 1294   // n.b. the translation rules below which rely on detection of the
 1295   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1296   // If we see anything other than the signature configurations we
 1297   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1298   // and translate acquire, release and volatile membars to the
 1299   // relevant dmb instructions.
 1300   //
 1301 
 1302   // is_CAS(int opcode, bool maybe_volatile)
 1303   //
 1304   // return true if opcode is one of the possible CompareAndSwapX
 1305   // values otherwise false.
 1306 
 1307   bool is_CAS(int opcode, bool maybe_volatile)
 1308   {
 1309     switch(opcode) {
 1310       // We handle these
 1311     case Op_CompareAndSwapI:
 1312     case Op_CompareAndSwapL:
 1313     case Op_CompareAndSwapP:
 1314     case Op_CompareAndSwapN:
 1315     case Op_ShenandoahCompareAndSwapP:
 1316     case Op_ShenandoahCompareAndSwapN:
 1317     case Op_CompareAndSwapB:
 1318     case Op_CompareAndSwapS:
 1319     case Op_GetAndSetI:
 1320     case Op_GetAndSetL:
 1321     case Op_GetAndSetP:
 1322     case Op_GetAndSetN:
 1323     case Op_GetAndAddI:
 1324     case Op_GetAndAddL:
 1325       return true;
 1326     case Op_CompareAndExchangeI:
 1327     case Op_CompareAndExchangeN:
 1328     case Op_CompareAndExchangeB:
 1329     case Op_CompareAndExchangeS:
 1330     case Op_CompareAndExchangeL:
 1331     case Op_CompareAndExchangeP:
 1332     case Op_WeakCompareAndSwapB:
 1333     case Op_WeakCompareAndSwapS:
 1334     case Op_WeakCompareAndSwapI:
 1335     case Op_WeakCompareAndSwapL:
 1336     case Op_WeakCompareAndSwapP:
 1337     case Op_WeakCompareAndSwapN:
 1338     case Op_ShenandoahWeakCompareAndSwapP:
 1339     case Op_ShenandoahWeakCompareAndSwapN:
 1340     case Op_ShenandoahCompareAndExchangeP:
 1341     case Op_ShenandoahCompareAndExchangeN:
 1342       return maybe_volatile;
 1343     default:
 1344       return false;
 1345     }
 1346   }
 1347 
 1348   // helper to determine the maximum number of Phi nodes we may need to
 1349   // traverse when searching from a card mark membar for the merge mem
 1350   // feeding a trailing membar or vice versa
 1351 
 1352 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1353 
 1354 bool unnecessary_acquire(const Node *barrier)
 1355 {
 1356   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1357 
 1358   if (UseBarriersForVolatile) {
 1359     // we need to plant a dmb
 1360     return false;
 1361   }
 1362 
 1363   MemBarNode* mb = barrier-&gt;as_MemBar();
 1364 
 1365   if (mb-&gt;trailing_load()) {
 1366     return true;
 1367   }
 1368 
 1369   if (mb-&gt;trailing_load_store()) {
 1370     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1371     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1372     return is_CAS(load_store-&gt;Opcode(), true);
 1373   }
 1374 
 1375   return false;
 1376 }
 1377 
 1378 bool needs_acquiring_load(const Node *n)
 1379 {
 1380   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1381   if (UseBarriersForVolatile) {
 1382     // we use a normal load and a dmb
 1383     return false;
 1384   }
 1385 
 1386   LoadNode *ld = n-&gt;as_Load();
 1387 
 1388   return ld-&gt;is_acquire();
 1389 }
 1390 
 1391 bool unnecessary_release(const Node *n)
 1392 {
 1393   assert((n-&gt;is_MemBar() &amp;&amp;
 1394 	  n-&gt;Opcode() == Op_MemBarRelease),
 1395 	 &quot;expecting a release membar&quot;);
 1396 
 1397   if (UseBarriersForVolatile) {
 1398     // we need to plant a dmb
 1399     return false;
 1400   }
 1401 
 1402   MemBarNode *barrier = n-&gt;as_MemBar();
 1403   if (!barrier-&gt;leading()) {
 1404     return false;
 1405   } else {
 1406     Node* trailing = barrier-&gt;trailing_membar();
 1407     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1408     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1409     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1410 
 1411     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1412     if (mem-&gt;is_Store()) {
 1413       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1414       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1415       return true;
 1416     } else {
 1417       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1418       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1419       return is_CAS(mem-&gt;Opcode(), true);
 1420     }
 1421   }
 1422   return false;
 1423 }
 1424 
 1425 bool unnecessary_volatile(const Node *n)
 1426 {
 1427   // assert n-&gt;is_MemBar();
 1428   if (UseBarriersForVolatile) {
 1429     // we need to plant a dmb
 1430     return false;
 1431   }
 1432 
 1433   MemBarNode *mbvol = n-&gt;as_MemBar();
 1434 
 1435   bool release = mbvol-&gt;trailing_store();
 1436   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1437 #ifdef ASSERT
 1438   if (release) {
 1439     Node* leading = mbvol-&gt;leading_membar();
 1440     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1441     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1442     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1443   }
 1444 #endif
 1445 
 1446   return release;
 1447 }
 1448 
 1449 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1450 
 1451 bool needs_releasing_store(const Node *n)
 1452 {
 1453   // assert n-&gt;is_Store();
 1454   if (UseBarriersForVolatile) {
 1455     // we use a normal store and dmb combination
 1456     return false;
 1457   }
 1458 
 1459   StoreNode *st = n-&gt;as_Store();
 1460 
 1461   return st-&gt;trailing_membar() != NULL;
 1462 }
 1463 
 1464 // predicate controlling translation of CAS
 1465 //
 1466 // returns true if CAS needs to use an acquiring load otherwise false
 1467 
 1468 bool needs_acquiring_load_exclusive(const Node *n)
 1469 {
 1470   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1471   if (UseBarriersForVolatile) {
 1472     return false;
 1473   }
 1474 
 1475   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1476   if (is_CAS(n-&gt;Opcode(), false)) {
 1477     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1478   } else {
 1479     return ldst-&gt;trailing_membar() != NULL;
 1480   }
 1481 
 1482   // so we can just return true here
 1483   return true;
 1484 }
 1485 
 1486 #define __ _masm.
 1487 
 1488 // advance declarations for helper functions to convert register
 1489 // indices to register objects
 1490 
 1491 // the ad file has to provide implementations of certain methods
 1492 // expected by the generic code
 1493 //
 1494 // REQUIRED FUNCTIONALITY
 1495 
 1496 //=============================================================================
 1497 
 1498 // !!!!! Special hack to get all types of calls to specify the byte offset
 1499 //       from the start of the call to the point where the return address
 1500 //       will point.
 1501 
 1502 int MachCallStaticJavaNode::ret_addr_offset()
 1503 {
 1504   // call should be a simple bl
 1505   int off = 4;
 1506   return off;
 1507 }
 1508 
 1509 int MachCallDynamicJavaNode::ret_addr_offset()
 1510 {
 1511   return 16; // movz, movk, movk, bl
 1512 }
 1513 
 1514 int MachCallRuntimeNode::ret_addr_offset() {
 1515   // for generated stubs the call will be
 1516   //   far_call(addr)
 1517   // for real runtime callouts it will be six instructions
 1518   // see aarch64_enc_java_to_runtime
 1519   //   adr(rscratch2, retaddr)
 1520   //   lea(rscratch1, RuntimeAddress(addr)
 1521   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1522   //   blr(rscratch1)
 1523   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1524   if (cb) {
 1525     return MacroAssembler::far_branch_size();
 1526   } else {
 1527     return 6 * NativeInstruction::instruction_size;
 1528   }
 1529 }
 1530 
 1531 // Indicate if the safepoint node needs the polling page as an input
 1532 
 1533 // the shared code plants the oop data at the start of the generated
 1534 // code for the safepoint node and that needs ot be at the load
 1535 // instruction itself. so we cannot plant a mov of the safepoint poll
 1536 // address followed by a load. setting this to true means the mov is
 1537 // scheduled as a prior instruction. that&#39;s better for scheduling
 1538 // anyway.
 1539 
 1540 bool SafePointNode::needs_polling_address_input()
 1541 {
 1542   return true;
 1543 }
 1544 
 1545 //=============================================================================
 1546 
 1547 #ifndef PRODUCT
 1548 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1549   st-&gt;print(&quot;BREAKPOINT&quot;);
 1550 }
 1551 #endif
 1552 
 1553 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1554   MacroAssembler _masm(&amp;cbuf);
 1555   __ brk(0);
 1556 }
 1557 
 1558 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1559   return MachNode::size(ra_);
 1560 }
 1561 
 1562 //=============================================================================
 1563 
 1564 #ifndef PRODUCT
 1565   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1566     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1567   }
 1568 #endif
 1569 
 1570   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1571     MacroAssembler _masm(&amp;cbuf);
 1572     for (int i = 0; i &lt; _count; i++) {
 1573       __ nop();
 1574     }
 1575   }
 1576 
 1577   uint MachNopNode::size(PhaseRegAlloc*) const {
 1578     return _count * NativeInstruction::instruction_size;
 1579   }
 1580 
 1581 //=============================================================================
 1582 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1583 
 1584 int Compile::ConstantTable::calculate_table_base_offset() const {
 1585   return 0;  // absolute addressing, no offset
 1586 }
 1587 
 1588 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1589 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1590   ShouldNotReachHere();
 1591 }
 1592 
 1593 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1594   // Empty encoding
 1595 }
 1596 
 1597 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1598   return 0;
 1599 }
 1600 
 1601 #ifndef PRODUCT
 1602 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1603   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1604 }
 1605 #endif
 1606 
 1607 #ifndef PRODUCT
 1608 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1609   Compile* C = ra_-&gt;C;
 1610 
 1611   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1612 
 1613   if (C-&gt;need_stack_bang(framesize))
 1614     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1615 
 1616   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1617     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1618     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1619     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1620   } else {
 1621     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1622     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1623     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1624     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1625   }
 1626 }
 1627 #endif
 1628 
 1629 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1630   Compile* C = ra_-&gt;C;
 1631   MacroAssembler _masm(&amp;cbuf);
 1632 
 1633   // n.b. frame size includes space for return pc and rfp
<a name="3" id="anc3"></a><span class="line-modified"> 1634   const int64_t framesize = C-&gt;frame_size_in_bytes();</span>
 1635   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1636 
 1637   // insert a nop at the start of the prolog so we can patch in a
 1638   // branch if we need to invalidate the method later
 1639   __ nop();
 1640 
 1641   if (C-&gt;clinit_barrier_on_entry()) {
 1642     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1643 
 1644     Label L_skip_barrier;
 1645 
 1646     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1647     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1648     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1649     __ bind(L_skip_barrier);
 1650   }
 1651 
 1652   int bangsize = C-&gt;bang_size_in_bytes();
 1653   if (C-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
 1654     __ generate_stack_overflow_check(bangsize);
 1655 
 1656   __ build_frame(framesize);
 1657 
 1658   if (VerifyStackAtCalls) {
 1659     Unimplemented();
 1660   }
 1661 
 1662   C-&gt;set_frame_complete(cbuf.insts_size());
 1663 
 1664   if (C-&gt;has_mach_constant_base_node()) {
 1665     // NOTE: We set the table base offset here because users might be
 1666     // emitted before MachConstantBaseNode.
 1667     Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();
 1668     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1669   }
 1670 }
 1671 
 1672 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1673 {
 1674   return MachNode::size(ra_); // too many variables; just compute it
 1675                               // the hard way
 1676 }
 1677 
 1678 int MachPrologNode::reloc() const
 1679 {
 1680   return 0;
 1681 }
 1682 
 1683 //=============================================================================
 1684 
 1685 #ifndef PRODUCT
 1686 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1687   Compile* C = ra_-&gt;C;
 1688   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1689 
 1690   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1691 
 1692   if (framesize == 0) {
 1693     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1694   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1695     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1696     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1697   } else {
 1698     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1699     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1700     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1701   }
 1702 
 1703   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1704     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1705     st-&gt;print(&quot;mov  rscratch1, #0x%lx\n\t&quot;, p2i(os::get_polling_page()));
 1706     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1707   }
 1708 }
 1709 #endif
 1710 
 1711 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1712   Compile* C = ra_-&gt;C;
 1713   MacroAssembler _masm(&amp;cbuf);
 1714   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1715 
 1716   __ remove_frame(framesize);
 1717 
 1718   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1719     __ reserved_stack_check();
 1720   }
 1721 
 1722   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1723     __ read_polling_page(rscratch1, os::get_polling_page(), relocInfo::poll_return_type);
 1724   }
 1725 }
 1726 
 1727 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1728   // Variable size. Determine dynamically.
 1729   return MachNode::size(ra_);
 1730 }
 1731 
 1732 int MachEpilogNode::reloc() const {
 1733   // Return number of relocatable values contained in this instruction.
 1734   return 1; // 1 for polling page.
 1735 }
 1736 
 1737 const Pipeline * MachEpilogNode::pipeline() const {
 1738   return MachNode::pipeline_class();
 1739 }
 1740 
 1741 // This method seems to be obsolete. It is declared in machnode.hpp
 1742 // and defined in all *.ad files, but it is never called. Should we
 1743 // get rid of it?
 1744 int MachEpilogNode::safepoint_offset() const {
 1745   assert(do_polling(), &quot;no return for this epilog node&quot;);
 1746   return 4;
 1747 }
 1748 
 1749 //=============================================================================
 1750 
 1751 // Figure out which register class each belongs in: rc_int, rc_float or
 1752 // rc_stack.
 1753 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1754 
 1755 static enum RC rc_class(OptoReg::Name reg) {
 1756 
 1757   if (reg == OptoReg::Bad) {
 1758     return rc_bad;
 1759   }
 1760 
 1761   // we have 30 int registers * 2 halves
 1762   // (rscratch1 and rscratch2 are omitted)
 1763   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1764 
 1765   if (reg &lt; slots_of_int_registers) {
 1766     return rc_int;
 1767   }
 1768 
 1769   // we have 32 float register * 4 halves
 1770   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1771     return rc_float;
 1772   }
 1773 
 1774   // Between float regs &amp; stack is the flags regs.
 1775   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1776 
 1777   return rc_stack;
 1778 }
 1779 
 1780 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1781   Compile* C = ra_-&gt;C;
 1782 
 1783   // Get registers to move.
 1784   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1785   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1786   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1787   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1788 
 1789   enum RC src_hi_rc = rc_class(src_hi);
 1790   enum RC src_lo_rc = rc_class(src_lo);
 1791   enum RC dst_hi_rc = rc_class(dst_hi);
 1792   enum RC dst_lo_rc = rc_class(dst_lo);
 1793 
 1794   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1795 
 1796   if (src_hi != OptoReg::Bad) {
 1797     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1798            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1799            &quot;expected aligned-adjacent pairs&quot;);
 1800   }
 1801 
 1802   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1803     return 0;            // Self copy, no move.
 1804   }
 1805 
 1806   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1807               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1808   int src_offset = ra_-&gt;reg2offset(src_lo);
 1809   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1810 
 1811   if (bottom_type()-&gt;isa_vect() != NULL) {
 1812     uint ireg = ideal_reg();
 1813     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1814     if (cbuf) {
 1815       MacroAssembler _masm(cbuf);
 1816       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1817       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1818         // stack-&gt;stack
 1819         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1820         if (ireg == Op_VecD) {
 1821           __ unspill(rscratch1, true, src_offset);
 1822           __ spill(rscratch1, true, dst_offset);
 1823         } else {
 1824           __ spill_copy128(src_offset, dst_offset);
 1825         }
 1826       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1827         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1828                ireg == Op_VecD ? __ T8B : __ T16B,
 1829                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1830       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1831         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1832                        ireg == Op_VecD ? __ D : __ Q,
 1833                        ra_-&gt;reg2offset(dst_lo));
 1834       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1835         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1836                        ireg == Op_VecD ? __ D : __ Q,
 1837                        ra_-&gt;reg2offset(src_lo));
 1838       } else {
 1839         ShouldNotReachHere();
 1840       }
 1841     }
 1842   } else if (cbuf) {
 1843     MacroAssembler _masm(cbuf);
 1844     switch (src_lo_rc) {
 1845     case rc_int:
 1846       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1847         if (is64) {
 1848             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1849                    as_Register(Matcher::_regEncode[src_lo]));
 1850         } else {
 1851             MacroAssembler _masm(cbuf);
 1852             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1853                     as_Register(Matcher::_regEncode[src_lo]));
 1854         }
 1855       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1856         if (is64) {
 1857             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1858                      as_Register(Matcher::_regEncode[src_lo]));
 1859         } else {
 1860             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1861                      as_Register(Matcher::_regEncode[src_lo]));
 1862         }
 1863       } else {                    // gpr --&gt; stack spill
 1864         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1865         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1866       }
 1867       break;
 1868     case rc_float:
 1869       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1870         if (is64) {
 1871             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1872                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1873         } else {
 1874             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1875                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1876         }
 1877       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1878           if (cbuf) {
 1879             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1880                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1881         } else {
 1882             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1883                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1884         }
 1885       } else {                    // fpr --&gt; stack spill
 1886         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1887         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1888                  is64 ? __ D : __ S, dst_offset);
 1889       }
 1890       break;
 1891     case rc_stack:
 1892       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1893         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1894       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1895         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1896                    is64 ? __ D : __ S, src_offset);
 1897       } else {                    // stack --&gt; stack copy
 1898         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1899         __ unspill(rscratch1, is64, src_offset);
 1900         __ spill(rscratch1, is64, dst_offset);
 1901       }
 1902       break;
 1903     default:
 1904       assert(false, &quot;bad rc_class for spill&quot;);
 1905       ShouldNotReachHere();
 1906     }
 1907   }
 1908 
 1909   if (st) {
 1910     st-&gt;print(&quot;spill &quot;);
 1911     if (src_lo_rc == rc_stack) {
 1912       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1913     } else {
 1914       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1915     }
 1916     if (dst_lo_rc == rc_stack) {
 1917       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1918     } else {
 1919       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1920     }
 1921     if (bottom_type()-&gt;isa_vect() != NULL) {
 1922       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1923     } else {
 1924       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1925     }
 1926   }
 1927 
 1928   return 0;
 1929 
 1930 }
 1931 
 1932 #ifndef PRODUCT
 1933 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1934   if (!ra_)
 1935     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1936   else
 1937     implementation(NULL, ra_, false, st);
 1938 }
 1939 #endif
 1940 
 1941 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1942   implementation(&amp;cbuf, ra_, false, NULL);
 1943 }
 1944 
 1945 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1946   return MachNode::size(ra_);
 1947 }
 1948 
 1949 //=============================================================================
 1950 
 1951 #ifndef PRODUCT
 1952 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1953   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1954   int reg = ra_-&gt;get_reg_first(this);
 1955   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1956             Matcher::regName[reg], offset);
 1957 }
 1958 #endif
 1959 
 1960 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1961   MacroAssembler _masm(&amp;cbuf);
 1962 
 1963   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1964   int reg    = ra_-&gt;get_encode(this);
 1965 
 1966   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1967     __ add(as_Register(reg), sp, offset);
 1968   } else {
 1969     ShouldNotReachHere();
 1970   }
 1971 }
 1972 
 1973 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1974   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1975   return 4;
 1976 }
 1977 
 1978 //=============================================================================
 1979 
 1980 #ifndef PRODUCT
 1981 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1982 {
 1983   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1984   if (UseCompressedClassPointers) {
 1985     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1986     if (CompressedKlassPointers::shift() != 0) {
 1987       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1988     }
 1989   } else {
 1990    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1991   }
 1992   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1993   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1994 }
 1995 #endif
 1996 
 1997 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1998 {
 1999   // This is the unverified entry point.
 2000   MacroAssembler _masm(&amp;cbuf);
 2001 
 2002   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2003   Label skip;
 2004   // TODO
 2005   // can we avoid this skip and still use a reloc?
 2006   __ br(Assembler::EQ, skip);
 2007   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2008   __ bind(skip);
 2009 }
 2010 
 2011 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2012 {
 2013   return MachNode::size(ra_);
 2014 }
 2015 
 2016 // REQUIRED EMIT CODE
 2017 
 2018 //=============================================================================
 2019 
 2020 // Emit exception handler code.
 2021 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2022 {
 2023   // mov rscratch1 #exception_blob_entry_point
 2024   // br rscratch1
 2025   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2026   // That&#39;s why we must use the macroassembler to generate a handler.
 2027   MacroAssembler _masm(&amp;cbuf);
 2028   address base = __ start_a_stub(size_exception_handler());
 2029   if (base == NULL) {
 2030     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2031     return 0;  // CodeBuffer::expand failed
 2032   }
 2033   int offset = __ offset();
 2034   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2035   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2036   __ end_a_stub();
 2037   return offset;
 2038 }
 2039 
 2040 // Emit deopt handler code.
 2041 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2042 {
 2043   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2044   // That&#39;s why we must use the macroassembler to generate a handler.
 2045   MacroAssembler _masm(&amp;cbuf);
 2046   address base = __ start_a_stub(size_deopt_handler());
 2047   if (base == NULL) {
 2048     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2049     return 0;  // CodeBuffer::expand failed
 2050   }
 2051   int offset = __ offset();
 2052 
 2053   __ adr(lr, __ pc());
 2054   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2055 
 2056   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2057   __ end_a_stub();
 2058   return offset;
 2059 }
 2060 
 2061 // REQUIRED MATCHER CODE
 2062 
 2063 //=============================================================================
 2064 
 2065 const bool Matcher::match_rule_supported(int opcode) {
 2066   if (!has_match_rule(opcode))
 2067     return false;
 2068 
 2069   bool ret_value = true;
 2070   switch (opcode) {
 2071     case Op_CacheWB:
 2072     case Op_CacheWBPreSync:
 2073     case Op_CacheWBPostSync:
 2074       if (!VM_Version::supports_data_cache_line_flush()) {
 2075         ret_value = false;
 2076       }
 2077       break;
 2078   }
 2079 
 2080   return ret_value; // Per default match rules are supported.
 2081 }
 2082 
 2083 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2084 
 2085   // TODO
 2086   // identify extra cases that we might want to provide match rules for
 2087   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
 2088   bool ret_value = match_rule_supported(opcode);
 2089   // Add rules here.
 2090 
 2091   return ret_value;  // Per default match rules are supported.
 2092 }
 2093 
 2094 const bool Matcher::has_predicated_vectors(void) {
 2095   return false;
 2096 }
 2097 
 2098 const int Matcher::float_pressure(int default_pressure_threshold) {
 2099   return default_pressure_threshold;
 2100 }
 2101 
 2102 int Matcher::regnum_to_fpu_offset(int regnum)
 2103 {
 2104   Unimplemented();
 2105   return 0;
 2106 }
 2107 
 2108 // Is this branch offset short enough that a short branch can be used?
 2109 //
 2110 // NOTE: If the platform does not provide any short branch variants, then
 2111 //       this method should return false for offset 0.
 2112 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2113   // The passed offset is relative to address of the branch.
 2114 
 2115   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2116 }
 2117 
 2118 const bool Matcher::isSimpleConstant64(jlong value) {
 2119   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2120   // Probably always true, even if a temp register is required.
 2121   return true;
 2122 }
 2123 
 2124 // true just means we have fast l2f conversion
 2125 const bool Matcher::convL2FSupported(void) {
 2126   return true;
 2127 }
 2128 
 2129 // Vector width in bytes.
 2130 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2131   int size = MIN2(16,(int)MaxVectorSize);
 2132   // Minimum 2 values in vector
 2133   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2134   // But never &lt; 4
 2135   if (size &lt; 4) size = 0;
 2136   return size;
 2137 }
 2138 
 2139 // Limits on vector size (number of elements) loaded into vector.
 2140 const int Matcher::max_vector_size(const BasicType bt) {
 2141   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2142 }
 2143 const int Matcher::min_vector_size(const BasicType bt) {
 2144 //  For the moment limit the vector size to 8 bytes
 2145     int size = 8 / type2aelembytes(bt);
 2146     if (size &lt; 2) size = 2;
 2147     return size;
 2148 }
 2149 
 2150 // Vector ideal reg.
 2151 const uint Matcher::vector_ideal_reg(int len) {
 2152   switch(len) {
 2153     case  8: return Op_VecD;
 2154     case 16: return Op_VecX;
 2155   }
 2156   ShouldNotReachHere();
 2157   return 0;
 2158 }
 2159 
 2160 const uint Matcher::vector_shift_count_ideal_reg(int size) {
 2161   switch(size) {
 2162     case  8: return Op_VecD;
 2163     case 16: return Op_VecX;
 2164   }
 2165   ShouldNotReachHere();
 2166   return 0;
 2167 }
 2168 
 2169 // AES support not yet implemented
 2170 const bool Matcher::pass_original_key_for_aes() {
 2171   return false;
 2172 }
 2173 
 2174 // aarch64 supports misaligned vectors store/load.
 2175 const bool Matcher::misaligned_vectors_ok() {
 2176   return true;
 2177 }
 2178 
 2179 // false =&gt; size gets scaled to BytesPerLong, ok.
 2180 const bool Matcher::init_array_count_is_in_bytes = false;
 2181 
 2182 // Use conditional move (CMOVL)
 2183 const int Matcher::long_cmove_cost() {
 2184   // long cmoves are no more expensive than int cmoves
 2185   return 0;
 2186 }
 2187 
 2188 const int Matcher::float_cmove_cost() {
 2189   // float cmoves are no more expensive than int cmoves
 2190   return 0;
 2191 }
 2192 
 2193 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2194 const bool Matcher::require_postalloc_expand = false;
 2195 
 2196 // Do we need to mask the count passed to shift instructions or does
 2197 // the cpu only look at the lower 5/6 bits anyway?
 2198 const bool Matcher::need_masked_shift_count = false;
 2199 
 2200 // No support for generic vector operands.
 2201 const bool Matcher::supports_generic_vector_operands  = false;
 2202 
 2203 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2204   ShouldNotReachHere(); // generic vector operands not supported
 2205   return NULL;
 2206 }
 2207 
 2208 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2209   ShouldNotReachHere();  // generic vector operands not supported
 2210   return false;
 2211 }
 2212 
 2213 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2214   ShouldNotReachHere();  // generic vector operands not supported
 2215   return false;
 2216 }
 2217 
 2218 // This affects two different things:
 2219 //  - how Decode nodes are matched
 2220 //  - how ImplicitNullCheck opportunities are recognized
 2221 // If true, the matcher will try to remove all Decodes and match them
 2222 // (as operands) into nodes. NullChecks are not prepared to deal with
 2223 // Decodes by final_graph_reshaping().
 2224 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2225 // for a NullCheck. The matcher matches the Decode node into a register.
 2226 // Implicit_null_check optimization moves the Decode along with the
 2227 // memory operation back up before the NullCheck.
 2228 bool Matcher::narrow_oop_use_complex_address() {
 2229   return CompressedOops::shift() == 0;
 2230 }
 2231 
 2232 bool Matcher::narrow_klass_use_complex_address() {
 2233 // TODO
 2234 // decide whether we need to set this to true
 2235   return false;
 2236 }
 2237 
 2238 bool Matcher::const_oop_prefer_decode() {
 2239   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2240   return CompressedOops::base() == NULL;
 2241 }
 2242 
 2243 bool Matcher::const_klass_prefer_decode() {
 2244   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2245   return CompressedKlassPointers::base() == NULL;
 2246 }
 2247 
 2248 // Is it better to copy float constants, or load them directly from
 2249 // memory?  Intel can load a float constant from a direct address,
 2250 // requiring no extra registers.  Most RISCs will have to materialize
 2251 // an address into a register first, so they would do better to copy
 2252 // the constant from stack.
 2253 const bool Matcher::rematerialize_float_constants = false;
 2254 
 2255 // If CPU can load and store mis-aligned doubles directly then no
 2256 // fixup is needed.  Else we split the double into 2 integer pieces
 2257 // and move it piece-by-piece.  Only happens when passing doubles into
 2258 // C code as the Java calling convention forces doubles to be aligned.
 2259 const bool Matcher::misaligned_doubles_ok = true;
 2260 
 2261 // No-op on amd64
 2262 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2263   Unimplemented();
 2264 }
 2265 
 2266 // Advertise here if the CPU requires explicit rounding operations to
 2267 // implement the UseStrictFP mode.
 2268 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2269 
 2270 // Are floats converted to double when stored to stack during
 2271 // deoptimization?
 2272 bool Matcher::float_in_double() { return false; }
 2273 
 2274 // Do ints take an entire long register or just half?
 2275 // The relevant question is how the int is callee-saved:
 2276 // the whole long is written but de-opt&#39;ing will have to extract
 2277 // the relevant 32 bits.
 2278 const bool Matcher::int_in_long = true;
 2279 
 2280 // Return whether or not this register is ever used as an argument.
 2281 // This function is used on startup to build the trampoline stubs in
 2282 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2283 // call in the trampoline, and arguments in those registers not be
 2284 // available to the callee.
 2285 bool Matcher::can_be_java_arg(int reg)
 2286 {
 2287   return
 2288     reg ==  R0_num || reg == R0_H_num ||
 2289     reg ==  R1_num || reg == R1_H_num ||
 2290     reg ==  R2_num || reg == R2_H_num ||
 2291     reg ==  R3_num || reg == R3_H_num ||
 2292     reg ==  R4_num || reg == R4_H_num ||
 2293     reg ==  R5_num || reg == R5_H_num ||
 2294     reg ==  R6_num || reg == R6_H_num ||
 2295     reg ==  R7_num || reg == R7_H_num ||
 2296     reg ==  V0_num || reg == V0_H_num ||
 2297     reg ==  V1_num || reg == V1_H_num ||
 2298     reg ==  V2_num || reg == V2_H_num ||
 2299     reg ==  V3_num || reg == V3_H_num ||
 2300     reg ==  V4_num || reg == V4_H_num ||
 2301     reg ==  V5_num || reg == V5_H_num ||
 2302     reg ==  V6_num || reg == V6_H_num ||
 2303     reg ==  V7_num || reg == V7_H_num;
 2304 }
 2305 
 2306 bool Matcher::is_spillable_arg(int reg)
 2307 {
 2308   return can_be_java_arg(reg);
 2309 }
 2310 
 2311 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2312   return false;
 2313 }
 2314 
 2315 RegMask Matcher::divI_proj_mask() {
 2316   ShouldNotReachHere();
 2317   return RegMask();
 2318 }
 2319 
 2320 // Register for MODI projection of divmodI.
 2321 RegMask Matcher::modI_proj_mask() {
 2322   ShouldNotReachHere();
 2323   return RegMask();
 2324 }
 2325 
 2326 // Register for DIVL projection of divmodL.
 2327 RegMask Matcher::divL_proj_mask() {
 2328   ShouldNotReachHere();
 2329   return RegMask();
 2330 }
 2331 
 2332 // Register for MODL projection of divmodL.
 2333 RegMask Matcher::modL_proj_mask() {
 2334   ShouldNotReachHere();
 2335   return RegMask();
 2336 }
 2337 
 2338 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2339   return FP_REG_mask();
 2340 }
 2341 
 2342 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2343   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2344     Node* u = addp-&gt;fast_out(i);
 2345     if (u-&gt;is_Mem()) {
 2346       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2347       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2348       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2349         return false;
 2350       }
 2351     }
 2352   }
 2353   return true;
 2354 }
 2355 
 2356 const bool Matcher::convi2l_type_required = false;
 2357 
 2358 // Should the Matcher clone shifts on addressing modes, expecting them
 2359 // to be subsumed into complex addressing expressions or compute them
 2360 // into registers?
 2361 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2362   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2363     return true;
 2364   }
 2365 
 2366   Node *off = m-&gt;in(AddPNode::Offset);
 2367   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2368       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2369       // Are there other uses besides address expressions?
 2370       !is_visited(off)) {
 2371     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2372     mstack.push(off-&gt;in(2), Visit);
 2373     Node *conv = off-&gt;in(1);
 2374     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2375         // Are there other uses besides address expressions?
 2376         !is_visited(conv)) {
 2377       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2378       mstack.push(conv-&gt;in(1), Pre_Visit);
 2379     } else {
 2380       mstack.push(conv, Pre_Visit);
 2381     }
 2382     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2383     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2384     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2385     return true;
 2386   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2387              // Are there other uses besides address expressions?
 2388              !is_visited(off)) {
 2389     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2390     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2391     mstack.push(off-&gt;in(1), Pre_Visit);
 2392     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2393     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2394     return true;
 2395   }
 2396   return false;
 2397 }
 2398 
 2399 void Compile::reshape_address(AddPNode* addp) {
 2400 }
 2401 
 2402 
 2403 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2404   MacroAssembler _masm(&amp;cbuf);                                          \
 2405   {                                                                     \
 2406     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2407     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2408     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2409     __ INSN(REG, as_Register(BASE));                                    \
 2410   }
 2411 
 2412 
 2413 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2414   {
 2415     Address::extend scale;
 2416 
 2417     // Hooboy, this is fugly.  We need a way to communicate to the
 2418     // encoder that the index needs to be sign extended, so we have to
 2419     // enumerate all the cases.
 2420     switch (opcode) {
 2421     case INDINDEXSCALEDI2L:
 2422     case INDINDEXSCALEDI2LN:
 2423     case INDINDEXI2L:
 2424     case INDINDEXI2LN:
 2425       scale = Address::sxtw(size);
 2426       break;
 2427     default:
 2428       scale = Address::lsl(size);
 2429     }
 2430 
 2431     if (index == -1) {
 2432       return Address(base, disp);
 2433     } else {
 2434       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2435       return Address(base, as_Register(index), scale);
 2436     }
 2437   }
 2438 
 2439 
 2440 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2441 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2442 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2443 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2444                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2445 
 2446   // Used for all non-volatile memory accesses.  The use of
 2447   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2448   // offsets is something of a kludge.
 2449   static void loadStore(MacroAssembler masm, mem_insn insn,
 2450                         Register reg, int opcode,
 2451                         Register base, int index, int scale, int disp,
 2452                         int size_in_memory)
 2453   {
 2454     Address addr = mem2address(opcode, base, index, scale, disp);
 2455     if (addr.getMode() == Address::base_plus_offset) {
 2456       /* If we get an out-of-range offset it is a bug in the compiler,
 2457          so we assert here. */
 2458       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2459              &quot;c2 compiler bug&quot;);
 2460       /* Fix up any out-of-range offsets. */
 2461       assert_different_registers(rscratch1, base);
 2462       assert_different_registers(rscratch1, reg);
 2463       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2464     }
 2465     (masm.*insn)(reg, addr);
 2466   }
 2467 
 2468   static void loadStore(MacroAssembler masm, mem_float_insn insn,
 2469                         FloatRegister reg, int opcode,
 2470                         Register base, int index, int size, int disp,
 2471                         int size_in_memory)
 2472   {
 2473     Address::extend scale;
 2474 
 2475     switch (opcode) {
 2476     case INDINDEXSCALEDI2L:
 2477     case INDINDEXSCALEDI2LN:
 2478       scale = Address::sxtw(size);
 2479       break;
 2480     default:
 2481       scale = Address::lsl(size);
 2482     }
 2483 
 2484     if (index == -1) {
 2485       /* If we get an out-of-range offset it is a bug in the compiler,
 2486          so we assert here. */
 2487       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2488       /* Fix up any out-of-range offsets. */
 2489       assert_different_registers(rscratch1, base);
 2490       Address addr = Address(base, disp);
 2491       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2492       (masm.*insn)(reg, addr);
 2493     } else {
 2494       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2495       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2496     }
 2497   }
 2498 
 2499   static void loadStore(MacroAssembler masm, mem_vector_insn insn,
 2500                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2501                         int opcode, Register base, int index, int size, int disp)
 2502   {
 2503     if (index == -1) {
 2504       (masm.*insn)(reg, T, Address(base, disp));
 2505     } else {
 2506       assert(disp == 0, &quot;unsupported address mode&quot;);
 2507       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2508     }
 2509   }
 2510 
 2511 %}
 2512 
 2513 
 2514 
 2515 //----------ENCODING BLOCK-----------------------------------------------------
 2516 // This block specifies the encoding classes used by the compiler to
 2517 // output byte streams.  Encoding classes are parameterized macros
 2518 // used by Machine Instruction Nodes in order to generate the bit
 2519 // encoding of the instruction.  Operands specify their base encoding
 2520 // interface with the interface keyword.  There are currently
 2521 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2522 // COND_INTER.  REG_INTER causes an operand to generate a function
 2523 // which returns its register number when queried.  CONST_INTER causes
 2524 // an operand to generate a function which returns the value of the
 2525 // constant when queried.  MEMORY_INTER causes an operand to generate
 2526 // four functions which return the Base Register, the Index Register,
 2527 // the Scale Value, and the Offset Value of the operand when queried.
 2528 // COND_INTER causes an operand to generate six functions which return
 2529 // the encoding code (ie - encoding bits for the instruction)
 2530 // associated with each basic boolean condition for a conditional
 2531 // instruction.
 2532 //
 2533 // Instructions specify two basic values for encoding.  Again, a
 2534 // function is available to check if the constant displacement is an
 2535 // oop. They use the ins_encode keyword to specify their encoding
 2536 // classes (which must be a sequence of enc_class names, and their
 2537 // parameters, specified in the encoding block), and they use the
 2538 // opcode keyword to specify, in order, their primary, secondary, and
 2539 // tertiary opcode.  Only the opcode sections which a particular
 2540 // instruction needs for encoding need to be specified.
 2541 encode %{
 2542   // Build emit functions for each basic byte or larger field in the
 2543   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2544   // from C++ code in the enc_class source block.  Emit functions will
 2545   // live in the main source block for now.  In future, we can
 2546   // generalize this by adding a syntax that specifies the sizes of
 2547   // fields in an order, so that the adlc can build the emit functions
 2548   // automagically
 2549 
 2550   // catch all for unimplemented encodings
 2551   enc_class enc_unimplemented %{
 2552     MacroAssembler _masm(&amp;cbuf);
 2553     __ unimplemented(&quot;C2 catch all&quot;);
 2554   %}
 2555 
 2556   // BEGIN Non-volatile memory access
 2557 
 2558   // This encoding class is generated automatically from ad_encode.m4.
 2559   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2560   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2561     Register dst_reg = as_Register($dst$$reg);
 2562     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2563                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2564   %}
 2565 
 2566   // This encoding class is generated automatically from ad_encode.m4.
 2567   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2568   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2569     Register dst_reg = as_Register($dst$$reg);
 2570     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2571                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2572   %}
 2573 
 2574   // This encoding class is generated automatically from ad_encode.m4.
 2575   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2576   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2577     Register dst_reg = as_Register($dst$$reg);
 2578     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2579                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2580   %}
 2581 
 2582   // This encoding class is generated automatically from ad_encode.m4.
 2583   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2584   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2585     Register dst_reg = as_Register($dst$$reg);
 2586     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2587                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2588   %}
 2589 
 2590   // This encoding class is generated automatically from ad_encode.m4.
 2591   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2592   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2593     Register dst_reg = as_Register($dst$$reg);
 2594     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2595                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2596   %}
 2597 
 2598   // This encoding class is generated automatically from ad_encode.m4.
 2599   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2600   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2601     Register dst_reg = as_Register($dst$$reg);
 2602     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2603                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2604   %}
 2605 
 2606   // This encoding class is generated automatically from ad_encode.m4.
 2607   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2608   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2609     Register dst_reg = as_Register($dst$$reg);
 2610     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2611                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2612   %}
 2613 
 2614   // This encoding class is generated automatically from ad_encode.m4.
 2615   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2616   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2617     Register dst_reg = as_Register($dst$$reg);
 2618     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2619                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2620   %}
 2621 
 2622   // This encoding class is generated automatically from ad_encode.m4.
 2623   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2624   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2625     Register dst_reg = as_Register($dst$$reg);
 2626     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2627                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2628   %}
 2629 
 2630   // This encoding class is generated automatically from ad_encode.m4.
 2631   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2632   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2633     Register dst_reg = as_Register($dst$$reg);
 2634     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2635                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2636   %}
 2637 
 2638   // This encoding class is generated automatically from ad_encode.m4.
 2639   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2640   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2641     Register dst_reg = as_Register($dst$$reg);
 2642     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2643                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2644   %}
 2645 
 2646   // This encoding class is generated automatically from ad_encode.m4.
 2647   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2648   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2649     Register dst_reg = as_Register($dst$$reg);
 2650     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2651                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2652   %}
 2653 
 2654   // This encoding class is generated automatically from ad_encode.m4.
 2655   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2656   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2657     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2658     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2659                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2660   %}
 2661 
 2662   // This encoding class is generated automatically from ad_encode.m4.
 2663   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2664   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2665     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2666     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2667                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2668   %}
 2669 
 2670   // This encoding class is generated automatically from ad_encode.m4.
 2671   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2672   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2673     Register src_reg = as_Register($src$$reg);
 2674     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2675                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2676   %}
 2677 
 2678   // This encoding class is generated automatically from ad_encode.m4.
 2679   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2680   enc_class aarch64_enc_strb0(memory1 mem) %{
 2681     MacroAssembler _masm(&amp;cbuf);
 2682     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2683                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2684   %}
 2685 
 2686   // This encoding class is generated automatically from ad_encode.m4.
 2687   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2688   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2689     Register src_reg = as_Register($src$$reg);
 2690     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2691                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2692   %}
 2693 
 2694   // This encoding class is generated automatically from ad_encode.m4.
 2695   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2696   enc_class aarch64_enc_strh0(memory2 mem) %{
 2697     MacroAssembler _masm(&amp;cbuf);
 2698     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2699                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2700   %}
 2701 
 2702   // This encoding class is generated automatically from ad_encode.m4.
 2703   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2704   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2705     Register src_reg = as_Register($src$$reg);
 2706     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2707                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2708   %}
 2709 
 2710   // This encoding class is generated automatically from ad_encode.m4.
 2711   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2712   enc_class aarch64_enc_strw0(memory4 mem) %{
 2713     MacroAssembler _masm(&amp;cbuf);
 2714     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2715                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2716   %}
 2717 
 2718   // This encoding class is generated automatically from ad_encode.m4.
 2719   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2720   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2721     Register src_reg = as_Register($src$$reg);
 2722     // we sometimes get asked to store the stack pointer into the
 2723     // current thread -- we cannot do that directly on AArch64
 2724     if (src_reg == r31_sp) {
 2725       MacroAssembler _masm(&amp;cbuf);
 2726       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2727       __ mov(rscratch2, sp);
 2728       src_reg = rscratch2;
 2729     }
 2730     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2731                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2732   %}
 2733 
 2734   // This encoding class is generated automatically from ad_encode.m4.
 2735   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2736   enc_class aarch64_enc_str0(memory8 mem) %{
 2737     MacroAssembler _masm(&amp;cbuf);
 2738     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2739                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2740   %}
 2741 
 2742   // This encoding class is generated automatically from ad_encode.m4.
 2743   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2744   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2745     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2746     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2747                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2748   %}
 2749 
 2750   // This encoding class is generated automatically from ad_encode.m4.
 2751   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2752   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2753     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2754     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2755                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2756   %}
 2757 
 2758   // This encoding class is generated automatically from ad_encode.m4.
 2759   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2760   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2761     MacroAssembler _masm(&amp;cbuf);
 2762     address con = (address)$src$$constant;
 2763     // need to do this the hard way until we can manage relocs
 2764     // for 32 bit constants
 2765     __ movoop(rscratch2, (jobject)con);
 2766     if (con) __ encode_heap_oop_not_null(rscratch2);
 2767     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2768                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2769   %}
 2770 
 2771   // This encoding class is generated automatically from ad_encode.m4.
 2772   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2773   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2774     MacroAssembler _masm(&amp;cbuf);
 2775     address con = (address)$src$$constant;
 2776     // need to do this the hard way until we can manage relocs
 2777     // for 32 bit constants
 2778     __ movoop(rscratch2, (jobject)con);
 2779     __ encode_klass_not_null(rscratch2);
 2780     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2781                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2782   %}
 2783 
 2784   // This encoding class is generated automatically from ad_encode.m4.
 2785   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2786   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2787       MacroAssembler _masm(&amp;cbuf);
 2788       __ membar(Assembler::StoreStore);
 2789       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2790                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2791   %}
 2792 
 2793   // END Non-volatile memory access
 2794 
 2795   // Vector loads and stores
 2796   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2797     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2798     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2799        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2800   %}
 2801 
 2802   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2803     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2804     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2805        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2806   %}
 2807 
 2808   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2809     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2810     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2811        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2812   %}
 2813 
 2814   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2815     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2816     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2817        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2818   %}
 2819 
 2820   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2821     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2822     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2823        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2824   %}
 2825 
 2826   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2827     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2828     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2829        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2830   %}
 2831 
 2832   // volatile loads and stores
 2833 
 2834   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2835     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2836                  rscratch1, stlrb);
 2837   %}
 2838 
 2839   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2840     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2841                  rscratch1, stlrh);
 2842   %}
 2843 
 2844   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2845     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2846                  rscratch1, stlrw);
 2847   %}
 2848 
 2849 
 2850   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2851     Register dst_reg = as_Register($dst$$reg);
 2852     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2853              rscratch1, ldarb);
 2854     __ sxtbw(dst_reg, dst_reg);
 2855   %}
 2856 
 2857   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2858     Register dst_reg = as_Register($dst$$reg);
 2859     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2860              rscratch1, ldarb);
 2861     __ sxtb(dst_reg, dst_reg);
 2862   %}
 2863 
 2864   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2865     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2866              rscratch1, ldarb);
 2867   %}
 2868 
 2869   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2870     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2871              rscratch1, ldarb);
 2872   %}
 2873 
 2874   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2875     Register dst_reg = as_Register($dst$$reg);
 2876     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2877              rscratch1, ldarh);
 2878     __ sxthw(dst_reg, dst_reg);
 2879   %}
 2880 
 2881   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2882     Register dst_reg = as_Register($dst$$reg);
 2883     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2884              rscratch1, ldarh);
 2885     __ sxth(dst_reg, dst_reg);
 2886   %}
 2887 
 2888   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2889     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2890              rscratch1, ldarh);
 2891   %}
 2892 
 2893   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2894     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2895              rscratch1, ldarh);
 2896   %}
 2897 
 2898   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2899     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2900              rscratch1, ldarw);
 2901   %}
 2902 
 2903   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2904     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2905              rscratch1, ldarw);
 2906   %}
 2907 
 2908   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2909     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2910              rscratch1, ldar);
 2911   %}
 2912 
 2913   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2914     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2915              rscratch1, ldarw);
 2916     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2917   %}
 2918 
 2919   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2920     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2921              rscratch1, ldar);
 2922     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2923   %}
 2924 
 2925   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2926     Register src_reg = as_Register($src$$reg);
 2927     // we sometimes get asked to store the stack pointer into the
 2928     // current thread -- we cannot do that directly on AArch64
 2929     if (src_reg == r31_sp) {
 2930         MacroAssembler _masm(&amp;cbuf);
 2931       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2932       __ mov(rscratch2, sp);
 2933       src_reg = rscratch2;
 2934     }
 2935     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2936                  rscratch1, stlr);
 2937   %}
 2938 
 2939   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2940     {
 2941       MacroAssembler _masm(&amp;cbuf);
 2942       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2943       __ fmovs(rscratch2, src_reg);
 2944     }
 2945     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2946                  rscratch1, stlrw);
 2947   %}
 2948 
 2949   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2950     {
 2951       MacroAssembler _masm(&amp;cbuf);
 2952       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2953       __ fmovd(rscratch2, src_reg);
 2954     }
 2955     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2956                  rscratch1, stlr);
 2957   %}
 2958 
 2959   // synchronized read/update encodings
 2960 
 2961   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2962     MacroAssembler _masm(&amp;cbuf);
 2963     Register dst_reg = as_Register($dst$$reg);
 2964     Register base = as_Register($mem$$base);
 2965     int index = $mem$$index;
 2966     int scale = $mem$$scale;
 2967     int disp = $mem$$disp;
 2968     if (index == -1) {
 2969        if (disp != 0) {
 2970         __ lea(rscratch1, Address(base, disp));
 2971         __ ldaxr(dst_reg, rscratch1);
 2972       } else {
 2973         // TODO
 2974         // should we ever get anything other than this case?
 2975         __ ldaxr(dst_reg, base);
 2976       }
 2977     } else {
 2978       Register index_reg = as_Register(index);
 2979       if (disp == 0) {
 2980         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2981         __ ldaxr(dst_reg, rscratch1);
 2982       } else {
 2983         __ lea(rscratch1, Address(base, disp));
 2984         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 2985         __ ldaxr(dst_reg, rscratch1);
 2986       }
 2987     }
 2988   %}
 2989 
 2990   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 2991     MacroAssembler _masm(&amp;cbuf);
 2992     Register src_reg = as_Register($src$$reg);
 2993     Register base = as_Register($mem$$base);
 2994     int index = $mem$$index;
 2995     int scale = $mem$$scale;
 2996     int disp = $mem$$disp;
 2997     if (index == -1) {
 2998        if (disp != 0) {
 2999         __ lea(rscratch2, Address(base, disp));
 3000         __ stlxr(rscratch1, src_reg, rscratch2);
 3001       } else {
 3002         // TODO
 3003         // should we ever get anything other than this case?
 3004         __ stlxr(rscratch1, src_reg, base);
 3005       }
 3006     } else {
 3007       Register index_reg = as_Register(index);
 3008       if (disp == 0) {
 3009         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3010         __ stlxr(rscratch1, src_reg, rscratch2);
 3011       } else {
 3012         __ lea(rscratch2, Address(base, disp));
 3013         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3014         __ stlxr(rscratch1, src_reg, rscratch2);
 3015       }
 3016     }
 3017     __ cmpw(rscratch1, zr);
 3018   %}
 3019 
 3020   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3021     MacroAssembler _masm(&amp;cbuf);
 3022     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3023     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3024                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3025                /*weak*/ false, noreg);
 3026   %}
 3027 
 3028   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3029     MacroAssembler _masm(&amp;cbuf);
 3030     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3031     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3032                Assembler::word, /*acquire*/ false, /*release*/ true,
 3033                /*weak*/ false, noreg);
 3034   %}
 3035 
 3036   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3037     MacroAssembler _masm(&amp;cbuf);
 3038     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3039     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3040                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3041                /*weak*/ false, noreg);
 3042   %}
 3043 
 3044   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3045     MacroAssembler _masm(&amp;cbuf);
 3046     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3047     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3048                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3049                /*weak*/ false, noreg);
 3050   %}
 3051 
 3052 
 3053   // The only difference between aarch64_enc_cmpxchg and
 3054   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3055   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3056   // lock.
 3057   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3058     MacroAssembler _masm(&amp;cbuf);
 3059     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3060     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3061                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3062                /*weak*/ false, noreg);
 3063   %}
 3064 
 3065   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3066     MacroAssembler _masm(&amp;cbuf);
 3067     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3068     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3069                Assembler::word, /*acquire*/ true, /*release*/ true,
 3070                /*weak*/ false, noreg);
 3071   %}
 3072 
 3073   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3074     MacroAssembler _masm(&amp;cbuf);
 3075     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3076     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3077                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3078                /*weak*/ false, noreg);
 3079   %}
 3080 
 3081   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3082     MacroAssembler _masm(&amp;cbuf);
 3083     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3084     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3085                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3086                /*weak*/ false, noreg);
 3087   %}
 3088 
 3089   // auxiliary used for CompareAndSwapX to set result register
 3090   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3091     MacroAssembler _masm(&amp;cbuf);
 3092     Register res_reg = as_Register($res$$reg);
 3093     __ cset(res_reg, Assembler::EQ);
 3094   %}
 3095 
 3096   // prefetch encodings
 3097 
 3098   enc_class aarch64_enc_prefetchw(memory mem) %{
 3099     MacroAssembler _masm(&amp;cbuf);
 3100     Register base = as_Register($mem$$base);
 3101     int index = $mem$$index;
 3102     int scale = $mem$$scale;
 3103     int disp = $mem$$disp;
 3104     if (index == -1) {
 3105       __ prfm(Address(base, disp), PSTL1KEEP);
 3106     } else {
 3107       Register index_reg = as_Register(index);
 3108       if (disp == 0) {
 3109         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3110       } else {
 3111         __ lea(rscratch1, Address(base, disp));
 3112 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3113       }
 3114     }
 3115   %}
 3116 
 3117   /// mov envcodings
 3118 
 3119   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3120     MacroAssembler _masm(&amp;cbuf);
<a name="4" id="anc4"></a><span class="line-modified"> 3121     uint32_t con = (uint32_t)$src$$constant;</span>
 3122     Register dst_reg = as_Register($dst$$reg);
 3123     if (con == 0) {
 3124       __ movw(dst_reg, zr);
 3125     } else {
 3126       __ movw(dst_reg, con);
 3127     }
 3128   %}
 3129 
 3130   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3131     MacroAssembler _masm(&amp;cbuf);
 3132     Register dst_reg = as_Register($dst$$reg);
<a name="5" id="anc5"></a><span class="line-modified"> 3133     uint64_t con = (uint64_t)$src$$constant;</span>
 3134     if (con == 0) {
 3135       __ mov(dst_reg, zr);
 3136     } else {
 3137       __ mov(dst_reg, con);
 3138     }
 3139   %}
 3140 
 3141   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3142     MacroAssembler _masm(&amp;cbuf);
 3143     Register dst_reg = as_Register($dst$$reg);
 3144     address con = (address)$src$$constant;
 3145     if (con == NULL || con == (address)1) {
 3146       ShouldNotReachHere();
 3147     } else {
 3148       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3149       if (rtype == relocInfo::oop_type) {
 3150         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3151       } else if (rtype == relocInfo::metadata_type) {
 3152         __ mov_metadata(dst_reg, (Metadata*)con);
 3153       } else {
 3154         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3155         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3156           __ mov(dst_reg, con);
 3157         } else {
<a name="6" id="anc6"></a><span class="line-modified"> 3158           uint64_t offset;</span>
 3159           __ adrp(dst_reg, con, offset);
 3160           __ add(dst_reg, dst_reg, offset);
 3161         }
 3162       }
 3163     }
 3164   %}
 3165 
 3166   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3167     MacroAssembler _masm(&amp;cbuf);
 3168     Register dst_reg = as_Register($dst$$reg);
 3169     __ mov(dst_reg, zr);
 3170   %}
 3171 
 3172   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3173     MacroAssembler _masm(&amp;cbuf);
 3174     Register dst_reg = as_Register($dst$$reg);
<a name="7" id="anc7"></a><span class="line-modified"> 3175     __ mov(dst_reg, (uint64_t)1);</span>
 3176   %}
 3177 
 3178   enc_class aarch64_enc_mov_poll_page(iRegP dst, immPollPage src) %{
 3179     MacroAssembler _masm(&amp;cbuf);
 3180     address page = (address)$src$$constant;
 3181     Register dst_reg = as_Register($dst$$reg);
<a name="8" id="anc8"></a><span class="line-modified"> 3182     uint64_t off;</span>
 3183     __ adrp(dst_reg, Address(page, relocInfo::poll_type), off);
 3184     assert(off == 0, &quot;assumed offset == 0&quot;);
 3185   %}
 3186 
 3187   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3188     MacroAssembler _masm(&amp;cbuf);
 3189     __ load_byte_map_base($dst$$Register);
 3190   %}
 3191 
 3192   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3193     MacroAssembler _masm(&amp;cbuf);
 3194     Register dst_reg = as_Register($dst$$reg);
 3195     address con = (address)$src$$constant;
 3196     if (con == NULL) {
 3197       ShouldNotReachHere();
 3198     } else {
 3199       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3200       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3201       __ set_narrow_oop(dst_reg, (jobject)con);
 3202     }
 3203   %}
 3204 
 3205   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3206     MacroAssembler _masm(&amp;cbuf);
 3207     Register dst_reg = as_Register($dst$$reg);
 3208     __ mov(dst_reg, zr);
 3209   %}
 3210 
 3211   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3212     MacroAssembler _masm(&amp;cbuf);
 3213     Register dst_reg = as_Register($dst$$reg);
 3214     address con = (address)$src$$constant;
 3215     if (con == NULL) {
 3216       ShouldNotReachHere();
 3217     } else {
 3218       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3219       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3220       __ set_narrow_klass(dst_reg, (Klass *)con);
 3221     }
 3222   %}
 3223 
 3224   // arithmetic encodings
 3225 
 3226   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3227     MacroAssembler _masm(&amp;cbuf);
 3228     Register dst_reg = as_Register($dst$$reg);
 3229     Register src_reg = as_Register($src1$$reg);
 3230     int32_t con = (int32_t)$src2$$constant;
 3231     // add has primary == 0, subtract has primary == 1
 3232     if ($primary) { con = -con; }
 3233     if (con &lt; 0) {
 3234       __ subw(dst_reg, src_reg, -con);
 3235     } else {
 3236       __ addw(dst_reg, src_reg, con);
 3237     }
 3238   %}
 3239 
 3240   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3241     MacroAssembler _masm(&amp;cbuf);
 3242     Register dst_reg = as_Register($dst$$reg);
 3243     Register src_reg = as_Register($src1$$reg);
 3244     int32_t con = (int32_t)$src2$$constant;
 3245     // add has primary == 0, subtract has primary == 1
 3246     if ($primary) { con = -con; }
 3247     if (con &lt; 0) {
 3248       __ sub(dst_reg, src_reg, -con);
 3249     } else {
 3250       __ add(dst_reg, src_reg, con);
 3251     }
 3252   %}
 3253 
 3254   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3255     MacroAssembler _masm(&amp;cbuf);
 3256    Register dst_reg = as_Register($dst$$reg);
 3257    Register src1_reg = as_Register($src1$$reg);
 3258    Register src2_reg = as_Register($src2$$reg);
 3259     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3260   %}
 3261 
 3262   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3263     MacroAssembler _masm(&amp;cbuf);
 3264    Register dst_reg = as_Register($dst$$reg);
 3265    Register src1_reg = as_Register($src1$$reg);
 3266    Register src2_reg = as_Register($src2$$reg);
 3267     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3268   %}
 3269 
 3270   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3271     MacroAssembler _masm(&amp;cbuf);
 3272    Register dst_reg = as_Register($dst$$reg);
 3273    Register src1_reg = as_Register($src1$$reg);
 3274    Register src2_reg = as_Register($src2$$reg);
 3275     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3276   %}
 3277 
 3278   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3279     MacroAssembler _masm(&amp;cbuf);
 3280    Register dst_reg = as_Register($dst$$reg);
 3281    Register src1_reg = as_Register($src1$$reg);
 3282    Register src2_reg = as_Register($src2$$reg);
 3283     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3284   %}
 3285 
 3286   // compare instruction encodings
 3287 
 3288   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3289     MacroAssembler _masm(&amp;cbuf);
 3290     Register reg1 = as_Register($src1$$reg);
 3291     Register reg2 = as_Register($src2$$reg);
 3292     __ cmpw(reg1, reg2);
 3293   %}
 3294 
 3295   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3296     MacroAssembler _masm(&amp;cbuf);
 3297     Register reg = as_Register($src1$$reg);
 3298     int32_t val = $src2$$constant;
 3299     if (val &gt;= 0) {
 3300       __ subsw(zr, reg, val);
 3301     } else {
 3302       __ addsw(zr, reg, -val);
 3303     }
 3304   %}
 3305 
 3306   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3307     MacroAssembler _masm(&amp;cbuf);
 3308     Register reg1 = as_Register($src1$$reg);
<a name="9" id="anc9"></a><span class="line-modified"> 3309     uint32_t val = (uint32_t)$src2$$constant;</span>
 3310     __ movw(rscratch1, val);
 3311     __ cmpw(reg1, rscratch1);
 3312   %}
 3313 
 3314   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3315     MacroAssembler _masm(&amp;cbuf);
 3316     Register reg1 = as_Register($src1$$reg);
 3317     Register reg2 = as_Register($src2$$reg);
 3318     __ cmp(reg1, reg2);
 3319   %}
 3320 
 3321   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3322     MacroAssembler _masm(&amp;cbuf);
 3323     Register reg = as_Register($src1$$reg);
 3324     int64_t val = $src2$$constant;
 3325     if (val &gt;= 0) {
 3326       __ subs(zr, reg, val);
 3327     } else if (val != -val) {
 3328       __ adds(zr, reg, -val);
 3329     } else {
 3330     // aargh, Long.MIN_VALUE is a special case
<a name="10" id="anc10"></a><span class="line-modified"> 3331       __ orr(rscratch1, zr, (uint64_t)val);</span>
 3332       __ subs(zr, reg, rscratch1);
 3333     }
 3334   %}
 3335 
 3336   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3337     MacroAssembler _masm(&amp;cbuf);
 3338     Register reg1 = as_Register($src1$$reg);
<a name="11" id="anc11"></a><span class="line-modified"> 3339     uint64_t val = (uint64_t)$src2$$constant;</span>
 3340     __ mov(rscratch1, val);
 3341     __ cmp(reg1, rscratch1);
 3342   %}
 3343 
 3344   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3345     MacroAssembler _masm(&amp;cbuf);
 3346     Register reg1 = as_Register($src1$$reg);
 3347     Register reg2 = as_Register($src2$$reg);
 3348     __ cmp(reg1, reg2);
 3349   %}
 3350 
 3351   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3352     MacroAssembler _masm(&amp;cbuf);
 3353     Register reg1 = as_Register($src1$$reg);
 3354     Register reg2 = as_Register($src2$$reg);
 3355     __ cmpw(reg1, reg2);
 3356   %}
 3357 
 3358   enc_class aarch64_enc_testp(iRegP src) %{
 3359     MacroAssembler _masm(&amp;cbuf);
 3360     Register reg = as_Register($src$$reg);
 3361     __ cmp(reg, zr);
 3362   %}
 3363 
 3364   enc_class aarch64_enc_testn(iRegN src) %{
 3365     MacroAssembler _masm(&amp;cbuf);
 3366     Register reg = as_Register($src$$reg);
 3367     __ cmpw(reg, zr);
 3368   %}
 3369 
 3370   enc_class aarch64_enc_b(label lbl) %{
 3371     MacroAssembler _masm(&amp;cbuf);
 3372     Label *L = $lbl$$label;
 3373     __ b(*L);
 3374   %}
 3375 
 3376   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3377     MacroAssembler _masm(&amp;cbuf);
 3378     Label *L = $lbl$$label;
 3379     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3380   %}
 3381 
 3382   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3383     MacroAssembler _masm(&amp;cbuf);
 3384     Label *L = $lbl$$label;
 3385     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3386   %}
 3387 
 3388   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3389   %{
 3390      Register sub_reg = as_Register($sub$$reg);
 3391      Register super_reg = as_Register($super$$reg);
 3392      Register temp_reg = as_Register($temp$$reg);
 3393      Register result_reg = as_Register($result$$reg);
 3394 
 3395      Label miss;
 3396      MacroAssembler _masm(&amp;cbuf);
 3397      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3398                                      NULL, &amp;miss,
 3399                                      /*set_cond_codes:*/ true);
 3400      if ($primary) {
 3401        __ mov(result_reg, zr);
 3402      }
 3403      __ bind(miss);
 3404   %}
 3405 
 3406   enc_class aarch64_enc_java_static_call(method meth) %{
 3407     MacroAssembler _masm(&amp;cbuf);
 3408 
 3409     address addr = (address)$meth$$method;
 3410     address call;
 3411     if (!_method) {
 3412       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3413       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3414     } else {
 3415       int method_index = resolved_method_index(cbuf);
 3416       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3417                                                   : static_call_Relocation::spec(method_index);
 3418       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3419 
 3420       // Emit stub for static call
 3421       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3422       if (stub == NULL) {
 3423         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3424         return;
 3425       }
 3426     }
 3427     if (call == NULL) {
 3428       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3429       return;
 3430     }
 3431   %}
 3432 
 3433   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3434     MacroAssembler _masm(&amp;cbuf);
 3435     int method_index = resolved_method_index(cbuf);
 3436     address call = __ ic_call((address)$meth$$method, method_index);
 3437     if (call == NULL) {
 3438       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3439       return;
 3440     }
 3441   %}
 3442 
 3443   enc_class aarch64_enc_call_epilog() %{
 3444     MacroAssembler _masm(&amp;cbuf);
 3445     if (VerifyStackAtCalls) {
 3446       // Check that stack depth is unchanged: find majik cookie on stack
 3447       __ call_Unimplemented();
 3448     }
 3449   %}
 3450 
 3451   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3452     MacroAssembler _masm(&amp;cbuf);
 3453 
 3454     // some calls to generated routines (arraycopy code) are scheduled
 3455     // by C2 as runtime calls. if so we can call them using a br (they
 3456     // will be in a reachable segment) otherwise we have to use a blr
 3457     // which loads the absolute address into a register.
 3458     address entry = (address)$meth$$method;
 3459     CodeBlob *cb = CodeCache::find_blob(entry);
 3460     if (cb) {
 3461       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3462       if (call == NULL) {
 3463         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3464         return;
 3465       }
 3466     } else {
 3467       Label retaddr;
 3468       __ adr(rscratch2, retaddr);
 3469       __ lea(rscratch1, RuntimeAddress(entry));
 3470       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3471       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3472       __ blr(rscratch1);
 3473       __ bind(retaddr);
 3474       __ add(sp, sp, 2 * wordSize);
 3475     }
 3476   %}
 3477 
 3478   enc_class aarch64_enc_rethrow() %{
 3479     MacroAssembler _masm(&amp;cbuf);
 3480     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3481   %}
 3482 
 3483   enc_class aarch64_enc_ret() %{
 3484     MacroAssembler _masm(&amp;cbuf);
 3485     __ ret(lr);
 3486   %}
 3487 
 3488   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3489     MacroAssembler _masm(&amp;cbuf);
 3490     Register target_reg = as_Register($jump_target$$reg);
 3491     __ br(target_reg);
 3492   %}
 3493 
 3494   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3495     MacroAssembler _masm(&amp;cbuf);
 3496     Register target_reg = as_Register($jump_target$$reg);
 3497     // exception oop should be in r0
 3498     // ret addr has been popped into lr
 3499     // callee expects it in r3
 3500     __ mov(r3, lr);
 3501     __ br(target_reg);
 3502   %}
 3503 
 3504   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3505     MacroAssembler _masm(&amp;cbuf);
 3506     Register oop = as_Register($object$$reg);
 3507     Register box = as_Register($box$$reg);
 3508     Register disp_hdr = as_Register($tmp$$reg);
 3509     Register tmp = as_Register($tmp2$$reg);
 3510     Label cont;
 3511     Label object_has_monitor;
 3512     Label cas_failed;
 3513 
 3514     assert_different_registers(oop, box, tmp, disp_hdr);
 3515 
 3516     // Load markWord from object into displaced_header.
 3517     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3518 
 3519     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3520       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3521     }
 3522 
 3523     // Check for existing monitor
 3524     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3525 
 3526     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3527     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3528 
 3529     // Initialize the box. (Must happen before we update the object mark!)
 3530     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3531 
 3532     // Compare object markWord with an unlocked value (tmp) and if
 3533     // equal exchange the stack address of our box with object markWord.
 3534     // On failure disp_hdr contains the possibly locked markWord.
 3535     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3536                /*release*/ true, /*weak*/ false, disp_hdr);
 3537     __ br(Assembler::EQ, cont);
 3538 
 3539     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3540 
 3541     // If the compare-and-exchange succeeded, then we found an unlocked
 3542     // object, will have now locked it will continue at label cont
 3543 
 3544     __ bind(cas_failed);
 3545     // We did not see an unlocked object so try the fast recursive case.
 3546 
 3547     // Check if the owner is self by comparing the value in the
 3548     // markWord of object (disp_hdr) with the stack pointer.
 3549     __ mov(rscratch1, sp);
 3550     __ sub(disp_hdr, disp_hdr, rscratch1);
 3551     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3552     // If condition is true we are cont and hence we can store 0 as the
 3553     // displaced header in the box, which indicates that it is a recursive lock.
 3554     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3555     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3556 
 3557     __ b(cont);
 3558 
 3559     // Handle existing monitor.
 3560     __ bind(object_has_monitor);
 3561 
 3562     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3563     // otherwise m-&gt;owner may contain a thread or a stack address.
 3564     //
 3565     // Try to CAS m-&gt;owner from NULL to current thread.
 3566     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3567     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3568                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3569 
 3570     // Store a non-null value into the box to avoid looking like a re-entrant
 3571     // lock. The fast-path monitor unlock code checks for
 3572     // markWord::monitor_value so use markWord::unused_mark which has the
 3573     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3574     __ mov(tmp, (address)markWord::unused_mark().value());
 3575     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3576 
 3577     __ bind(cont);
 3578     // flag == EQ indicates success
 3579     // flag == NE indicates failure
 3580   %}
 3581 
 3582   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3583     MacroAssembler _masm(&amp;cbuf);
 3584     Register oop = as_Register($object$$reg);
 3585     Register box = as_Register($box$$reg);
 3586     Register disp_hdr = as_Register($tmp$$reg);
 3587     Register tmp = as_Register($tmp2$$reg);
 3588     Label cont;
 3589     Label object_has_monitor;
 3590 
 3591     assert_different_registers(oop, box, tmp, disp_hdr);
 3592 
 3593     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3594       __ biased_locking_exit(oop, tmp, cont);
 3595     }
 3596 
 3597     // Find the lock address and load the displaced header from the stack.
 3598     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3599 
 3600     // If the displaced header is 0, we have a recursive unlock.
 3601     __ cmp(disp_hdr, zr);
 3602     __ br(Assembler::EQ, cont);
 3603 
 3604     // Handle existing monitor.
 3605     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3606     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3607 
 3608     // Check if it is still a light weight lock, this is is true if we
 3609     // see the stack address of the basicLock in the markWord of the
 3610     // object.
 3611 
 3612     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3613                /*release*/ true, /*weak*/ false, tmp);
 3614     __ b(cont);
 3615 
 3616     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3617 
 3618     // Handle existing monitor.
 3619     __ bind(object_has_monitor);
 3620     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3621     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3622     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3623     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3624     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3625     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3626     __ cmp(rscratch1, zr); // Sets flags for result
 3627     __ br(Assembler::NE, cont);
 3628 
 3629     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3630     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3631     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3632     __ cmp(rscratch1, zr); // Sets flags for result
 3633     __ cbnz(rscratch1, cont);
 3634     // need a release store here
 3635     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3636     __ stlr(zr, tmp); // set unowned
 3637 
 3638     __ bind(cont);
 3639     // flag == EQ indicates success
 3640     // flag == NE indicates failure
 3641   %}
 3642 
 3643 %}
 3644 
 3645 //----------FRAME--------------------------------------------------------------
 3646 // Definition of frame structure and management information.
 3647 //
 3648 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3649 //                             |   (to get allocators register number
 3650 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3651 //  r   CALLER     |        |
 3652 //  o     |        +--------+      pad to even-align allocators stack-slot
 3653 //  w     V        |  pad0  |        numbers; owned by CALLER
 3654 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3655 //  h     ^        |   in   |  5
 3656 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3657 //  |     |        |        |  3
 3658 //  |     |        +--------+
 3659 //  V     |        | old out|      Empty on Intel, window on Sparc
 3660 //        |    old |preserve|      Must be even aligned.
 3661 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3662 //        |        |   in   |  3   area for Intel ret address
 3663 //     Owned by    |preserve|      Empty on Sparc.
 3664 //       SELF      +--------+
 3665 //        |        |  pad2  |  2   pad to align old SP
 3666 //        |        +--------+  1
 3667 //        |        | locks  |  0
 3668 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3669 //        |        |  pad1  | 11   pad to align new SP
 3670 //        |        +--------+
 3671 //        |        |        | 10
 3672 //        |        | spills |  9   spills
 3673 //        V        |        |  8   (pad0 slot for callee)
 3674 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3675 //        ^        |  out   |  7
 3676 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3677 //     Owned by    +--------+
 3678 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3679 //        |    new |preserve|      Must be even-aligned.
 3680 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3681 //        |        |        |
 3682 //
 3683 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3684 //         known from SELF&#39;s arguments and the Java calling convention.
 3685 //         Region 6-7 is determined per call site.
 3686 // Note 2: If the calling convention leaves holes in the incoming argument
 3687 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3688 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3689 //         incoming area, as the Java calling convention is completely under
 3690 //         the control of the AD file.  Doubles can be sorted and packed to
 3691 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3692 //         varargs C calling conventions.
 3693 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3694 //         even aligned with pad0 as needed.
 3695 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3696 //           (the latter is true on Intel but is it false on AArch64?)
 3697 //         region 6-11 is even aligned; it may be padded out more so that
 3698 //         the region from SP to FP meets the minimum stack alignment.
 3699 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3700 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3701 //         SP meets the minimum alignment.
 3702 
 3703 frame %{
 3704   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3705   stack_direction(TOWARDS_LOW);
 3706 
 3707   // These three registers define part of the calling convention
 3708   // between compiled code and the interpreter.
 3709 
 3710   // Inline Cache Register or methodOop for I2C.
 3711   inline_cache_reg(R12);
 3712 
 3713   // Method Oop Register when calling interpreter.
 3714   interpreter_method_oop_reg(R12);
 3715 
 3716   // Number of stack slots consumed by locking an object
 3717   sync_stack_slots(2);
 3718 
 3719   // Compiled code&#39;s Frame Pointer
 3720   frame_pointer(R31);
 3721 
 3722   // Interpreter stores its frame pointer in a register which is
 3723   // stored to the stack by I2CAdaptors.
 3724   // I2CAdaptors convert from interpreted java to compiled java.
 3725   interpreter_frame_pointer(R29);
 3726 
 3727   // Stack alignment requirement
 3728   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3729 
 3730   // Number of stack slots between incoming argument block and the start of
 3731   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3732   // EPILOG must remove this many slots. aarch64 needs two slots for
 3733   // return address and fp.
 3734   // TODO think this is correct but check
 3735   in_preserve_stack_slots(4);
 3736 
 3737   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3738   // for calls to C.  Supports the var-args backing area for register parms.
 3739   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3740 
 3741   // The after-PROLOG location of the return address.  Location of
 3742   // return address specifies a type (REG or STACK) and a number
 3743   // representing the register number (i.e. - use a register name) or
 3744   // stack slot.
 3745   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3746   // Otherwise, it is above the locks and verification slot and alignment word
 3747   // TODO this may well be correct but need to check why that - 2 is there
 3748   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3749   // which folds in the space used for monitors
 3750   return_addr(STACK - 2 +
 3751               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3752                         Compile::current()-&gt;fixed_slots()),
 3753                        stack_alignment_in_slots()));
 3754 
 3755   // Body of function which returns an integer array locating
 3756   // arguments either in registers or in stack slots.  Passed an array
 3757   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3758   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3759   // arguments for a CALLEE.  Incoming stack arguments are
 3760   // automatically biased by the preserve_stack_slots field above.
 3761 
 3762   calling_convention
 3763   %{
 3764     // No difference between ingoing/outgoing just pass false
 3765     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3766   %}
 3767 
 3768   c_calling_convention
 3769   %{
 3770     // This is obviously always outgoing
 3771     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3772   %}
 3773 
 3774   // Location of compiled Java return values.  Same as C for now.
 3775   return_value
 3776   %{
 3777     // TODO do we allow ideal_reg == Op_RegN???
 3778     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3779            &quot;only return normal values&quot;);
 3780 
 3781     static const int lo[Op_RegL + 1] = { // enum name
 3782       0,                                 // Op_Node
 3783       0,                                 // Op_Set
 3784       R0_num,                            // Op_RegN
 3785       R0_num,                            // Op_RegI
 3786       R0_num,                            // Op_RegP
 3787       V0_num,                            // Op_RegF
 3788       V0_num,                            // Op_RegD
 3789       R0_num                             // Op_RegL
 3790     };
 3791 
 3792     static const int hi[Op_RegL + 1] = { // enum name
 3793       0,                                 // Op_Node
 3794       0,                                 // Op_Set
 3795       OptoReg::Bad,                      // Op_RegN
 3796       OptoReg::Bad,                      // Op_RegI
 3797       R0_H_num,                          // Op_RegP
 3798       OptoReg::Bad,                      // Op_RegF
 3799       V0_H_num,                          // Op_RegD
 3800       R0_H_num                           // Op_RegL
 3801     };
 3802 
 3803     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3804   %}
 3805 %}
 3806 
 3807 //----------ATTRIBUTES---------------------------------------------------------
 3808 //----------Operand Attributes-------------------------------------------------
 3809 op_attrib op_cost(1);        // Required cost attribute
 3810 
 3811 //----------Instruction Attributes---------------------------------------------
 3812 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3813 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3814 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3815                                 // a non-matching short branch variant
 3816                                 // of some long branch?
 3817 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3818                                 // be a power of 2) specifies the
 3819                                 // alignment that some part of the
 3820                                 // instruction (not necessarily the
 3821                                 // start) requires.  If &gt; 1, a
 3822                                 // compute_padding() function must be
 3823                                 // provided for the instruction
 3824 
 3825 //----------OPERANDS-----------------------------------------------------------
 3826 // Operand definitions must precede instruction definitions for correct parsing
 3827 // in the ADLC because operands constitute user defined types which are used in
 3828 // instruction definitions.
 3829 
 3830 //----------Simple Operands----------------------------------------------------
 3831 
 3832 // Integer operands 32 bit
 3833 // 32 bit immediate
 3834 operand immI()
 3835 %{
 3836   match(ConI);
 3837 
 3838   op_cost(0);
 3839   format %{ %}
 3840   interface(CONST_INTER);
 3841 %}
 3842 
 3843 // 32 bit zero
 3844 operand immI0()
 3845 %{
 3846   predicate(n-&gt;get_int() == 0);
 3847   match(ConI);
 3848 
 3849   op_cost(0);
 3850   format %{ %}
 3851   interface(CONST_INTER);
 3852 %}
 3853 
 3854 // 32 bit unit increment
 3855 operand immI_1()
 3856 %{
 3857   predicate(n-&gt;get_int() == 1);
 3858   match(ConI);
 3859 
 3860   op_cost(0);
 3861   format %{ %}
 3862   interface(CONST_INTER);
 3863 %}
 3864 
 3865 // 32 bit unit decrement
 3866 operand immI_M1()
 3867 %{
 3868   predicate(n-&gt;get_int() == -1);
 3869   match(ConI);
 3870 
 3871   op_cost(0);
 3872   format %{ %}
 3873   interface(CONST_INTER);
 3874 %}
 3875 
 3876 // Shift values for add/sub extension shift
 3877 operand immIExt()
 3878 %{
 3879   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3880   match(ConI);
 3881 
 3882   op_cost(0);
 3883   format %{ %}
 3884   interface(CONST_INTER);
 3885 %}
 3886 
 3887 operand immI_le_4()
 3888 %{
 3889   predicate(n-&gt;get_int() &lt;= 4);
 3890   match(ConI);
 3891 
 3892   op_cost(0);
 3893   format %{ %}
 3894   interface(CONST_INTER);
 3895 %}
 3896 
 3897 operand immI_31()
 3898 %{
 3899   predicate(n-&gt;get_int() == 31);
 3900   match(ConI);
 3901 
 3902   op_cost(0);
 3903   format %{ %}
 3904   interface(CONST_INTER);
 3905 %}
 3906 
 3907 operand immI_8()
 3908 %{
 3909   predicate(n-&gt;get_int() == 8);
 3910   match(ConI);
 3911 
 3912   op_cost(0);
 3913   format %{ %}
 3914   interface(CONST_INTER);
 3915 %}
 3916 
 3917 operand immI_16()
 3918 %{
 3919   predicate(n-&gt;get_int() == 16);
 3920   match(ConI);
 3921 
 3922   op_cost(0);
 3923   format %{ %}
 3924   interface(CONST_INTER);
 3925 %}
 3926 
 3927 operand immI_24()
 3928 %{
 3929   predicate(n-&gt;get_int() == 24);
 3930   match(ConI);
 3931 
 3932   op_cost(0);
 3933   format %{ %}
 3934   interface(CONST_INTER);
 3935 %}
 3936 
 3937 operand immI_32()
 3938 %{
 3939   predicate(n-&gt;get_int() == 32);
 3940   match(ConI);
 3941 
 3942   op_cost(0);
 3943   format %{ %}
 3944   interface(CONST_INTER);
 3945 %}
 3946 
 3947 operand immI_48()
 3948 %{
 3949   predicate(n-&gt;get_int() == 48);
 3950   match(ConI);
 3951 
 3952   op_cost(0);
 3953   format %{ %}
 3954   interface(CONST_INTER);
 3955 %}
 3956 
 3957 operand immI_56()
 3958 %{
 3959   predicate(n-&gt;get_int() == 56);
 3960   match(ConI);
 3961 
 3962   op_cost(0);
 3963   format %{ %}
 3964   interface(CONST_INTER);
 3965 %}
 3966 
 3967 operand immI_63()
 3968 %{
 3969   predicate(n-&gt;get_int() == 63);
 3970   match(ConI);
 3971 
 3972   op_cost(0);
 3973   format %{ %}
 3974   interface(CONST_INTER);
 3975 %}
 3976 
 3977 operand immI_64()
 3978 %{
 3979   predicate(n-&gt;get_int() == 64);
 3980   match(ConI);
 3981 
 3982   op_cost(0);
 3983   format %{ %}
 3984   interface(CONST_INTER);
 3985 %}
 3986 
 3987 operand immI_255()
 3988 %{
 3989   predicate(n-&gt;get_int() == 255);
 3990   match(ConI);
 3991 
 3992   op_cost(0);
 3993   format %{ %}
 3994   interface(CONST_INTER);
 3995 %}
 3996 
 3997 operand immI_65535()
 3998 %{
 3999   predicate(n-&gt;get_int() == 65535);
 4000   match(ConI);
 4001 
 4002   op_cost(0);
 4003   format %{ %}
 4004   interface(CONST_INTER);
 4005 %}
 4006 
 4007 operand immL_255()
 4008 %{
 4009   predicate(n-&gt;get_long() == 255L);
 4010   match(ConL);
 4011 
 4012   op_cost(0);
 4013   format %{ %}
 4014   interface(CONST_INTER);
 4015 %}
 4016 
 4017 operand immL_65535()
 4018 %{
 4019   predicate(n-&gt;get_long() == 65535L);
 4020   match(ConL);
 4021 
 4022   op_cost(0);
 4023   format %{ %}
 4024   interface(CONST_INTER);
 4025 %}
 4026 
 4027 operand immL_4294967295()
 4028 %{
 4029   predicate(n-&gt;get_long() == 4294967295L);
 4030   match(ConL);
 4031 
 4032   op_cost(0);
 4033   format %{ %}
 4034   interface(CONST_INTER);
 4035 %}
 4036 
 4037 operand immL_bitmask()
 4038 %{
 4039   predicate((n-&gt;get_long() != 0)
 4040             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4041             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4042   match(ConL);
 4043 
 4044   op_cost(0);
 4045   format %{ %}
 4046   interface(CONST_INTER);
 4047 %}
 4048 
 4049 operand immI_bitmask()
 4050 %{
 4051   predicate((n-&gt;get_int() != 0)
 4052             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4053             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4054   match(ConI);
 4055 
 4056   op_cost(0);
 4057   format %{ %}
 4058   interface(CONST_INTER);
 4059 %}
 4060 
 4061 // Scale values for scaled offset addressing modes (up to long but not quad)
 4062 operand immIScale()
 4063 %{
 4064   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4065   match(ConI);
 4066 
 4067   op_cost(0);
 4068   format %{ %}
 4069   interface(CONST_INTER);
 4070 %}
 4071 
 4072 // 26 bit signed offset -- for pc-relative branches
 4073 operand immI26()
 4074 %{
 4075   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4076   match(ConI);
 4077 
 4078   op_cost(0);
 4079   format %{ %}
 4080   interface(CONST_INTER);
 4081 %}
 4082 
 4083 // 19 bit signed offset -- for pc-relative loads
 4084 operand immI19()
 4085 %{
 4086   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4087   match(ConI);
 4088 
 4089   op_cost(0);
 4090   format %{ %}
 4091   interface(CONST_INTER);
 4092 %}
 4093 
 4094 // 12 bit unsigned offset -- for base plus immediate loads
 4095 operand immIU12()
 4096 %{
 4097   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4098   match(ConI);
 4099 
 4100   op_cost(0);
 4101   format %{ %}
 4102   interface(CONST_INTER);
 4103 %}
 4104 
 4105 operand immLU12()
 4106 %{
 4107   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4108   match(ConL);
 4109 
 4110   op_cost(0);
 4111   format %{ %}
 4112   interface(CONST_INTER);
 4113 %}
 4114 
 4115 // Offset for scaled or unscaled immediate loads and stores
 4116 operand immIOffset()
 4117 %{
 4118   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4119   match(ConI);
 4120 
 4121   op_cost(0);
 4122   format %{ %}
 4123   interface(CONST_INTER);
 4124 %}
 4125 
 4126 operand immIOffset1()
 4127 %{
 4128   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4129   match(ConI);
 4130 
 4131   op_cost(0);
 4132   format %{ %}
 4133   interface(CONST_INTER);
 4134 %}
 4135 
 4136 operand immIOffset2()
 4137 %{
 4138   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4139   match(ConI);
 4140 
 4141   op_cost(0);
 4142   format %{ %}
 4143   interface(CONST_INTER);
 4144 %}
 4145 
 4146 operand immIOffset4()
 4147 %{
 4148   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4149   match(ConI);
 4150 
 4151   op_cost(0);
 4152   format %{ %}
 4153   interface(CONST_INTER);
 4154 %}
 4155 
 4156 operand immIOffset8()
 4157 %{
 4158   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4159   match(ConI);
 4160 
 4161   op_cost(0);
 4162   format %{ %}
 4163   interface(CONST_INTER);
 4164 %}
 4165 
 4166 operand immIOffset16()
 4167 %{
 4168   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4169   match(ConI);
 4170 
 4171   op_cost(0);
 4172   format %{ %}
 4173   interface(CONST_INTER);
 4174 %}
 4175 
 4176 operand immLoffset()
 4177 %{
 4178   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4179   match(ConL);
 4180 
 4181   op_cost(0);
 4182   format %{ %}
 4183   interface(CONST_INTER);
 4184 %}
 4185 
 4186 operand immLoffset1()
 4187 %{
 4188   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4189   match(ConL);
 4190 
 4191   op_cost(0);
 4192   format %{ %}
 4193   interface(CONST_INTER);
 4194 %}
 4195 
 4196 operand immLoffset2()
 4197 %{
 4198   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4199   match(ConL);
 4200 
 4201   op_cost(0);
 4202   format %{ %}
 4203   interface(CONST_INTER);
 4204 %}
 4205 
 4206 operand immLoffset4()
 4207 %{
 4208   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4209   match(ConL);
 4210 
 4211   op_cost(0);
 4212   format %{ %}
 4213   interface(CONST_INTER);
 4214 %}
 4215 
 4216 operand immLoffset8()
 4217 %{
 4218   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4219   match(ConL);
 4220 
 4221   op_cost(0);
 4222   format %{ %}
 4223   interface(CONST_INTER);
 4224 %}
 4225 
 4226 operand immLoffset16()
 4227 %{
 4228   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4229   match(ConL);
 4230 
 4231   op_cost(0);
 4232   format %{ %}
 4233   interface(CONST_INTER);
 4234 %}
 4235 
 4236 // 32 bit integer valid for add sub immediate
 4237 operand immIAddSub()
 4238 %{
<a name="12" id="anc12"></a><span class="line-modified"> 4239   predicate(Assembler::operand_valid_for_add_sub_immediate((int64_t)n-&gt;get_int()));</span>
 4240   match(ConI);
 4241   op_cost(0);
 4242   format %{ %}
 4243   interface(CONST_INTER);
 4244 %}
 4245 
 4246 // 32 bit unsigned integer valid for logical immediate
 4247 // TODO -- check this is right when e.g the mask is 0x80000000
 4248 operand immILog()
 4249 %{
<a name="13" id="anc13"></a><span class="line-modified"> 4250   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (uint64_t)n-&gt;get_int()));</span>
 4251   match(ConI);
 4252 
 4253   op_cost(0);
 4254   format %{ %}
 4255   interface(CONST_INTER);
 4256 %}
 4257 
 4258 // Integer operands 64 bit
 4259 // 64 bit immediate
 4260 operand immL()
 4261 %{
 4262   match(ConL);
 4263 
 4264   op_cost(0);
 4265   format %{ %}
 4266   interface(CONST_INTER);
 4267 %}
 4268 
 4269 // 64 bit zero
 4270 operand immL0()
 4271 %{
 4272   predicate(n-&gt;get_long() == 0);
 4273   match(ConL);
 4274 
 4275   op_cost(0);
 4276   format %{ %}
 4277   interface(CONST_INTER);
 4278 %}
 4279 
 4280 // 64 bit unit increment
 4281 operand immL_1()
 4282 %{
 4283   predicate(n-&gt;get_long() == 1);
 4284   match(ConL);
 4285 
 4286   op_cost(0);
 4287   format %{ %}
 4288   interface(CONST_INTER);
 4289 %}
 4290 
 4291 // 64 bit unit decrement
 4292 operand immL_M1()
 4293 %{
 4294   predicate(n-&gt;get_long() == -1);
 4295   match(ConL);
 4296 
 4297   op_cost(0);
 4298   format %{ %}
 4299   interface(CONST_INTER);
 4300 %}
 4301 
 4302 // 32 bit offset of pc in thread anchor
 4303 
 4304 operand immL_pc_off()
 4305 %{
 4306   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4307                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4308   match(ConL);
 4309 
 4310   op_cost(0);
 4311   format %{ %}
 4312   interface(CONST_INTER);
 4313 %}
 4314 
 4315 // 64 bit integer valid for add sub immediate
 4316 operand immLAddSub()
 4317 %{
 4318   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4319   match(ConL);
 4320   op_cost(0);
 4321   format %{ %}
 4322   interface(CONST_INTER);
 4323 %}
 4324 
 4325 // 64 bit integer valid for logical immediate
 4326 operand immLLog()
 4327 %{
<a name="14" id="anc14"></a><span class="line-modified"> 4328   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (uint64_t)n-&gt;get_long()));</span>
 4329   match(ConL);
 4330   op_cost(0);
 4331   format %{ %}
 4332   interface(CONST_INTER);
 4333 %}
 4334 
 4335 // Long Immediate: low 32-bit mask
 4336 operand immL_32bits()
 4337 %{
 4338   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4339   match(ConL);
 4340   op_cost(0);
 4341   format %{ %}
 4342   interface(CONST_INTER);
 4343 %}
 4344 
 4345 // Pointer operands
 4346 // Pointer Immediate
 4347 operand immP()
 4348 %{
 4349   match(ConP);
 4350 
 4351   op_cost(0);
 4352   format %{ %}
 4353   interface(CONST_INTER);
 4354 %}
 4355 
 4356 // NULL Pointer Immediate
 4357 operand immP0()
 4358 %{
 4359   predicate(n-&gt;get_ptr() == 0);
 4360   match(ConP);
 4361 
 4362   op_cost(0);
 4363   format %{ %}
 4364   interface(CONST_INTER);
 4365 %}
 4366 
 4367 // Pointer Immediate One
 4368 // this is used in object initialization (initial object header)
 4369 operand immP_1()
 4370 %{
 4371   predicate(n-&gt;get_ptr() == 1);
 4372   match(ConP);
 4373 
 4374   op_cost(0);
 4375   format %{ %}
 4376   interface(CONST_INTER);
 4377 %}
 4378 
 4379 // Polling Page Pointer Immediate
 4380 operand immPollPage()
 4381 %{
 4382   predicate((address)n-&gt;get_ptr() == os::get_polling_page());
 4383   match(ConP);
 4384 
 4385   op_cost(0);
 4386   format %{ %}
 4387   interface(CONST_INTER);
 4388 %}
 4389 
 4390 // Card Table Byte Map Base
 4391 operand immByteMapBase()
 4392 %{
 4393   // Get base of card map
 4394   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4395             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4396   match(ConP);
 4397 
 4398   op_cost(0);
 4399   format %{ %}
 4400   interface(CONST_INTER);
 4401 %}
 4402 
 4403 // Pointer Immediate Minus One
 4404 // this is used when we want to write the current PC to the thread anchor
 4405 operand immP_M1()
 4406 %{
 4407   predicate(n-&gt;get_ptr() == -1);
 4408   match(ConP);
 4409 
 4410   op_cost(0);
 4411   format %{ %}
 4412   interface(CONST_INTER);
 4413 %}
 4414 
 4415 // Pointer Immediate Minus Two
 4416 // this is used when we want to write the current PC to the thread anchor
 4417 operand immP_M2()
 4418 %{
 4419   predicate(n-&gt;get_ptr() == -2);
 4420   match(ConP);
 4421 
 4422   op_cost(0);
 4423   format %{ %}
 4424   interface(CONST_INTER);
 4425 %}
 4426 
 4427 // Float and Double operands
 4428 // Double Immediate
 4429 operand immD()
 4430 %{
 4431   match(ConD);
 4432   op_cost(0);
 4433   format %{ %}
 4434   interface(CONST_INTER);
 4435 %}
 4436 
 4437 // Double Immediate: +0.0d
 4438 operand immD0()
 4439 %{
 4440   predicate(jlong_cast(n-&gt;getd()) == 0);
 4441   match(ConD);
 4442 
 4443   op_cost(0);
 4444   format %{ %}
 4445   interface(CONST_INTER);
 4446 %}
 4447 
 4448 // constant &#39;double +0.0&#39;.
 4449 operand immDPacked()
 4450 %{
 4451   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4452   match(ConD);
 4453   op_cost(0);
 4454   format %{ %}
 4455   interface(CONST_INTER);
 4456 %}
 4457 
 4458 // Float Immediate
 4459 operand immF()
 4460 %{
 4461   match(ConF);
 4462   op_cost(0);
 4463   format %{ %}
 4464   interface(CONST_INTER);
 4465 %}
 4466 
 4467 // Float Immediate: +0.0f.
 4468 operand immF0()
 4469 %{
 4470   predicate(jint_cast(n-&gt;getf()) == 0);
 4471   match(ConF);
 4472 
 4473   op_cost(0);
 4474   format %{ %}
 4475   interface(CONST_INTER);
 4476 %}
 4477 
 4478 //
 4479 operand immFPacked()
 4480 %{
 4481   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4482   match(ConF);
 4483   op_cost(0);
 4484   format %{ %}
 4485   interface(CONST_INTER);
 4486 %}
 4487 
 4488 // Narrow pointer operands
 4489 // Narrow Pointer Immediate
 4490 operand immN()
 4491 %{
 4492   match(ConN);
 4493 
 4494   op_cost(0);
 4495   format %{ %}
 4496   interface(CONST_INTER);
 4497 %}
 4498 
 4499 // Narrow NULL Pointer Immediate
 4500 operand immN0()
 4501 %{
 4502   predicate(n-&gt;get_narrowcon() == 0);
 4503   match(ConN);
 4504 
 4505   op_cost(0);
 4506   format %{ %}
 4507   interface(CONST_INTER);
 4508 %}
 4509 
 4510 operand immNKlass()
 4511 %{
 4512   match(ConNKlass);
 4513 
 4514   op_cost(0);
 4515   format %{ %}
 4516   interface(CONST_INTER);
 4517 %}
 4518 
 4519 // Integer 32 bit Register Operands
 4520 // Integer 32 bitRegister (excludes SP)
 4521 operand iRegI()
 4522 %{
 4523   constraint(ALLOC_IN_RC(any_reg32));
 4524   match(RegI);
 4525   match(iRegINoSp);
 4526   op_cost(0);
 4527   format %{ %}
 4528   interface(REG_INTER);
 4529 %}
 4530 
 4531 // Integer 32 bit Register not Special
 4532 operand iRegINoSp()
 4533 %{
 4534   constraint(ALLOC_IN_RC(no_special_reg32));
 4535   match(RegI);
 4536   op_cost(0);
 4537   format %{ %}
 4538   interface(REG_INTER);
 4539 %}
 4540 
 4541 // Integer 64 bit Register Operands
 4542 // Integer 64 bit Register (includes SP)
 4543 operand iRegL()
 4544 %{
 4545   constraint(ALLOC_IN_RC(any_reg));
 4546   match(RegL);
 4547   match(iRegLNoSp);
 4548   op_cost(0);
 4549   format %{ %}
 4550   interface(REG_INTER);
 4551 %}
 4552 
 4553 // Integer 64 bit Register not Special
 4554 operand iRegLNoSp()
 4555 %{
 4556   constraint(ALLOC_IN_RC(no_special_reg));
 4557   match(RegL);
 4558   match(iRegL_R0);
 4559   format %{ %}
 4560   interface(REG_INTER);
 4561 %}
 4562 
 4563 // Pointer Register Operands
 4564 // Pointer Register
 4565 operand iRegP()
 4566 %{
 4567   constraint(ALLOC_IN_RC(ptr_reg));
 4568   match(RegP);
 4569   match(iRegPNoSp);
 4570   match(iRegP_R0);
 4571   //match(iRegP_R2);
 4572   //match(iRegP_R4);
 4573   //match(iRegP_R5);
 4574   match(thread_RegP);
 4575   op_cost(0);
 4576   format %{ %}
 4577   interface(REG_INTER);
 4578 %}
 4579 
 4580 // Pointer 64 bit Register not Special
 4581 operand iRegPNoSp()
 4582 %{
 4583   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4584   match(RegP);
 4585   // match(iRegP);
 4586   // match(iRegP_R0);
 4587   // match(iRegP_R2);
 4588   // match(iRegP_R4);
 4589   // match(iRegP_R5);
 4590   // match(thread_RegP);
 4591   op_cost(0);
 4592   format %{ %}
 4593   interface(REG_INTER);
 4594 %}
 4595 
 4596 // Pointer 64 bit Register R0 only
 4597 operand iRegP_R0()
 4598 %{
 4599   constraint(ALLOC_IN_RC(r0_reg));
 4600   match(RegP);
 4601   // match(iRegP);
 4602   match(iRegPNoSp);
 4603   op_cost(0);
 4604   format %{ %}
 4605   interface(REG_INTER);
 4606 %}
 4607 
 4608 // Pointer 64 bit Register R1 only
 4609 operand iRegP_R1()
 4610 %{
 4611   constraint(ALLOC_IN_RC(r1_reg));
 4612   match(RegP);
 4613   // match(iRegP);
 4614   match(iRegPNoSp);
 4615   op_cost(0);
 4616   format %{ %}
 4617   interface(REG_INTER);
 4618 %}
 4619 
 4620 // Pointer 64 bit Register R2 only
 4621 operand iRegP_R2()
 4622 %{
 4623   constraint(ALLOC_IN_RC(r2_reg));
 4624   match(RegP);
 4625   // match(iRegP);
 4626   match(iRegPNoSp);
 4627   op_cost(0);
 4628   format %{ %}
 4629   interface(REG_INTER);
 4630 %}
 4631 
 4632 // Pointer 64 bit Register R3 only
 4633 operand iRegP_R3()
 4634 %{
 4635   constraint(ALLOC_IN_RC(r3_reg));
 4636   match(RegP);
 4637   // match(iRegP);
 4638   match(iRegPNoSp);
 4639   op_cost(0);
 4640   format %{ %}
 4641   interface(REG_INTER);
 4642 %}
 4643 
 4644 // Pointer 64 bit Register R4 only
 4645 operand iRegP_R4()
 4646 %{
 4647   constraint(ALLOC_IN_RC(r4_reg));
 4648   match(RegP);
 4649   // match(iRegP);
 4650   match(iRegPNoSp);
 4651   op_cost(0);
 4652   format %{ %}
 4653   interface(REG_INTER);
 4654 %}
 4655 
 4656 // Pointer 64 bit Register R5 only
 4657 operand iRegP_R5()
 4658 %{
 4659   constraint(ALLOC_IN_RC(r5_reg));
 4660   match(RegP);
 4661   // match(iRegP);
 4662   match(iRegPNoSp);
 4663   op_cost(0);
 4664   format %{ %}
 4665   interface(REG_INTER);
 4666 %}
 4667 
 4668 // Pointer 64 bit Register R10 only
 4669 operand iRegP_R10()
 4670 %{
 4671   constraint(ALLOC_IN_RC(r10_reg));
 4672   match(RegP);
 4673   // match(iRegP);
 4674   match(iRegPNoSp);
 4675   op_cost(0);
 4676   format %{ %}
 4677   interface(REG_INTER);
 4678 %}
 4679 
 4680 // Long 64 bit Register R0 only
 4681 operand iRegL_R0()
 4682 %{
 4683   constraint(ALLOC_IN_RC(r0_reg));
 4684   match(RegL);
 4685   match(iRegLNoSp);
 4686   op_cost(0);
 4687   format %{ %}
 4688   interface(REG_INTER);
 4689 %}
 4690 
 4691 // Long 64 bit Register R2 only
 4692 operand iRegL_R2()
 4693 %{
 4694   constraint(ALLOC_IN_RC(r2_reg));
 4695   match(RegL);
 4696   match(iRegLNoSp);
 4697   op_cost(0);
 4698   format %{ %}
 4699   interface(REG_INTER);
 4700 %}
 4701 
 4702 // Long 64 bit Register R3 only
 4703 operand iRegL_R3()
 4704 %{
 4705   constraint(ALLOC_IN_RC(r3_reg));
 4706   match(RegL);
 4707   match(iRegLNoSp);
 4708   op_cost(0);
 4709   format %{ %}
 4710   interface(REG_INTER);
 4711 %}
 4712 
 4713 // Long 64 bit Register R11 only
 4714 operand iRegL_R11()
 4715 %{
 4716   constraint(ALLOC_IN_RC(r11_reg));
 4717   match(RegL);
 4718   match(iRegLNoSp);
 4719   op_cost(0);
 4720   format %{ %}
 4721   interface(REG_INTER);
 4722 %}
 4723 
 4724 // Pointer 64 bit Register FP only
 4725 operand iRegP_FP()
 4726 %{
 4727   constraint(ALLOC_IN_RC(fp_reg));
 4728   match(RegP);
 4729   // match(iRegP);
 4730   op_cost(0);
 4731   format %{ %}
 4732   interface(REG_INTER);
 4733 %}
 4734 
 4735 // Register R0 only
 4736 operand iRegI_R0()
 4737 %{
 4738   constraint(ALLOC_IN_RC(int_r0_reg));
 4739   match(RegI);
 4740   match(iRegINoSp);
 4741   op_cost(0);
 4742   format %{ %}
 4743   interface(REG_INTER);
 4744 %}
 4745 
 4746 // Register R2 only
 4747 operand iRegI_R2()
 4748 %{
 4749   constraint(ALLOC_IN_RC(int_r2_reg));
 4750   match(RegI);
 4751   match(iRegINoSp);
 4752   op_cost(0);
 4753   format %{ %}
 4754   interface(REG_INTER);
 4755 %}
 4756 
 4757 // Register R3 only
 4758 operand iRegI_R3()
 4759 %{
 4760   constraint(ALLOC_IN_RC(int_r3_reg));
 4761   match(RegI);
 4762   match(iRegINoSp);
 4763   op_cost(0);
 4764   format %{ %}
 4765   interface(REG_INTER);
 4766 %}
 4767 
 4768 
 4769 // Register R4 only
 4770 operand iRegI_R4()
 4771 %{
 4772   constraint(ALLOC_IN_RC(int_r4_reg));
 4773   match(RegI);
 4774   match(iRegINoSp);
 4775   op_cost(0);
 4776   format %{ %}
 4777   interface(REG_INTER);
 4778 %}
 4779 
 4780 
 4781 // Pointer Register Operands
 4782 // Narrow Pointer Register
 4783 operand iRegN()
 4784 %{
 4785   constraint(ALLOC_IN_RC(any_reg32));
 4786   match(RegN);
 4787   match(iRegNNoSp);
 4788   op_cost(0);
 4789   format %{ %}
 4790   interface(REG_INTER);
 4791 %}
 4792 
 4793 operand iRegN_R0()
 4794 %{
 4795   constraint(ALLOC_IN_RC(r0_reg));
 4796   match(iRegN);
 4797   op_cost(0);
 4798   format %{ %}
 4799   interface(REG_INTER);
 4800 %}
 4801 
 4802 operand iRegN_R2()
 4803 %{
 4804   constraint(ALLOC_IN_RC(r2_reg));
 4805   match(iRegN);
 4806   op_cost(0);
 4807   format %{ %}
 4808   interface(REG_INTER);
 4809 %}
 4810 
 4811 operand iRegN_R3()
 4812 %{
 4813   constraint(ALLOC_IN_RC(r3_reg));
 4814   match(iRegN);
 4815   op_cost(0);
 4816   format %{ %}
 4817   interface(REG_INTER);
 4818 %}
 4819 
 4820 // Integer 64 bit Register not Special
 4821 operand iRegNNoSp()
 4822 %{
 4823   constraint(ALLOC_IN_RC(no_special_reg32));
 4824   match(RegN);
 4825   op_cost(0);
 4826   format %{ %}
 4827   interface(REG_INTER);
 4828 %}
 4829 
 4830 // heap base register -- used for encoding immN0
 4831 
 4832 operand iRegIHeapbase()
 4833 %{
 4834   constraint(ALLOC_IN_RC(heapbase_reg));
 4835   match(RegI);
 4836   op_cost(0);
 4837   format %{ %}
 4838   interface(REG_INTER);
 4839 %}
 4840 
 4841 // Float Register
 4842 // Float register operands
 4843 operand vRegF()
 4844 %{
 4845   constraint(ALLOC_IN_RC(float_reg));
 4846   match(RegF);
 4847 
 4848   op_cost(0);
 4849   format %{ %}
 4850   interface(REG_INTER);
 4851 %}
 4852 
 4853 // Double Register
 4854 // Double register operands
 4855 operand vRegD()
 4856 %{
 4857   constraint(ALLOC_IN_RC(double_reg));
 4858   match(RegD);
 4859 
 4860   op_cost(0);
 4861   format %{ %}
 4862   interface(REG_INTER);
 4863 %}
 4864 
 4865 operand vecD()
 4866 %{
 4867   constraint(ALLOC_IN_RC(vectord_reg));
 4868   match(VecD);
 4869 
 4870   op_cost(0);
 4871   format %{ %}
 4872   interface(REG_INTER);
 4873 %}
 4874 
 4875 operand vecX()
 4876 %{
 4877   constraint(ALLOC_IN_RC(vectorx_reg));
 4878   match(VecX);
 4879 
 4880   op_cost(0);
 4881   format %{ %}
 4882   interface(REG_INTER);
 4883 %}
 4884 
 4885 operand vRegD_V0()
 4886 %{
 4887   constraint(ALLOC_IN_RC(v0_reg));
 4888   match(RegD);
 4889   op_cost(0);
 4890   format %{ %}
 4891   interface(REG_INTER);
 4892 %}
 4893 
 4894 operand vRegD_V1()
 4895 %{
 4896   constraint(ALLOC_IN_RC(v1_reg));
 4897   match(RegD);
 4898   op_cost(0);
 4899   format %{ %}
 4900   interface(REG_INTER);
 4901 %}
 4902 
 4903 operand vRegD_V2()
 4904 %{
 4905   constraint(ALLOC_IN_RC(v2_reg));
 4906   match(RegD);
 4907   op_cost(0);
 4908   format %{ %}
 4909   interface(REG_INTER);
 4910 %}
 4911 
 4912 operand vRegD_V3()
 4913 %{
 4914   constraint(ALLOC_IN_RC(v3_reg));
 4915   match(RegD);
 4916   op_cost(0);
 4917   format %{ %}
 4918   interface(REG_INTER);
 4919 %}
 4920 
 4921 operand vRegD_V4()
 4922 %{
 4923   constraint(ALLOC_IN_RC(v4_reg));
 4924   match(RegD);
 4925   op_cost(0);
 4926   format %{ %}
 4927   interface(REG_INTER);
 4928 %}
 4929 
 4930 operand vRegD_V5()
 4931 %{
 4932   constraint(ALLOC_IN_RC(v5_reg));
 4933   match(RegD);
 4934   op_cost(0);
 4935   format %{ %}
 4936   interface(REG_INTER);
 4937 %}
 4938 
 4939 operand vRegD_V6()
 4940 %{
 4941   constraint(ALLOC_IN_RC(v6_reg));
 4942   match(RegD);
 4943   op_cost(0);
 4944   format %{ %}
 4945   interface(REG_INTER);
 4946 %}
 4947 
 4948 operand vRegD_V7()
 4949 %{
 4950   constraint(ALLOC_IN_RC(v7_reg));
 4951   match(RegD);
 4952   op_cost(0);
 4953   format %{ %}
 4954   interface(REG_INTER);
 4955 %}
 4956 
 4957 operand vRegD_V8()
 4958 %{
 4959   constraint(ALLOC_IN_RC(v8_reg));
 4960   match(RegD);
 4961   op_cost(0);
 4962   format %{ %}
 4963   interface(REG_INTER);
 4964 %}
 4965 
 4966 operand vRegD_V9()
 4967 %{
 4968   constraint(ALLOC_IN_RC(v9_reg));
 4969   match(RegD);
 4970   op_cost(0);
 4971   format %{ %}
 4972   interface(REG_INTER);
 4973 %}
 4974 
 4975 operand vRegD_V10()
 4976 %{
 4977   constraint(ALLOC_IN_RC(v10_reg));
 4978   match(RegD);
 4979   op_cost(0);
 4980   format %{ %}
 4981   interface(REG_INTER);
 4982 %}
 4983 
 4984 operand vRegD_V11()
 4985 %{
 4986   constraint(ALLOC_IN_RC(v11_reg));
 4987   match(RegD);
 4988   op_cost(0);
 4989   format %{ %}
 4990   interface(REG_INTER);
 4991 %}
 4992 
 4993 operand vRegD_V12()
 4994 %{
 4995   constraint(ALLOC_IN_RC(v12_reg));
 4996   match(RegD);
 4997   op_cost(0);
 4998   format %{ %}
 4999   interface(REG_INTER);
 5000 %}
 5001 
 5002 operand vRegD_V13()
 5003 %{
 5004   constraint(ALLOC_IN_RC(v13_reg));
 5005   match(RegD);
 5006   op_cost(0);
 5007   format %{ %}
 5008   interface(REG_INTER);
 5009 %}
 5010 
 5011 operand vRegD_V14()
 5012 %{
 5013   constraint(ALLOC_IN_RC(v14_reg));
 5014   match(RegD);
 5015   op_cost(0);
 5016   format %{ %}
 5017   interface(REG_INTER);
 5018 %}
 5019 
 5020 operand vRegD_V15()
 5021 %{
 5022   constraint(ALLOC_IN_RC(v15_reg));
 5023   match(RegD);
 5024   op_cost(0);
 5025   format %{ %}
 5026   interface(REG_INTER);
 5027 %}
 5028 
 5029 operand vRegD_V16()
 5030 %{
 5031   constraint(ALLOC_IN_RC(v16_reg));
 5032   match(RegD);
 5033   op_cost(0);
 5034   format %{ %}
 5035   interface(REG_INTER);
 5036 %}
 5037 
 5038 operand vRegD_V17()
 5039 %{
 5040   constraint(ALLOC_IN_RC(v17_reg));
 5041   match(RegD);
 5042   op_cost(0);
 5043   format %{ %}
 5044   interface(REG_INTER);
 5045 %}
 5046 
 5047 operand vRegD_V18()
 5048 %{
 5049   constraint(ALLOC_IN_RC(v18_reg));
 5050   match(RegD);
 5051   op_cost(0);
 5052   format %{ %}
 5053   interface(REG_INTER);
 5054 %}
 5055 
 5056 operand vRegD_V19()
 5057 %{
 5058   constraint(ALLOC_IN_RC(v19_reg));
 5059   match(RegD);
 5060   op_cost(0);
 5061   format %{ %}
 5062   interface(REG_INTER);
 5063 %}
 5064 
 5065 operand vRegD_V20()
 5066 %{
 5067   constraint(ALLOC_IN_RC(v20_reg));
 5068   match(RegD);
 5069   op_cost(0);
 5070   format %{ %}
 5071   interface(REG_INTER);
 5072 %}
 5073 
 5074 operand vRegD_V21()
 5075 %{
 5076   constraint(ALLOC_IN_RC(v21_reg));
 5077   match(RegD);
 5078   op_cost(0);
 5079   format %{ %}
 5080   interface(REG_INTER);
 5081 %}
 5082 
 5083 operand vRegD_V22()
 5084 %{
 5085   constraint(ALLOC_IN_RC(v22_reg));
 5086   match(RegD);
 5087   op_cost(0);
 5088   format %{ %}
 5089   interface(REG_INTER);
 5090 %}
 5091 
 5092 operand vRegD_V23()
 5093 %{
 5094   constraint(ALLOC_IN_RC(v23_reg));
 5095   match(RegD);
 5096   op_cost(0);
 5097   format %{ %}
 5098   interface(REG_INTER);
 5099 %}
 5100 
 5101 operand vRegD_V24()
 5102 %{
 5103   constraint(ALLOC_IN_RC(v24_reg));
 5104   match(RegD);
 5105   op_cost(0);
 5106   format %{ %}
 5107   interface(REG_INTER);
 5108 %}
 5109 
 5110 operand vRegD_V25()
 5111 %{
 5112   constraint(ALLOC_IN_RC(v25_reg));
 5113   match(RegD);
 5114   op_cost(0);
 5115   format %{ %}
 5116   interface(REG_INTER);
 5117 %}
 5118 
 5119 operand vRegD_V26()
 5120 %{
 5121   constraint(ALLOC_IN_RC(v26_reg));
 5122   match(RegD);
 5123   op_cost(0);
 5124   format %{ %}
 5125   interface(REG_INTER);
 5126 %}
 5127 
 5128 operand vRegD_V27()
 5129 %{
 5130   constraint(ALLOC_IN_RC(v27_reg));
 5131   match(RegD);
 5132   op_cost(0);
 5133   format %{ %}
 5134   interface(REG_INTER);
 5135 %}
 5136 
 5137 operand vRegD_V28()
 5138 %{
 5139   constraint(ALLOC_IN_RC(v28_reg));
 5140   match(RegD);
 5141   op_cost(0);
 5142   format %{ %}
 5143   interface(REG_INTER);
 5144 %}
 5145 
 5146 operand vRegD_V29()
 5147 %{
 5148   constraint(ALLOC_IN_RC(v29_reg));
 5149   match(RegD);
 5150   op_cost(0);
 5151   format %{ %}
 5152   interface(REG_INTER);
 5153 %}
 5154 
 5155 operand vRegD_V30()
 5156 %{
 5157   constraint(ALLOC_IN_RC(v30_reg));
 5158   match(RegD);
 5159   op_cost(0);
 5160   format %{ %}
 5161   interface(REG_INTER);
 5162 %}
 5163 
 5164 operand vRegD_V31()
 5165 %{
 5166   constraint(ALLOC_IN_RC(v31_reg));
 5167   match(RegD);
 5168   op_cost(0);
 5169   format %{ %}
 5170   interface(REG_INTER);
 5171 %}
 5172 
 5173 // Flags register, used as output of signed compare instructions
 5174 
 5175 // note that on AArch64 we also use this register as the output for
 5176 // for floating point compare instructions (CmpF CmpD). this ensures
 5177 // that ordered inequality tests use GT, GE, LT or LE none of which
 5178 // pass through cases where the result is unordered i.e. one or both
 5179 // inputs to the compare is a NaN. this means that the ideal code can
 5180 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5181 // (where the comparison should always fail). EQ and NE tests are
 5182 // always generated in ideal code so that unordered folds into the NE
 5183 // case, matching the behaviour of AArch64 NE.
 5184 //
 5185 // This differs from x86 where the outputs of FP compares use a
 5186 // special FP flags registers and where compares based on this
 5187 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5188 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5189 // to explicitly handle the unordered case in branches. x86 also has
 5190 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5191 
 5192 operand rFlagsReg()
 5193 %{
 5194   constraint(ALLOC_IN_RC(int_flags));
 5195   match(RegFlags);
 5196 
 5197   op_cost(0);
 5198   format %{ &quot;RFLAGS&quot; %}
 5199   interface(REG_INTER);
 5200 %}
 5201 
 5202 // Flags register, used as output of unsigned compare instructions
 5203 operand rFlagsRegU()
 5204 %{
 5205   constraint(ALLOC_IN_RC(int_flags));
 5206   match(RegFlags);
 5207 
 5208   op_cost(0);
 5209   format %{ &quot;RFLAGSU&quot; %}
 5210   interface(REG_INTER);
 5211 %}
 5212 
 5213 // Special Registers
 5214 
 5215 // Method Register
 5216 operand inline_cache_RegP(iRegP reg)
 5217 %{
 5218   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5219   match(reg);
 5220   match(iRegPNoSp);
 5221   op_cost(0);
 5222   format %{ %}
 5223   interface(REG_INTER);
 5224 %}
 5225 
 5226 operand interpreter_method_oop_RegP(iRegP reg)
 5227 %{
 5228   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5229   match(reg);
 5230   match(iRegPNoSp);
 5231   op_cost(0);
 5232   format %{ %}
 5233   interface(REG_INTER);
 5234 %}
 5235 
 5236 // Thread Register
 5237 operand thread_RegP(iRegP reg)
 5238 %{
 5239   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5240   match(reg);
 5241   op_cost(0);
 5242   format %{ %}
 5243   interface(REG_INTER);
 5244 %}
 5245 
 5246 operand lr_RegP(iRegP reg)
 5247 %{
 5248   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5249   match(reg);
 5250   op_cost(0);
 5251   format %{ %}
 5252   interface(REG_INTER);
 5253 %}
 5254 
 5255 //----------Memory Operands----------------------------------------------------
 5256 
 5257 operand indirect(iRegP reg)
 5258 %{
 5259   constraint(ALLOC_IN_RC(ptr_reg));
 5260   match(reg);
 5261   op_cost(0);
 5262   format %{ &quot;[$reg]&quot; %}
 5263   interface(MEMORY_INTER) %{
 5264     base($reg);
 5265     index(0xffffffff);
 5266     scale(0x0);
 5267     disp(0x0);
 5268   %}
 5269 %}
 5270 
 5271 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5272 %{
 5273   constraint(ALLOC_IN_RC(ptr_reg));
 5274   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5275   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5276   op_cost(0);
 5277   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5278   interface(MEMORY_INTER) %{
 5279     base($reg);
 5280     index($ireg);
 5281     scale($scale);
 5282     disp(0x0);
 5283   %}
 5284 %}
 5285 
 5286 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5287 %{
 5288   constraint(ALLOC_IN_RC(ptr_reg));
 5289   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5290   match(AddP reg (LShiftL lreg scale));
 5291   op_cost(0);
 5292   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5293   interface(MEMORY_INTER) %{
 5294     base($reg);
 5295     index($lreg);
 5296     scale($scale);
 5297     disp(0x0);
 5298   %}
 5299 %}
 5300 
 5301 operand indIndexI2L(iRegP reg, iRegI ireg)
 5302 %{
 5303   constraint(ALLOC_IN_RC(ptr_reg));
 5304   match(AddP reg (ConvI2L ireg));
 5305   op_cost(0);
 5306   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5307   interface(MEMORY_INTER) %{
 5308     base($reg);
 5309     index($ireg);
 5310     scale(0x0);
 5311     disp(0x0);
 5312   %}
 5313 %}
 5314 
 5315 operand indIndex(iRegP reg, iRegL lreg)
 5316 %{
 5317   constraint(ALLOC_IN_RC(ptr_reg));
 5318   match(AddP reg lreg);
 5319   op_cost(0);
 5320   format %{ &quot;$reg, $lreg&quot; %}
 5321   interface(MEMORY_INTER) %{
 5322     base($reg);
 5323     index($lreg);
 5324     scale(0x0);
 5325     disp(0x0);
 5326   %}
 5327 %}
 5328 
 5329 operand indOffI(iRegP reg, immIOffset off)
 5330 %{
 5331   constraint(ALLOC_IN_RC(ptr_reg));
 5332   match(AddP reg off);
 5333   op_cost(0);
 5334   format %{ &quot;[$reg, $off]&quot; %}
 5335   interface(MEMORY_INTER) %{
 5336     base($reg);
 5337     index(0xffffffff);
 5338     scale(0x0);
 5339     disp($off);
 5340   %}
 5341 %}
 5342 
 5343 operand indOffI1(iRegP reg, immIOffset1 off)
 5344 %{
 5345   constraint(ALLOC_IN_RC(ptr_reg));
 5346   match(AddP reg off);
 5347   op_cost(0);
 5348   format %{ &quot;[$reg, $off]&quot; %}
 5349   interface(MEMORY_INTER) %{
 5350     base($reg);
 5351     index(0xffffffff);
 5352     scale(0x0);
 5353     disp($off);
 5354   %}
 5355 %}
 5356 
 5357 operand indOffI2(iRegP reg, immIOffset2 off)
 5358 %{
 5359   constraint(ALLOC_IN_RC(ptr_reg));
 5360   match(AddP reg off);
 5361   op_cost(0);
 5362   format %{ &quot;[$reg, $off]&quot; %}
 5363   interface(MEMORY_INTER) %{
 5364     base($reg);
 5365     index(0xffffffff);
 5366     scale(0x0);
 5367     disp($off);
 5368   %}
 5369 %}
 5370 
 5371 operand indOffI4(iRegP reg, immIOffset4 off)
 5372 %{
 5373   constraint(ALLOC_IN_RC(ptr_reg));
 5374   match(AddP reg off);
 5375   op_cost(0);
 5376   format %{ &quot;[$reg, $off]&quot; %}
 5377   interface(MEMORY_INTER) %{
 5378     base($reg);
 5379     index(0xffffffff);
 5380     scale(0x0);
 5381     disp($off);
 5382   %}
 5383 %}
 5384 
 5385 operand indOffI8(iRegP reg, immIOffset8 off)
 5386 %{
 5387   constraint(ALLOC_IN_RC(ptr_reg));
 5388   match(AddP reg off);
 5389   op_cost(0);
 5390   format %{ &quot;[$reg, $off]&quot; %}
 5391   interface(MEMORY_INTER) %{
 5392     base($reg);
 5393     index(0xffffffff);
 5394     scale(0x0);
 5395     disp($off);
 5396   %}
 5397 %}
 5398 
 5399 operand indOffI16(iRegP reg, immIOffset16 off)
 5400 %{
 5401   constraint(ALLOC_IN_RC(ptr_reg));
 5402   match(AddP reg off);
 5403   op_cost(0);
 5404   format %{ &quot;[$reg, $off]&quot; %}
 5405   interface(MEMORY_INTER) %{
 5406     base($reg);
 5407     index(0xffffffff);
 5408     scale(0x0);
 5409     disp($off);
 5410   %}
 5411 %}
 5412 
 5413 operand indOffL(iRegP reg, immLoffset off)
 5414 %{
 5415   constraint(ALLOC_IN_RC(ptr_reg));
 5416   match(AddP reg off);
 5417   op_cost(0);
 5418   format %{ &quot;[$reg, $off]&quot; %}
 5419   interface(MEMORY_INTER) %{
 5420     base($reg);
 5421     index(0xffffffff);
 5422     scale(0x0);
 5423     disp($off);
 5424   %}
 5425 %}
 5426 
 5427 operand indOffL1(iRegP reg, immLoffset1 off)
 5428 %{
 5429   constraint(ALLOC_IN_RC(ptr_reg));
 5430   match(AddP reg off);
 5431   op_cost(0);
 5432   format %{ &quot;[$reg, $off]&quot; %}
 5433   interface(MEMORY_INTER) %{
 5434     base($reg);
 5435     index(0xffffffff);
 5436     scale(0x0);
 5437     disp($off);
 5438   %}
 5439 %}
 5440 
 5441 operand indOffL2(iRegP reg, immLoffset2 off)
 5442 %{
 5443   constraint(ALLOC_IN_RC(ptr_reg));
 5444   match(AddP reg off);
 5445   op_cost(0);
 5446   format %{ &quot;[$reg, $off]&quot; %}
 5447   interface(MEMORY_INTER) %{
 5448     base($reg);
 5449     index(0xffffffff);
 5450     scale(0x0);
 5451     disp($off);
 5452   %}
 5453 %}
 5454 
 5455 operand indOffL4(iRegP reg, immLoffset4 off)
 5456 %{
 5457   constraint(ALLOC_IN_RC(ptr_reg));
 5458   match(AddP reg off);
 5459   op_cost(0);
 5460   format %{ &quot;[$reg, $off]&quot; %}
 5461   interface(MEMORY_INTER) %{
 5462     base($reg);
 5463     index(0xffffffff);
 5464     scale(0x0);
 5465     disp($off);
 5466   %}
 5467 %}
 5468 
 5469 operand indOffL8(iRegP reg, immLoffset8 off)
 5470 %{
 5471   constraint(ALLOC_IN_RC(ptr_reg));
 5472   match(AddP reg off);
 5473   op_cost(0);
 5474   format %{ &quot;[$reg, $off]&quot; %}
 5475   interface(MEMORY_INTER) %{
 5476     base($reg);
 5477     index(0xffffffff);
 5478     scale(0x0);
 5479     disp($off);
 5480   %}
 5481 %}
 5482 
 5483 operand indOffL16(iRegP reg, immLoffset16 off)
 5484 %{
 5485   constraint(ALLOC_IN_RC(ptr_reg));
 5486   match(AddP reg off);
 5487   op_cost(0);
 5488   format %{ &quot;[$reg, $off]&quot; %}
 5489   interface(MEMORY_INTER) %{
 5490     base($reg);
 5491     index(0xffffffff);
 5492     scale(0x0);
 5493     disp($off);
 5494   %}
 5495 %}
 5496 
 5497 operand indirectN(iRegN reg)
 5498 %{
 5499   predicate(CompressedOops::shift() == 0);
 5500   constraint(ALLOC_IN_RC(ptr_reg));
 5501   match(DecodeN reg);
 5502   op_cost(0);
 5503   format %{ &quot;[$reg]\t# narrow&quot; %}
 5504   interface(MEMORY_INTER) %{
 5505     base($reg);
 5506     index(0xffffffff);
 5507     scale(0x0);
 5508     disp(0x0);
 5509   %}
 5510 %}
 5511 
 5512 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5513 %{
 5514   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5515   constraint(ALLOC_IN_RC(ptr_reg));
 5516   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5517   op_cost(0);
 5518   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5519   interface(MEMORY_INTER) %{
 5520     base($reg);
 5521     index($ireg);
 5522     scale($scale);
 5523     disp(0x0);
 5524   %}
 5525 %}
 5526 
 5527 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5528 %{
 5529   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5530   constraint(ALLOC_IN_RC(ptr_reg));
 5531   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5532   op_cost(0);
 5533   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5534   interface(MEMORY_INTER) %{
 5535     base($reg);
 5536     index($lreg);
 5537     scale($scale);
 5538     disp(0x0);
 5539   %}
 5540 %}
 5541 
 5542 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5543 %{
 5544   predicate(CompressedOops::shift() == 0);
 5545   constraint(ALLOC_IN_RC(ptr_reg));
 5546   match(AddP (DecodeN reg) (ConvI2L ireg));
 5547   op_cost(0);
 5548   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5549   interface(MEMORY_INTER) %{
 5550     base($reg);
 5551     index($ireg);
 5552     scale(0x0);
 5553     disp(0x0);
 5554   %}
 5555 %}
 5556 
 5557 operand indIndexN(iRegN reg, iRegL lreg)
 5558 %{
 5559   predicate(CompressedOops::shift() == 0);
 5560   constraint(ALLOC_IN_RC(ptr_reg));
 5561   match(AddP (DecodeN reg) lreg);
 5562   op_cost(0);
 5563   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5564   interface(MEMORY_INTER) %{
 5565     base($reg);
 5566     index($lreg);
 5567     scale(0x0);
 5568     disp(0x0);
 5569   %}
 5570 %}
 5571 
 5572 operand indOffIN(iRegN reg, immIOffset off)
 5573 %{
 5574   predicate(CompressedOops::shift() == 0);
 5575   constraint(ALLOC_IN_RC(ptr_reg));
 5576   match(AddP (DecodeN reg) off);
 5577   op_cost(0);
 5578   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5579   interface(MEMORY_INTER) %{
 5580     base($reg);
 5581     index(0xffffffff);
 5582     scale(0x0);
 5583     disp($off);
 5584   %}
 5585 %}
 5586 
 5587 operand indOffLN(iRegN reg, immLoffset off)
 5588 %{
 5589   predicate(CompressedOops::shift() == 0);
 5590   constraint(ALLOC_IN_RC(ptr_reg));
 5591   match(AddP (DecodeN reg) off);
 5592   op_cost(0);
 5593   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5594   interface(MEMORY_INTER) %{
 5595     base($reg);
 5596     index(0xffffffff);
 5597     scale(0x0);
 5598     disp($off);
 5599   %}
 5600 %}
 5601 
 5602 
 5603 
 5604 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5605 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5606 %{
 5607   constraint(ALLOC_IN_RC(ptr_reg));
 5608   match(AddP reg off);
 5609   op_cost(0);
 5610   format %{ &quot;[$reg, $off]&quot; %}
 5611   interface(MEMORY_INTER) %{
 5612     base($reg);
 5613     index(0xffffffff);
 5614     scale(0x0);
 5615     disp($off);
 5616   %}
 5617 %}
 5618 
 5619 //----------Special Memory Operands--------------------------------------------
 5620 // Stack Slot Operand - This operand is used for loading and storing temporary
 5621 //                      values on the stack where a match requires a value to
 5622 //                      flow through memory.
 5623 operand stackSlotP(sRegP reg)
 5624 %{
 5625   constraint(ALLOC_IN_RC(stack_slots));
 5626   op_cost(100);
 5627   // No match rule because this operand is only generated in matching
 5628   // match(RegP);
 5629   format %{ &quot;[$reg]&quot; %}
 5630   interface(MEMORY_INTER) %{
 5631     base(0x1e);  // RSP
 5632     index(0x0);  // No Index
 5633     scale(0x0);  // No Scale
 5634     disp($reg);  // Stack Offset
 5635   %}
 5636 %}
 5637 
 5638 operand stackSlotI(sRegI reg)
 5639 %{
 5640   constraint(ALLOC_IN_RC(stack_slots));
 5641   // No match rule because this operand is only generated in matching
 5642   // match(RegI);
 5643   format %{ &quot;[$reg]&quot; %}
 5644   interface(MEMORY_INTER) %{
 5645     base(0x1e);  // RSP
 5646     index(0x0);  // No Index
 5647     scale(0x0);  // No Scale
 5648     disp($reg);  // Stack Offset
 5649   %}
 5650 %}
 5651 
 5652 operand stackSlotF(sRegF reg)
 5653 %{
 5654   constraint(ALLOC_IN_RC(stack_slots));
 5655   // No match rule because this operand is only generated in matching
 5656   // match(RegF);
 5657   format %{ &quot;[$reg]&quot; %}
 5658   interface(MEMORY_INTER) %{
 5659     base(0x1e);  // RSP
 5660     index(0x0);  // No Index
 5661     scale(0x0);  // No Scale
 5662     disp($reg);  // Stack Offset
 5663   %}
 5664 %}
 5665 
 5666 operand stackSlotD(sRegD reg)
 5667 %{
 5668   constraint(ALLOC_IN_RC(stack_slots));
 5669   // No match rule because this operand is only generated in matching
 5670   // match(RegD);
 5671   format %{ &quot;[$reg]&quot; %}
 5672   interface(MEMORY_INTER) %{
 5673     base(0x1e);  // RSP
 5674     index(0x0);  // No Index
 5675     scale(0x0);  // No Scale
 5676     disp($reg);  // Stack Offset
 5677   %}
 5678 %}
 5679 
 5680 operand stackSlotL(sRegL reg)
 5681 %{
 5682   constraint(ALLOC_IN_RC(stack_slots));
 5683   // No match rule because this operand is only generated in matching
 5684   // match(RegL);
 5685   format %{ &quot;[$reg]&quot; %}
 5686   interface(MEMORY_INTER) %{
 5687     base(0x1e);  // RSP
 5688     index(0x0);  // No Index
 5689     scale(0x0);  // No Scale
 5690     disp($reg);  // Stack Offset
 5691   %}
 5692 %}
 5693 
 5694 // Operands for expressing Control Flow
 5695 // NOTE: Label is a predefined operand which should not be redefined in
 5696 //       the AD file. It is generically handled within the ADLC.
 5697 
 5698 //----------Conditional Branch Operands----------------------------------------
 5699 // Comparison Op  - This is the operation of the comparison, and is limited to
 5700 //                  the following set of codes:
 5701 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5702 //
 5703 // Other attributes of the comparison, such as unsignedness, are specified
 5704 // by the comparison instruction that sets a condition code flags register.
 5705 // That result is represented by a flags operand whose subtype is appropriate
 5706 // to the unsignedness (etc.) of the comparison.
 5707 //
 5708 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5709 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5710 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5711 
 5712 // used for signed integral comparisons and fp comparisons
 5713 
 5714 operand cmpOp()
 5715 %{
 5716   match(Bool);
 5717 
 5718   format %{ &quot;&quot; %}
 5719   interface(COND_INTER) %{
 5720     equal(0x0, &quot;eq&quot;);
 5721     not_equal(0x1, &quot;ne&quot;);
 5722     less(0xb, &quot;lt&quot;);
 5723     greater_equal(0xa, &quot;ge&quot;);
 5724     less_equal(0xd, &quot;le&quot;);
 5725     greater(0xc, &quot;gt&quot;);
 5726     overflow(0x6, &quot;vs&quot;);
 5727     no_overflow(0x7, &quot;vc&quot;);
 5728   %}
 5729 %}
 5730 
 5731 // used for unsigned integral comparisons
 5732 
 5733 operand cmpOpU()
 5734 %{
 5735   match(Bool);
 5736 
 5737   format %{ &quot;&quot; %}
 5738   interface(COND_INTER) %{
 5739     equal(0x0, &quot;eq&quot;);
 5740     not_equal(0x1, &quot;ne&quot;);
 5741     less(0x3, &quot;lo&quot;);
 5742     greater_equal(0x2, &quot;hs&quot;);
 5743     less_equal(0x9, &quot;ls&quot;);
 5744     greater(0x8, &quot;hi&quot;);
 5745     overflow(0x6, &quot;vs&quot;);
 5746     no_overflow(0x7, &quot;vc&quot;);
 5747   %}
 5748 %}
 5749 
 5750 // used for certain integral comparisons which can be
 5751 // converted to cbxx or tbxx instructions
 5752 
 5753 operand cmpOpEqNe()
 5754 %{
 5755   match(Bool);
 5756   op_cost(0);
 5757   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5758             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5759 
 5760   format %{ &quot;&quot; %}
 5761   interface(COND_INTER) %{
 5762     equal(0x0, &quot;eq&quot;);
 5763     not_equal(0x1, &quot;ne&quot;);
 5764     less(0xb, &quot;lt&quot;);
 5765     greater_equal(0xa, &quot;ge&quot;);
 5766     less_equal(0xd, &quot;le&quot;);
 5767     greater(0xc, &quot;gt&quot;);
 5768     overflow(0x6, &quot;vs&quot;);
 5769     no_overflow(0x7, &quot;vc&quot;);
 5770   %}
 5771 %}
 5772 
 5773 // used for certain integral comparisons which can be
 5774 // converted to cbxx or tbxx instructions
 5775 
 5776 operand cmpOpLtGe()
 5777 %{
 5778   match(Bool);
 5779   op_cost(0);
 5780 
 5781   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5782             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5783 
 5784   format %{ &quot;&quot; %}
 5785   interface(COND_INTER) %{
 5786     equal(0x0, &quot;eq&quot;);
 5787     not_equal(0x1, &quot;ne&quot;);
 5788     less(0xb, &quot;lt&quot;);
 5789     greater_equal(0xa, &quot;ge&quot;);
 5790     less_equal(0xd, &quot;le&quot;);
 5791     greater(0xc, &quot;gt&quot;);
 5792     overflow(0x6, &quot;vs&quot;);
 5793     no_overflow(0x7, &quot;vc&quot;);
 5794   %}
 5795 %}
 5796 
 5797 // used for certain unsigned integral comparisons which can be
 5798 // converted to cbxx or tbxx instructions
 5799 
 5800 operand cmpOpUEqNeLtGe()
 5801 %{
 5802   match(Bool);
 5803   op_cost(0);
 5804 
 5805   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5806             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5807             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5808             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5809 
 5810   format %{ &quot;&quot; %}
 5811   interface(COND_INTER) %{
 5812     equal(0x0, &quot;eq&quot;);
 5813     not_equal(0x1, &quot;ne&quot;);
 5814     less(0xb, &quot;lt&quot;);
 5815     greater_equal(0xa, &quot;ge&quot;);
 5816     less_equal(0xd, &quot;le&quot;);
 5817     greater(0xc, &quot;gt&quot;);
 5818     overflow(0x6, &quot;vs&quot;);
 5819     no_overflow(0x7, &quot;vc&quot;);
 5820   %}
 5821 %}
 5822 
 5823 // Special operand allowing long args to int ops to be truncated for free
 5824 
 5825 operand iRegL2I(iRegL reg) %{
 5826 
 5827   op_cost(0);
 5828 
 5829   match(ConvL2I reg);
 5830 
 5831   format %{ &quot;l2i($reg)&quot; %}
 5832 
 5833   interface(REG_INTER)
 5834 %}
 5835 
 5836 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5837 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5838 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5839 
 5840 //----------OPERAND CLASSES----------------------------------------------------
 5841 // Operand Classes are groups of operands that are used as to simplify
 5842 // instruction definitions by not requiring the AD writer to specify
 5843 // separate instructions for every form of operand when the
 5844 // instruction accepts multiple operand types with the same basic
 5845 // encoding and format. The classic case of this is memory operands.
 5846 
 5847 // memory is used to define read/write location for load/store
 5848 // instruction defs. we can turn a memory op into an Address
 5849 
 5850 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5851                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5852 
 5853 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5854                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5855 
 5856 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5857                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5858 
 5859 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5860                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5861 
 5862 // All of the memory operands. For the pipeline description.
 5863 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5864                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5865                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5866 
 5867 
 5868 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5869 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5870 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5871 // can be elided because the 32-bit instruction will just employ the
 5872 // lower 32 bits anyway.
 5873 //
 5874 // n.b. this does not elide all L2I conversions. if the truncated
 5875 // value is consumed by more than one operation then the ConvL2I
 5876 // cannot be bundled into the consuming nodes so an l2i gets planted
 5877 // (actually a movw $dst $src) and the downstream instructions consume
 5878 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5879 // movw is actually redundant but its not too costly.
 5880 
 5881 opclass iRegIorL2I(iRegI, iRegL2I);
 5882 
 5883 //----------PIPELINE-----------------------------------------------------------
 5884 // Rules which define the behavior of the target architectures pipeline.
 5885 
 5886 // For specific pipelines, eg A53, define the stages of that pipeline
 5887 //pipe_desc(ISS, EX1, EX2, WR);
 5888 #define ISS S0
 5889 #define EX1 S1
 5890 #define EX2 S2
 5891 #define WR  S3
 5892 
 5893 // Integer ALU reg operation
 5894 pipeline %{
 5895 
 5896 attributes %{
 5897   // ARM instructions are of fixed length
 5898   fixed_size_instructions;        // Fixed size instructions TODO does
<a name="15" id="anc15"></a><span class="line-modified"> 5899   max_instructions_per_bundle = 4;   // A53 = 2, A57 = 4</span>
 5900   // ARM instructions come in 32-bit word units
 5901   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5902   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5903   instruction_fetch_units = 1;       // of 64 bytes
 5904 
 5905   // List of nop instructions
 5906   nops( MachNop );
 5907 %}
 5908 
 5909 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5910 // or description. we do use pipeline classes to introduce fixed
 5911 // latencies
 5912 
 5913 //----------RESOURCES----------------------------------------------------------
 5914 // Resources are the functional units available to the machine
 5915 
 5916 resources( INS0, INS1, INS01 = INS0 | INS1,
 5917            ALU0, ALU1, ALU = ALU0 | ALU1,
 5918            MAC,
 5919            DIV,
 5920            BRANCH,
 5921            LDST,
 5922            NEON_FP);
 5923 
 5924 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5925 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5926 
 5927 // Define the pipeline as a generic 6 stage pipeline
 5928 pipe_desc(S0, S1, S2, S3, S4, S5);
 5929 
 5930 //----------PIPELINE CLASSES---------------------------------------------------
 5931 // Pipeline Classes describe the stages in which input and output are
 5932 // referenced by the hardware pipeline.
 5933 
 5934 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5935 %{
 5936   single_instruction;
 5937   src1   : S1(read);
 5938   src2   : S2(read);
 5939   dst    : S5(write);
 5940   INS01  : ISS;
 5941   NEON_FP : S5;
 5942 %}
 5943 
 5944 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5945 %{
 5946   single_instruction;
 5947   src1   : S1(read);
 5948   src2   : S2(read);
 5949   dst    : S5(write);
 5950   INS01  : ISS;
 5951   NEON_FP : S5;
 5952 %}
 5953 
 5954 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5955 %{
 5956   single_instruction;
 5957   src    : S1(read);
 5958   dst    : S5(write);
 5959   INS01  : ISS;
 5960   NEON_FP : S5;
 5961 %}
 5962 
 5963 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5964 %{
 5965   single_instruction;
 5966   src    : S1(read);
 5967   dst    : S5(write);
 5968   INS01  : ISS;
 5969   NEON_FP : S5;
 5970 %}
 5971 
 5972 pipe_class fp_d2f(vRegF dst, vRegD src)
 5973 %{
 5974   single_instruction;
 5975   src    : S1(read);
 5976   dst    : S5(write);
 5977   INS01  : ISS;
 5978   NEON_FP : S5;
 5979 %}
 5980 
 5981 pipe_class fp_f2d(vRegD dst, vRegF src)
 5982 %{
 5983   single_instruction;
 5984   src    : S1(read);
 5985   dst    : S5(write);
 5986   INS01  : ISS;
 5987   NEON_FP : S5;
 5988 %}
 5989 
 5990 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5991 %{
 5992   single_instruction;
 5993   src    : S1(read);
 5994   dst    : S5(write);
 5995   INS01  : ISS;
 5996   NEON_FP : S5;
 5997 %}
 5998 
 5999 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 6000 %{
 6001   single_instruction;
 6002   src    : S1(read);
 6003   dst    : S5(write);
 6004   INS01  : ISS;
 6005   NEON_FP : S5;
 6006 %}
 6007 
 6008 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6009 %{
 6010   single_instruction;
 6011   src    : S1(read);
 6012   dst    : S5(write);
 6013   INS01  : ISS;
 6014   NEON_FP : S5;
 6015 %}
 6016 
 6017 pipe_class fp_l2f(vRegF dst, iRegL src)
 6018 %{
 6019   single_instruction;
 6020   src    : S1(read);
 6021   dst    : S5(write);
 6022   INS01  : ISS;
 6023   NEON_FP : S5;
 6024 %}
 6025 
 6026 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6027 %{
 6028   single_instruction;
 6029   src    : S1(read);
 6030   dst    : S5(write);
 6031   INS01  : ISS;
 6032   NEON_FP : S5;
 6033 %}
 6034 
 6035 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6036 %{
 6037   single_instruction;
 6038   src    : S1(read);
 6039   dst    : S5(write);
 6040   INS01  : ISS;
 6041   NEON_FP : S5;
 6042 %}
 6043 
 6044 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6045 %{
 6046   single_instruction;
 6047   src    : S1(read);
 6048   dst    : S5(write);
 6049   INS01  : ISS;
 6050   NEON_FP : S5;
 6051 %}
 6052 
 6053 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6054 %{
 6055   single_instruction;
 6056   src    : S1(read);
 6057   dst    : S5(write);
 6058   INS01  : ISS;
 6059   NEON_FP : S5;
 6060 %}
 6061 
 6062 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6063 %{
 6064   single_instruction;
 6065   src1   : S1(read);
 6066   src2   : S2(read);
 6067   dst    : S5(write);
 6068   INS0   : ISS;
 6069   NEON_FP : S5;
 6070 %}
 6071 
 6072 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6073 %{
 6074   single_instruction;
 6075   src1   : S1(read);
 6076   src2   : S2(read);
 6077   dst    : S5(write);
 6078   INS0   : ISS;
 6079   NEON_FP : S5;
 6080 %}
 6081 
 6082 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6083 %{
 6084   single_instruction;
 6085   cr     : S1(read);
 6086   src1   : S1(read);
 6087   src2   : S1(read);
 6088   dst    : S3(write);
 6089   INS01  : ISS;
 6090   NEON_FP : S3;
 6091 %}
 6092 
 6093 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6094 %{
 6095   single_instruction;
 6096   cr     : S1(read);
 6097   src1   : S1(read);
 6098   src2   : S1(read);
 6099   dst    : S3(write);
 6100   INS01  : ISS;
 6101   NEON_FP : S3;
 6102 %}
 6103 
 6104 pipe_class fp_imm_s(vRegF dst)
 6105 %{
 6106   single_instruction;
 6107   dst    : S3(write);
 6108   INS01  : ISS;
 6109   NEON_FP : S3;
 6110 %}
 6111 
 6112 pipe_class fp_imm_d(vRegD dst)
 6113 %{
 6114   single_instruction;
 6115   dst    : S3(write);
 6116   INS01  : ISS;
 6117   NEON_FP : S3;
 6118 %}
 6119 
 6120 pipe_class fp_load_constant_s(vRegF dst)
 6121 %{
 6122   single_instruction;
 6123   dst    : S4(write);
 6124   INS01  : ISS;
 6125   NEON_FP : S4;
 6126 %}
 6127 
 6128 pipe_class fp_load_constant_d(vRegD dst)
 6129 %{
 6130   single_instruction;
 6131   dst    : S4(write);
 6132   INS01  : ISS;
 6133   NEON_FP : S4;
 6134 %}
 6135 
 6136 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6137 %{
 6138   single_instruction;
 6139   dst    : S5(write);
 6140   src1   : S1(read);
 6141   src2   : S1(read);
 6142   INS01  : ISS;
 6143   NEON_FP : S5;
 6144 %}
 6145 
 6146 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6147 %{
 6148   single_instruction;
 6149   dst    : S5(write);
 6150   src1   : S1(read);
 6151   src2   : S1(read);
 6152   INS0   : ISS;
 6153   NEON_FP : S5;
 6154 %}
 6155 
 6156 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6157 %{
 6158   single_instruction;
 6159   dst    : S5(write);
 6160   src1   : S1(read);
 6161   src2   : S1(read);
 6162   dst    : S1(read);
 6163   INS01  : ISS;
 6164   NEON_FP : S5;
 6165 %}
 6166 
 6167 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6168 %{
 6169   single_instruction;
 6170   dst    : S5(write);
 6171   src1   : S1(read);
 6172   src2   : S1(read);
 6173   dst    : S1(read);
 6174   INS0   : ISS;
 6175   NEON_FP : S5;
 6176 %}
 6177 
 6178 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6179 %{
 6180   single_instruction;
 6181   dst    : S4(write);
 6182   src1   : S2(read);
 6183   src2   : S2(read);
 6184   INS01  : ISS;
 6185   NEON_FP : S4;
 6186 %}
 6187 
 6188 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6189 %{
 6190   single_instruction;
 6191   dst    : S4(write);
 6192   src1   : S2(read);
 6193   src2   : S2(read);
 6194   INS0   : ISS;
 6195   NEON_FP : S4;
 6196 %}
 6197 
 6198 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6199 %{
 6200   single_instruction;
 6201   dst    : S3(write);
 6202   src1   : S2(read);
 6203   src2   : S2(read);
 6204   INS01  : ISS;
 6205   NEON_FP : S3;
 6206 %}
 6207 
 6208 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6209 %{
 6210   single_instruction;
 6211   dst    : S3(write);
 6212   src1   : S2(read);
 6213   src2   : S2(read);
 6214   INS0   : ISS;
 6215   NEON_FP : S3;
 6216 %}
 6217 
 6218 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6219 %{
 6220   single_instruction;
 6221   dst    : S3(write);
 6222   src    : S1(read);
 6223   shift  : S1(read);
 6224   INS01  : ISS;
 6225   NEON_FP : S3;
 6226 %}
 6227 
 6228 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6229 %{
 6230   single_instruction;
 6231   dst    : S3(write);
 6232   src    : S1(read);
 6233   shift  : S1(read);
 6234   INS0   : ISS;
 6235   NEON_FP : S3;
 6236 %}
 6237 
 6238 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6239 %{
 6240   single_instruction;
 6241   dst    : S3(write);
 6242   src    : S1(read);
 6243   INS01  : ISS;
 6244   NEON_FP : S3;
 6245 %}
 6246 
 6247 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6248 %{
 6249   single_instruction;
 6250   dst    : S3(write);
 6251   src    : S1(read);
 6252   INS0   : ISS;
 6253   NEON_FP : S3;
 6254 %}
 6255 
 6256 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6257 %{
 6258   single_instruction;
 6259   dst    : S5(write);
 6260   src1   : S1(read);
 6261   src2   : S1(read);
 6262   INS01  : ISS;
 6263   NEON_FP : S5;
 6264 %}
 6265 
 6266 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6267 %{
 6268   single_instruction;
 6269   dst    : S5(write);
 6270   src1   : S1(read);
 6271   src2   : S1(read);
 6272   INS0   : ISS;
 6273   NEON_FP : S5;
 6274 %}
 6275 
 6276 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6277 %{
 6278   single_instruction;
 6279   dst    : S5(write);
 6280   src1   : S1(read);
 6281   src2   : S1(read);
 6282   INS0   : ISS;
 6283   NEON_FP : S5;
 6284 %}
 6285 
 6286 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6287 %{
 6288   single_instruction;
 6289   dst    : S5(write);
 6290   src1   : S1(read);
 6291   src2   : S1(read);
 6292   INS0   : ISS;
 6293   NEON_FP : S5;
 6294 %}
 6295 
 6296 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6297 %{
 6298   single_instruction;
 6299   dst    : S5(write);
 6300   src    : S1(read);
 6301   INS0   : ISS;
 6302   NEON_FP : S5;
 6303 %}
 6304 
 6305 pipe_class vunop_fp64(vecD dst, vecD src)
 6306 %{
 6307   single_instruction;
 6308   dst    : S5(write);
 6309   src    : S1(read);
 6310   INS01  : ISS;
 6311   NEON_FP : S5;
 6312 %}
 6313 
 6314 pipe_class vunop_fp128(vecX dst, vecX src)
 6315 %{
 6316   single_instruction;
 6317   dst    : S5(write);
 6318   src    : S1(read);
 6319   INS0   : ISS;
 6320   NEON_FP : S5;
 6321 %}
 6322 
 6323 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6324 %{
 6325   single_instruction;
 6326   dst    : S3(write);
 6327   src    : S1(read);
 6328   INS01  : ISS;
 6329   NEON_FP : S3;
 6330 %}
 6331 
 6332 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6333 %{
 6334   single_instruction;
 6335   dst    : S3(write);
 6336   src    : S1(read);
 6337   INS01  : ISS;
 6338   NEON_FP : S3;
 6339 %}
 6340 
 6341 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6342 %{
 6343   single_instruction;
 6344   dst    : S3(write);
 6345   src    : S1(read);
 6346   INS01  : ISS;
 6347   NEON_FP : S3;
 6348 %}
 6349 
 6350 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6351 %{
 6352   single_instruction;
 6353   dst    : S3(write);
 6354   src    : S1(read);
 6355   INS01  : ISS;
 6356   NEON_FP : S3;
 6357 %}
 6358 
 6359 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6360 %{
 6361   single_instruction;
 6362   dst    : S3(write);
 6363   src    : S1(read);
 6364   INS01  : ISS;
 6365   NEON_FP : S3;
 6366 %}
 6367 
 6368 pipe_class vmovi_reg_imm64(vecD dst)
 6369 %{
 6370   single_instruction;
 6371   dst    : S3(write);
 6372   INS01  : ISS;
 6373   NEON_FP : S3;
 6374 %}
 6375 
 6376 pipe_class vmovi_reg_imm128(vecX dst)
 6377 %{
 6378   single_instruction;
 6379   dst    : S3(write);
 6380   INS0   : ISS;
 6381   NEON_FP : S3;
 6382 %}
 6383 
 6384 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6385 %{
 6386   single_instruction;
 6387   dst    : S5(write);
 6388   mem    : ISS(read);
 6389   INS01  : ISS;
 6390   NEON_FP : S3;
 6391 %}
 6392 
 6393 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6394 %{
 6395   single_instruction;
 6396   dst    : S5(write);
 6397   mem    : ISS(read);
 6398   INS01  : ISS;
 6399   NEON_FP : S3;
 6400 %}
 6401 
 6402 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6403 %{
 6404   single_instruction;
 6405   mem    : ISS(read);
 6406   src    : S2(read);
 6407   INS01  : ISS;
 6408   NEON_FP : S3;
 6409 %}
 6410 
 6411 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6412 %{
 6413   single_instruction;
 6414   mem    : ISS(read);
 6415   src    : S2(read);
 6416   INS01  : ISS;
 6417   NEON_FP : S3;
 6418 %}
 6419 
 6420 //------- Integer ALU operations --------------------------
 6421 
 6422 // Integer ALU reg-reg operation
 6423 // Operands needed in EX1, result generated in EX2
 6424 // Eg.  ADD     x0, x1, x2
 6425 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6426 %{
 6427   single_instruction;
 6428   dst    : EX2(write);
 6429   src1   : EX1(read);
 6430   src2   : EX1(read);
 6431   INS01  : ISS; // Dual issue as instruction 0 or 1
 6432   ALU    : EX2;
 6433 %}
 6434 
 6435 // Integer ALU reg-reg operation with constant shift
 6436 // Shifted register must be available in LATE_ISS instead of EX1
 6437 // Eg.  ADD     x0, x1, x2, LSL #2
 6438 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6439 %{
 6440   single_instruction;
 6441   dst    : EX2(write);
 6442   src1   : EX1(read);
 6443   src2   : ISS(read);
 6444   INS01  : ISS;
 6445   ALU    : EX2;
 6446 %}
 6447 
 6448 // Integer ALU reg operation with constant shift
 6449 // Eg.  LSL     x0, x1, #shift
 6450 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6451 %{
 6452   single_instruction;
 6453   dst    : EX2(write);
 6454   src1   : ISS(read);
 6455   INS01  : ISS;
 6456   ALU    : EX2;
 6457 %}
 6458 
 6459 // Integer ALU reg-reg operation with variable shift
 6460 // Both operands must be available in LATE_ISS instead of EX1
 6461 // Result is available in EX1 instead of EX2
 6462 // Eg.  LSLV    x0, x1, x2
 6463 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6464 %{
 6465   single_instruction;
 6466   dst    : EX1(write);
 6467   src1   : ISS(read);
 6468   src2   : ISS(read);
 6469   INS01  : ISS;
 6470   ALU    : EX1;
 6471 %}
 6472 
 6473 // Integer ALU reg-reg operation with extract
 6474 // As for _vshift above, but result generated in EX2
 6475 // Eg.  EXTR    x0, x1, x2, #N
 6476 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6477 %{
 6478   single_instruction;
 6479   dst    : EX2(write);
 6480   src1   : ISS(read);
 6481   src2   : ISS(read);
 6482   INS1   : ISS; // Can only dual issue as Instruction 1
 6483   ALU    : EX1;
 6484 %}
 6485 
 6486 // Integer ALU reg operation
 6487 // Eg.  NEG     x0, x1
 6488 pipe_class ialu_reg(iRegI dst, iRegI src)
 6489 %{
 6490   single_instruction;
 6491   dst    : EX2(write);
 6492   src    : EX1(read);
 6493   INS01  : ISS;
 6494   ALU    : EX2;
 6495 %}
 6496 
 6497 // Integer ALU reg mmediate operation
 6498 // Eg.  ADD     x0, x1, #N
 6499 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6500 %{
 6501   single_instruction;
 6502   dst    : EX2(write);
 6503   src1   : EX1(read);
 6504   INS01  : ISS;
 6505   ALU    : EX2;
 6506 %}
 6507 
 6508 // Integer ALU immediate operation (no source operands)
 6509 // Eg.  MOV     x0, #N
 6510 pipe_class ialu_imm(iRegI dst)
 6511 %{
 6512   single_instruction;
 6513   dst    : EX1(write);
 6514   INS01  : ISS;
 6515   ALU    : EX1;
 6516 %}
 6517 
 6518 //------- Compare operation -------------------------------
 6519 
 6520 // Compare reg-reg
 6521 // Eg.  CMP     x0, x1
 6522 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6523 %{
 6524   single_instruction;
 6525 //  fixed_latency(16);
 6526   cr     : EX2(write);
 6527   op1    : EX1(read);
 6528   op2    : EX1(read);
 6529   INS01  : ISS;
 6530   ALU    : EX2;
 6531 %}
 6532 
 6533 // Compare reg-reg
 6534 // Eg.  CMP     x0, #N
 6535 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6536 %{
 6537   single_instruction;
 6538 //  fixed_latency(16);
 6539   cr     : EX2(write);
 6540   op1    : EX1(read);
 6541   INS01  : ISS;
 6542   ALU    : EX2;
 6543 %}
 6544 
 6545 //------- Conditional instructions ------------------------
 6546 
 6547 // Conditional no operands
 6548 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6549 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6550 %{
 6551   single_instruction;
 6552   cr     : EX1(read);
 6553   dst    : EX2(write);
 6554   INS01  : ISS;
 6555   ALU    : EX2;
 6556 %}
 6557 
 6558 // Conditional 2 operand
 6559 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6560 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6561 %{
 6562   single_instruction;
 6563   cr     : EX1(read);
 6564   src1   : EX1(read);
 6565   src2   : EX1(read);
 6566   dst    : EX2(write);
 6567   INS01  : ISS;
 6568   ALU    : EX2;
 6569 %}
 6570 
 6571 // Conditional 2 operand
 6572 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6573 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6574 %{
 6575   single_instruction;
 6576   cr     : EX1(read);
 6577   src    : EX1(read);
 6578   dst    : EX2(write);
 6579   INS01  : ISS;
 6580   ALU    : EX2;
 6581 %}
 6582 
 6583 //------- Multiply pipeline operations --------------------
 6584 
 6585 // Multiply reg-reg
 6586 // Eg.  MUL     w0, w1, w2
 6587 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6588 %{
 6589   single_instruction;
 6590   dst    : WR(write);
 6591   src1   : ISS(read);
 6592   src2   : ISS(read);
 6593   INS01  : ISS;
 6594   MAC    : WR;
 6595 %}
 6596 
 6597 // Multiply accumulate
 6598 // Eg.  MADD    w0, w1, w2, w3
 6599 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6600 %{
 6601   single_instruction;
 6602   dst    : WR(write);
 6603   src1   : ISS(read);
 6604   src2   : ISS(read);
 6605   src3   : ISS(read);
 6606   INS01  : ISS;
 6607   MAC    : WR;
 6608 %}
 6609 
 6610 // Eg.  MUL     w0, w1, w2
 6611 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6612 %{
 6613   single_instruction;
 6614   fixed_latency(3); // Maximum latency for 64 bit mul
 6615   dst    : WR(write);
 6616   src1   : ISS(read);
 6617   src2   : ISS(read);
 6618   INS01  : ISS;
 6619   MAC    : WR;
 6620 %}
 6621 
 6622 // Multiply accumulate
 6623 // Eg.  MADD    w0, w1, w2, w3
 6624 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6625 %{
 6626   single_instruction;
 6627   fixed_latency(3); // Maximum latency for 64 bit mul
 6628   dst    : WR(write);
 6629   src1   : ISS(read);
 6630   src2   : ISS(read);
 6631   src3   : ISS(read);
 6632   INS01  : ISS;
 6633   MAC    : WR;
 6634 %}
 6635 
 6636 //------- Divide pipeline operations --------------------
 6637 
 6638 // Eg.  SDIV    w0, w1, w2
 6639 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6640 %{
 6641   single_instruction;
 6642   fixed_latency(8); // Maximum latency for 32 bit divide
 6643   dst    : WR(write);
 6644   src1   : ISS(read);
 6645   src2   : ISS(read);
 6646   INS0   : ISS; // Can only dual issue as instruction 0
 6647   DIV    : WR;
 6648 %}
 6649 
 6650 // Eg.  SDIV    x0, x1, x2
 6651 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6652 %{
 6653   single_instruction;
 6654   fixed_latency(16); // Maximum latency for 64 bit divide
 6655   dst    : WR(write);
 6656   src1   : ISS(read);
 6657   src2   : ISS(read);
 6658   INS0   : ISS; // Can only dual issue as instruction 0
 6659   DIV    : WR;
 6660 %}
 6661 
 6662 //------- Load pipeline operations ------------------------
 6663 
 6664 // Load - prefetch
 6665 // Eg.  PFRM    &lt;mem&gt;
 6666 pipe_class iload_prefetch(memory mem)
 6667 %{
 6668   single_instruction;
 6669   mem    : ISS(read);
 6670   INS01  : ISS;
 6671   LDST   : WR;
 6672 %}
 6673 
 6674 // Load - reg, mem
 6675 // Eg.  LDR     x0, &lt;mem&gt;
 6676 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6677 %{
 6678   single_instruction;
 6679   dst    : WR(write);
 6680   mem    : ISS(read);
 6681   INS01  : ISS;
 6682   LDST   : WR;
 6683 %}
 6684 
 6685 // Load - reg, reg
 6686 // Eg.  LDR     x0, [sp, x1]
 6687 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6688 %{
 6689   single_instruction;
 6690   dst    : WR(write);
 6691   src    : ISS(read);
 6692   INS01  : ISS;
 6693   LDST   : WR;
 6694 %}
 6695 
 6696 //------- Store pipeline operations -----------------------
 6697 
 6698 // Store - zr, mem
 6699 // Eg.  STR     zr, &lt;mem&gt;
 6700 pipe_class istore_mem(memory mem)
 6701 %{
 6702   single_instruction;
 6703   mem    : ISS(read);
 6704   INS01  : ISS;
 6705   LDST   : WR;
 6706 %}
 6707 
 6708 // Store - reg, mem
 6709 // Eg.  STR     x0, &lt;mem&gt;
 6710 pipe_class istore_reg_mem(iRegI src, memory mem)
 6711 %{
 6712   single_instruction;
 6713   mem    : ISS(read);
 6714   src    : EX2(read);
 6715   INS01  : ISS;
 6716   LDST   : WR;
 6717 %}
 6718 
 6719 // Store - reg, reg
 6720 // Eg. STR      x0, [sp, x1]
 6721 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6722 %{
 6723   single_instruction;
 6724   dst    : ISS(read);
 6725   src    : EX2(read);
 6726   INS01  : ISS;
 6727   LDST   : WR;
 6728 %}
 6729 
 6730 //------- Store pipeline operations -----------------------
 6731 
 6732 // Branch
 6733 pipe_class pipe_branch()
 6734 %{
 6735   single_instruction;
 6736   INS01  : ISS;
 6737   BRANCH : EX1;
 6738 %}
 6739 
 6740 // Conditional branch
 6741 pipe_class pipe_branch_cond(rFlagsReg cr)
 6742 %{
 6743   single_instruction;
 6744   cr     : EX1(read);
 6745   INS01  : ISS;
 6746   BRANCH : EX1;
 6747 %}
 6748 
 6749 // Compare &amp; Branch
 6750 // EG.  CBZ/CBNZ
 6751 pipe_class pipe_cmp_branch(iRegI op1)
 6752 %{
 6753   single_instruction;
 6754   op1    : EX1(read);
 6755   INS01  : ISS;
 6756   BRANCH : EX1;
 6757 %}
 6758 
 6759 //------- Synchronisation operations ----------------------
 6760 
 6761 // Any operation requiring serialization.
 6762 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6763 pipe_class pipe_serial()
 6764 %{
 6765   single_instruction;
 6766   force_serialization;
 6767   fixed_latency(16);
 6768   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6769   LDST   : WR;
 6770 %}
 6771 
 6772 // Generic big/slow expanded idiom - also serialized
 6773 pipe_class pipe_slow()
 6774 %{
 6775   instruction_count(10);
 6776   multiple_bundles;
 6777   force_serialization;
 6778   fixed_latency(16);
 6779   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6780   LDST   : WR;
 6781 %}
 6782 
 6783 // Empty pipeline class
 6784 pipe_class pipe_class_empty()
 6785 %{
 6786   single_instruction;
 6787   fixed_latency(0);
 6788 %}
 6789 
 6790 // Default pipeline class.
 6791 pipe_class pipe_class_default()
 6792 %{
 6793   single_instruction;
 6794   fixed_latency(2);
 6795 %}
 6796 
 6797 // Pipeline class for compares.
 6798 pipe_class pipe_class_compare()
 6799 %{
 6800   single_instruction;
 6801   fixed_latency(16);
 6802 %}
 6803 
 6804 // Pipeline class for memory operations.
 6805 pipe_class pipe_class_memory()
 6806 %{
 6807   single_instruction;
 6808   fixed_latency(16);
 6809 %}
 6810 
 6811 // Pipeline class for call.
 6812 pipe_class pipe_class_call()
 6813 %{
 6814   single_instruction;
 6815   fixed_latency(100);
 6816 %}
 6817 
 6818 // Define the class for the Nop node.
 6819 define %{
 6820    MachNop = pipe_class_empty;
 6821 %}
 6822 
 6823 %}
 6824 //----------INSTRUCTIONS-------------------------------------------------------
 6825 //
 6826 // match      -- States which machine-independent subtree may be replaced
 6827 //               by this instruction.
 6828 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6829 //               selection to identify a minimum cost tree of machine
 6830 //               instructions that matches a tree of machine-independent
 6831 //               instructions.
 6832 // format     -- A string providing the disassembly for this instruction.
 6833 //               The value of an instruction&#39;s operand may be inserted
 6834 //               by referring to it with a &#39;$&#39; prefix.
 6835 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6836 //               to within an encode class as $primary, $secondary, and $tertiary
 6837 //               rrspectively.  The primary opcode is commonly used to
 6838 //               indicate the type of machine instruction, while secondary
 6839 //               and tertiary are often used for prefix options or addressing
 6840 //               modes.
 6841 // ins_encode -- A list of encode classes with parameters. The encode class
 6842 //               name must have been defined in an &#39;enc_class&#39; specification
 6843 //               in the encode section of the architecture description.
 6844 
 6845 // ============================================================================
 6846 // Memory (Load/Store) Instructions
 6847 
 6848 // Load Instructions
 6849 
 6850 // Load Byte (8 bit signed)
 6851 instruct loadB(iRegINoSp dst, memory1 mem)
 6852 %{
 6853   match(Set dst (LoadB mem));
 6854   predicate(!needs_acquiring_load(n));
 6855 
 6856   ins_cost(4 * INSN_COST);
 6857   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6858 
 6859   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6860 
 6861   ins_pipe(iload_reg_mem);
 6862 %}
 6863 
 6864 // Load Byte (8 bit signed) into long
 6865 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6866 %{
 6867   match(Set dst (ConvI2L (LoadB mem)));
 6868   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6869 
 6870   ins_cost(4 * INSN_COST);
 6871   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6872 
 6873   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6874 
 6875   ins_pipe(iload_reg_mem);
 6876 %}
 6877 
 6878 // Load Byte (8 bit unsigned)
 6879 instruct loadUB(iRegINoSp dst, memory1 mem)
 6880 %{
 6881   match(Set dst (LoadUB mem));
 6882   predicate(!needs_acquiring_load(n));
 6883 
 6884   ins_cost(4 * INSN_COST);
 6885   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6886 
 6887   ins_encode(aarch64_enc_ldrb(dst, mem));
 6888 
 6889   ins_pipe(iload_reg_mem);
 6890 %}
 6891 
 6892 // Load Byte (8 bit unsigned) into long
 6893 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6894 %{
 6895   match(Set dst (ConvI2L (LoadUB mem)));
 6896   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6897 
 6898   ins_cost(4 * INSN_COST);
 6899   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6900 
 6901   ins_encode(aarch64_enc_ldrb(dst, mem));
 6902 
 6903   ins_pipe(iload_reg_mem);
 6904 %}
 6905 
 6906 // Load Short (16 bit signed)
 6907 instruct loadS(iRegINoSp dst, memory2 mem)
 6908 %{
 6909   match(Set dst (LoadS mem));
 6910   predicate(!needs_acquiring_load(n));
 6911 
 6912   ins_cost(4 * INSN_COST);
 6913   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6914 
 6915   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6916 
 6917   ins_pipe(iload_reg_mem);
 6918 %}
 6919 
 6920 // Load Short (16 bit signed) into long
 6921 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6922 %{
 6923   match(Set dst (ConvI2L (LoadS mem)));
 6924   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6925 
 6926   ins_cost(4 * INSN_COST);
 6927   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6928 
 6929   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6930 
 6931   ins_pipe(iload_reg_mem);
 6932 %}
 6933 
 6934 // Load Char (16 bit unsigned)
 6935 instruct loadUS(iRegINoSp dst, memory2 mem)
 6936 %{
 6937   match(Set dst (LoadUS mem));
 6938   predicate(!needs_acquiring_load(n));
 6939 
 6940   ins_cost(4 * INSN_COST);
 6941   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6942 
 6943   ins_encode(aarch64_enc_ldrh(dst, mem));
 6944 
 6945   ins_pipe(iload_reg_mem);
 6946 %}
 6947 
 6948 // Load Short/Char (16 bit unsigned) into long
 6949 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6950 %{
 6951   match(Set dst (ConvI2L (LoadUS mem)));
 6952   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6953 
 6954   ins_cost(4 * INSN_COST);
 6955   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6956 
 6957   ins_encode(aarch64_enc_ldrh(dst, mem));
 6958 
 6959   ins_pipe(iload_reg_mem);
 6960 %}
 6961 
 6962 // Load Integer (32 bit signed)
 6963 instruct loadI(iRegINoSp dst, memory4 mem)
 6964 %{
 6965   match(Set dst (LoadI mem));
 6966   predicate(!needs_acquiring_load(n));
 6967 
 6968   ins_cost(4 * INSN_COST);
 6969   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6970 
 6971   ins_encode(aarch64_enc_ldrw(dst, mem));
 6972 
 6973   ins_pipe(iload_reg_mem);
 6974 %}
 6975 
 6976 // Load Integer (32 bit signed) into long
 6977 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6978 %{
 6979   match(Set dst (ConvI2L (LoadI mem)));
 6980   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6981 
 6982   ins_cost(4 * INSN_COST);
 6983   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6984 
 6985   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6986 
 6987   ins_pipe(iload_reg_mem);
 6988 %}
 6989 
 6990 // Load Integer (32 bit unsigned) into long
 6991 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6992 %{
 6993   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6994   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 6995 
 6996   ins_cost(4 * INSN_COST);
 6997   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6998 
 6999   ins_encode(aarch64_enc_ldrw(dst, mem));
 7000 
 7001   ins_pipe(iload_reg_mem);
 7002 %}
 7003 
 7004 // Load Long (64 bit signed)
 7005 instruct loadL(iRegLNoSp dst, memory8 mem)
 7006 %{
 7007   match(Set dst (LoadL mem));
 7008   predicate(!needs_acquiring_load(n));
 7009 
 7010   ins_cost(4 * INSN_COST);
 7011   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7012 
 7013   ins_encode(aarch64_enc_ldr(dst, mem));
 7014 
 7015   ins_pipe(iload_reg_mem);
 7016 %}
 7017 
 7018 // Load Range
 7019 instruct loadRange(iRegINoSp dst, memory4 mem)
 7020 %{
 7021   match(Set dst (LoadRange mem));
 7022 
 7023   ins_cost(4 * INSN_COST);
 7024   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7025 
 7026   ins_encode(aarch64_enc_ldrw(dst, mem));
 7027 
 7028   ins_pipe(iload_reg_mem);
 7029 %}
 7030 
 7031 // Load Pointer
 7032 instruct loadP(iRegPNoSp dst, memory8 mem)
 7033 %{
 7034   match(Set dst (LoadP mem));
 7035   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7036 
 7037   ins_cost(4 * INSN_COST);
 7038   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7039 
 7040   ins_encode(aarch64_enc_ldr(dst, mem));
 7041 
 7042   ins_pipe(iload_reg_mem);
 7043 %}
 7044 
 7045 // Load Compressed Pointer
 7046 instruct loadN(iRegNNoSp dst, memory4 mem)
 7047 %{
 7048   match(Set dst (LoadN mem));
 7049   predicate(!needs_acquiring_load(n));
 7050 
 7051   ins_cost(4 * INSN_COST);
 7052   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7053 
 7054   ins_encode(aarch64_enc_ldrw(dst, mem));
 7055 
 7056   ins_pipe(iload_reg_mem);
 7057 %}
 7058 
 7059 // Load Klass Pointer
 7060 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7061 %{
 7062   match(Set dst (LoadKlass mem));
 7063   predicate(!needs_acquiring_load(n));
 7064 
 7065   ins_cost(4 * INSN_COST);
 7066   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7067 
 7068   ins_encode(aarch64_enc_ldr(dst, mem));
 7069 
 7070   ins_pipe(iload_reg_mem);
 7071 %}
 7072 
 7073 // Load Narrow Klass Pointer
 7074 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7075 %{
 7076   match(Set dst (LoadNKlass mem));
 7077   predicate(!needs_acquiring_load(n));
 7078 
 7079   ins_cost(4 * INSN_COST);
 7080   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7081 
 7082   ins_encode(aarch64_enc_ldrw(dst, mem));
 7083 
 7084   ins_pipe(iload_reg_mem);
 7085 %}
 7086 
 7087 // Load Float
 7088 instruct loadF(vRegF dst, memory4 mem)
 7089 %{
 7090   match(Set dst (LoadF mem));
 7091   predicate(!needs_acquiring_load(n));
 7092 
 7093   ins_cost(4 * INSN_COST);
 7094   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7095 
 7096   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7097 
 7098   ins_pipe(pipe_class_memory);
 7099 %}
 7100 
 7101 // Load Double
 7102 instruct loadD(vRegD dst, memory8 mem)
 7103 %{
 7104   match(Set dst (LoadD mem));
 7105   predicate(!needs_acquiring_load(n));
 7106 
 7107   ins_cost(4 * INSN_COST);
 7108   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7109 
 7110   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7111 
 7112   ins_pipe(pipe_class_memory);
 7113 %}
 7114 
 7115 
 7116 // Load Int Constant
 7117 instruct loadConI(iRegINoSp dst, immI src)
 7118 %{
 7119   match(Set dst src);
 7120 
 7121   ins_cost(INSN_COST);
 7122   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7123 
 7124   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7125 
 7126   ins_pipe(ialu_imm);
 7127 %}
 7128 
 7129 // Load Long Constant
 7130 instruct loadConL(iRegLNoSp dst, immL src)
 7131 %{
 7132   match(Set dst src);
 7133 
 7134   ins_cost(INSN_COST);
<a name="16" id="anc16"></a><span class="line-modified"> 7135   format %{ &quot;mov $dst, $src\t# int64_t&quot; %}</span>
 7136 
 7137   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7138 
 7139   ins_pipe(ialu_imm);
 7140 %}
 7141 
 7142 // Load Pointer Constant
 7143 
 7144 instruct loadConP(iRegPNoSp dst, immP con)
 7145 %{
 7146   match(Set dst con);
 7147 
 7148   ins_cost(INSN_COST * 4);
 7149   format %{
 7150     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7151   %}
 7152 
 7153   ins_encode(aarch64_enc_mov_p(dst, con));
 7154 
 7155   ins_pipe(ialu_imm);
 7156 %}
 7157 
 7158 // Load Null Pointer Constant
 7159 
 7160 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7161 %{
 7162   match(Set dst con);
 7163 
 7164   ins_cost(INSN_COST);
 7165   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7166 
 7167   ins_encode(aarch64_enc_mov_p0(dst, con));
 7168 
 7169   ins_pipe(ialu_imm);
 7170 %}
 7171 
 7172 // Load Pointer Constant One
 7173 
 7174 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7175 %{
 7176   match(Set dst con);
 7177 
 7178   ins_cost(INSN_COST);
 7179   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7180 
 7181   ins_encode(aarch64_enc_mov_p1(dst, con));
 7182 
 7183   ins_pipe(ialu_imm);
 7184 %}
 7185 
 7186 // Load Poll Page Constant
 7187 
 7188 instruct loadConPollPage(iRegPNoSp dst, immPollPage con)
 7189 %{
 7190   match(Set dst con);
 7191 
 7192   ins_cost(INSN_COST);
 7193   format %{ &quot;adr  $dst, $con\t# Poll Page Ptr&quot; %}
 7194 
 7195   ins_encode(aarch64_enc_mov_poll_page(dst, con));
 7196 
 7197   ins_pipe(ialu_imm);
 7198 %}
 7199 
 7200 // Load Byte Map Base Constant
 7201 
 7202 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7203 %{
 7204   match(Set dst con);
 7205 
 7206   ins_cost(INSN_COST);
 7207   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7208 
 7209   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7210 
 7211   ins_pipe(ialu_imm);
 7212 %}
 7213 
 7214 // Load Narrow Pointer Constant
 7215 
 7216 instruct loadConN(iRegNNoSp dst, immN con)
 7217 %{
 7218   match(Set dst con);
 7219 
 7220   ins_cost(INSN_COST * 4);
 7221   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7222 
 7223   ins_encode(aarch64_enc_mov_n(dst, con));
 7224 
 7225   ins_pipe(ialu_imm);
 7226 %}
 7227 
 7228 // Load Narrow Null Pointer Constant
 7229 
 7230 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7231 %{
 7232   match(Set dst con);
 7233 
 7234   ins_cost(INSN_COST);
 7235   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7236 
 7237   ins_encode(aarch64_enc_mov_n0(dst, con));
 7238 
 7239   ins_pipe(ialu_imm);
 7240 %}
 7241 
 7242 // Load Narrow Klass Constant
 7243 
 7244 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7245 %{
 7246   match(Set dst con);
 7247 
 7248   ins_cost(INSN_COST);
 7249   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7250 
 7251   ins_encode(aarch64_enc_mov_nk(dst, con));
 7252 
 7253   ins_pipe(ialu_imm);
 7254 %}
 7255 
 7256 // Load Packed Float Constant
 7257 
 7258 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7259   match(Set dst con);
 7260   ins_cost(INSN_COST * 4);
 7261   format %{ &quot;fmovs  $dst, $con&quot;%}
 7262   ins_encode %{
 7263     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7264   %}
 7265 
 7266   ins_pipe(fp_imm_s);
 7267 %}
 7268 
 7269 // Load Float Constant
 7270 
 7271 instruct loadConF(vRegF dst, immF con) %{
 7272   match(Set dst con);
 7273 
 7274   ins_cost(INSN_COST * 4);
 7275 
 7276   format %{
 7277     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7278   %}
 7279 
 7280   ins_encode %{
 7281     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7282   %}
 7283 
 7284   ins_pipe(fp_load_constant_s);
 7285 %}
 7286 
 7287 // Load Packed Double Constant
 7288 
 7289 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7290   match(Set dst con);
 7291   ins_cost(INSN_COST);
 7292   format %{ &quot;fmovd  $dst, $con&quot;%}
 7293   ins_encode %{
 7294     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7295   %}
 7296 
 7297   ins_pipe(fp_imm_d);
 7298 %}
 7299 
 7300 // Load Double Constant
 7301 
 7302 instruct loadConD(vRegD dst, immD con) %{
 7303   match(Set dst con);
 7304 
 7305   ins_cost(INSN_COST * 5);
 7306   format %{
 7307     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7308   %}
 7309 
 7310   ins_encode %{
 7311     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7312   %}
 7313 
 7314   ins_pipe(fp_load_constant_d);
 7315 %}
 7316 
 7317 // Store Instructions
 7318 
 7319 // Store CMS card-mark Immediate
 7320 instruct storeimmCM0(immI0 zero, memory1 mem)
 7321 %{
 7322   match(Set mem (StoreCM mem zero));
 7323 
 7324   ins_cost(INSN_COST);
 7325   format %{ &quot;storestore (elided)\n\t&quot;
 7326             &quot;strb zr, $mem\t# byte&quot; %}
 7327 
 7328   ins_encode(aarch64_enc_strb0(mem));
 7329 
 7330   ins_pipe(istore_mem);
 7331 %}
 7332 
 7333 // Store CMS card-mark Immediate with intervening StoreStore
 7334 // needed when using CMS with no conditional card marking
 7335 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7336 %{
 7337   match(Set mem (StoreCM mem zero));
 7338 
 7339   ins_cost(INSN_COST * 2);
 7340   format %{ &quot;storestore\n\t&quot;
 7341             &quot;dmb ishst&quot;
 7342             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7343 
 7344   ins_encode(aarch64_enc_strb0_ordered(mem));
 7345 
 7346   ins_pipe(istore_mem);
 7347 %}
 7348 
 7349 // Store Byte
 7350 instruct storeB(iRegIorL2I src, memory1 mem)
 7351 %{
 7352   match(Set mem (StoreB mem src));
 7353   predicate(!needs_releasing_store(n));
 7354 
 7355   ins_cost(INSN_COST);
 7356   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7357 
 7358   ins_encode(aarch64_enc_strb(src, mem));
 7359 
 7360   ins_pipe(istore_reg_mem);
 7361 %}
 7362 
 7363 
 7364 instruct storeimmB0(immI0 zero, memory1 mem)
 7365 %{
 7366   match(Set mem (StoreB mem zero));
 7367   predicate(!needs_releasing_store(n));
 7368 
 7369   ins_cost(INSN_COST);
 7370   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7371 
 7372   ins_encode(aarch64_enc_strb0(mem));
 7373 
 7374   ins_pipe(istore_mem);
 7375 %}
 7376 
 7377 // Store Char/Short
 7378 instruct storeC(iRegIorL2I src, memory2 mem)
 7379 %{
 7380   match(Set mem (StoreC mem src));
 7381   predicate(!needs_releasing_store(n));
 7382 
 7383   ins_cost(INSN_COST);
 7384   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7385 
 7386   ins_encode(aarch64_enc_strh(src, mem));
 7387 
 7388   ins_pipe(istore_reg_mem);
 7389 %}
 7390 
 7391 instruct storeimmC0(immI0 zero, memory2 mem)
 7392 %{
 7393   match(Set mem (StoreC mem zero));
 7394   predicate(!needs_releasing_store(n));
 7395 
 7396   ins_cost(INSN_COST);
 7397   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7398 
 7399   ins_encode(aarch64_enc_strh0(mem));
 7400 
 7401   ins_pipe(istore_mem);
 7402 %}
 7403 
 7404 // Store Integer
 7405 
 7406 instruct storeI(iRegIorL2I src, memory4 mem)
 7407 %{
 7408   match(Set mem(StoreI mem src));
 7409   predicate(!needs_releasing_store(n));
 7410 
 7411   ins_cost(INSN_COST);
 7412   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7413 
 7414   ins_encode(aarch64_enc_strw(src, mem));
 7415 
 7416   ins_pipe(istore_reg_mem);
 7417 %}
 7418 
 7419 instruct storeimmI0(immI0 zero, memory4 mem)
 7420 %{
 7421   match(Set mem(StoreI mem zero));
 7422   predicate(!needs_releasing_store(n));
 7423 
 7424   ins_cost(INSN_COST);
 7425   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7426 
 7427   ins_encode(aarch64_enc_strw0(mem));
 7428 
 7429   ins_pipe(istore_mem);
 7430 %}
 7431 
 7432 // Store Long (64 bit signed)
 7433 instruct storeL(iRegL src, memory8 mem)
 7434 %{
 7435   match(Set mem (StoreL mem src));
 7436   predicate(!needs_releasing_store(n));
 7437 
 7438   ins_cost(INSN_COST);
 7439   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7440 
 7441   ins_encode(aarch64_enc_str(src, mem));
 7442 
 7443   ins_pipe(istore_reg_mem);
 7444 %}
 7445 
 7446 // Store Long (64 bit signed)
 7447 instruct storeimmL0(immL0 zero, memory8 mem)
 7448 %{
 7449   match(Set mem (StoreL mem zero));
 7450   predicate(!needs_releasing_store(n));
 7451 
 7452   ins_cost(INSN_COST);
 7453   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7454 
 7455   ins_encode(aarch64_enc_str0(mem));
 7456 
 7457   ins_pipe(istore_mem);
 7458 %}
 7459 
 7460 // Store Pointer
 7461 instruct storeP(iRegP src, memory8 mem)
 7462 %{
 7463   match(Set mem (StoreP mem src));
 7464   predicate(!needs_releasing_store(n));
 7465 
 7466   ins_cost(INSN_COST);
 7467   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7468 
 7469   ins_encode(aarch64_enc_str(src, mem));
 7470 
 7471   ins_pipe(istore_reg_mem);
 7472 %}
 7473 
 7474 // Store Pointer
 7475 instruct storeimmP0(immP0 zero, memory8 mem)
 7476 %{
 7477   match(Set mem (StoreP mem zero));
 7478   predicate(!needs_releasing_store(n));
 7479 
 7480   ins_cost(INSN_COST);
 7481   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7482 
 7483   ins_encode(aarch64_enc_str0(mem));
 7484 
 7485   ins_pipe(istore_mem);
 7486 %}
 7487 
 7488 // Store Compressed Pointer
 7489 instruct storeN(iRegN src, memory4 mem)
 7490 %{
 7491   match(Set mem (StoreN mem src));
 7492   predicate(!needs_releasing_store(n));
 7493 
 7494   ins_cost(INSN_COST);
 7495   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7496 
 7497   ins_encode(aarch64_enc_strw(src, mem));
 7498 
 7499   ins_pipe(istore_reg_mem);
 7500 %}
 7501 
 7502 instruct storeImmN0(iRegIHeapbase heapbase, immN0 zero, memory4 mem)
 7503 %{
 7504   match(Set mem (StoreN mem zero));
 7505   predicate(CompressedOops::base() == NULL &amp;&amp;
 7506             CompressedKlassPointers::base() == NULL &amp;&amp;
 7507             (!needs_releasing_store(n)));
 7508 
 7509   ins_cost(INSN_COST);
 7510   format %{ &quot;strw  rheapbase, $mem\t# compressed ptr (rheapbase==0)&quot; %}
 7511 
 7512   ins_encode(aarch64_enc_strw(heapbase, mem));
 7513 
 7514   ins_pipe(istore_reg_mem);
 7515 %}
 7516 
 7517 // Store Float
 7518 instruct storeF(vRegF src, memory4 mem)
 7519 %{
 7520   match(Set mem (StoreF mem src));
 7521   predicate(!needs_releasing_store(n));
 7522 
 7523   ins_cost(INSN_COST);
 7524   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7525 
 7526   ins_encode( aarch64_enc_strs(src, mem) );
 7527 
 7528   ins_pipe(pipe_class_memory);
 7529 %}
 7530 
 7531 // TODO
 7532 // implement storeImmF0 and storeFImmPacked
 7533 
 7534 // Store Double
 7535 instruct storeD(vRegD src, memory8 mem)
 7536 %{
 7537   match(Set mem (StoreD mem src));
 7538   predicate(!needs_releasing_store(n));
 7539 
 7540   ins_cost(INSN_COST);
 7541   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7542 
 7543   ins_encode( aarch64_enc_strd(src, mem) );
 7544 
 7545   ins_pipe(pipe_class_memory);
 7546 %}
 7547 
 7548 // Store Compressed Klass Pointer
 7549 instruct storeNKlass(iRegN src, memory4 mem)
 7550 %{
 7551   predicate(!needs_releasing_store(n));
 7552   match(Set mem (StoreNKlass mem src));
 7553 
 7554   ins_cost(INSN_COST);
 7555   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7556 
 7557   ins_encode(aarch64_enc_strw(src, mem));
 7558 
 7559   ins_pipe(istore_reg_mem);
 7560 %}
 7561 
 7562 // TODO
 7563 // implement storeImmD0 and storeDImmPacked
 7564 
 7565 // prefetch instructions
 7566 // Must be safe to execute with invalid address (cannot fault).
 7567 
 7568 instruct prefetchalloc( memory8 mem ) %{
 7569   match(PrefetchAllocation mem);
 7570 
 7571   ins_cost(INSN_COST);
 7572   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7573 
 7574   ins_encode( aarch64_enc_prefetchw(mem) );
 7575 
 7576   ins_pipe(iload_prefetch);
 7577 %}
 7578 
 7579 //  ---------------- volatile loads and stores ----------------
 7580 
 7581 // Load Byte (8 bit signed)
 7582 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7583 %{
 7584   match(Set dst (LoadB mem));
 7585 
 7586   ins_cost(VOLATILE_REF_COST);
 7587   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7588 
 7589   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7590 
 7591   ins_pipe(pipe_serial);
 7592 %}
 7593 
 7594 // Load Byte (8 bit signed) into long
 7595 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7596 %{
 7597   match(Set dst (ConvI2L (LoadB mem)));
 7598 
 7599   ins_cost(VOLATILE_REF_COST);
 7600   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7601 
 7602   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7603 
 7604   ins_pipe(pipe_serial);
 7605 %}
 7606 
 7607 // Load Byte (8 bit unsigned)
 7608 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7609 %{
 7610   match(Set dst (LoadUB mem));
 7611 
 7612   ins_cost(VOLATILE_REF_COST);
 7613   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7614 
 7615   ins_encode(aarch64_enc_ldarb(dst, mem));
 7616 
 7617   ins_pipe(pipe_serial);
 7618 %}
 7619 
 7620 // Load Byte (8 bit unsigned) into long
 7621 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7622 %{
 7623   match(Set dst (ConvI2L (LoadUB mem)));
 7624 
 7625   ins_cost(VOLATILE_REF_COST);
 7626   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7627 
 7628   ins_encode(aarch64_enc_ldarb(dst, mem));
 7629 
 7630   ins_pipe(pipe_serial);
 7631 %}
 7632 
 7633 // Load Short (16 bit signed)
 7634 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7635 %{
 7636   match(Set dst (LoadS mem));
 7637 
 7638   ins_cost(VOLATILE_REF_COST);
 7639   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7640 
 7641   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7642 
 7643   ins_pipe(pipe_serial);
 7644 %}
 7645 
 7646 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7647 %{
 7648   match(Set dst (LoadUS mem));
 7649 
 7650   ins_cost(VOLATILE_REF_COST);
 7651   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7652 
 7653   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7654 
 7655   ins_pipe(pipe_serial);
 7656 %}
 7657 
 7658 // Load Short/Char (16 bit unsigned) into long
 7659 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7660 %{
 7661   match(Set dst (ConvI2L (LoadUS mem)));
 7662 
 7663   ins_cost(VOLATILE_REF_COST);
 7664   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7665 
 7666   ins_encode(aarch64_enc_ldarh(dst, mem));
 7667 
 7668   ins_pipe(pipe_serial);
 7669 %}
 7670 
 7671 // Load Short/Char (16 bit signed) into long
 7672 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7673 %{
 7674   match(Set dst (ConvI2L (LoadS mem)));
 7675 
 7676   ins_cost(VOLATILE_REF_COST);
 7677   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7678 
 7679   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7680 
 7681   ins_pipe(pipe_serial);
 7682 %}
 7683 
 7684 // Load Integer (32 bit signed)
 7685 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7686 %{
 7687   match(Set dst (LoadI mem));
 7688 
 7689   ins_cost(VOLATILE_REF_COST);
 7690   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7691 
 7692   ins_encode(aarch64_enc_ldarw(dst, mem));
 7693 
 7694   ins_pipe(pipe_serial);
 7695 %}
 7696 
 7697 // Load Integer (32 bit unsigned) into long
 7698 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7699 %{
 7700   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7701 
 7702   ins_cost(VOLATILE_REF_COST);
 7703   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7704 
 7705   ins_encode(aarch64_enc_ldarw(dst, mem));
 7706 
 7707   ins_pipe(pipe_serial);
 7708 %}
 7709 
 7710 // Load Long (64 bit signed)
 7711 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7712 %{
 7713   match(Set dst (LoadL mem));
 7714 
 7715   ins_cost(VOLATILE_REF_COST);
 7716   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7717 
 7718   ins_encode(aarch64_enc_ldar(dst, mem));
 7719 
 7720   ins_pipe(pipe_serial);
 7721 %}
 7722 
 7723 // Load Pointer
 7724 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7725 %{
 7726   match(Set dst (LoadP mem));
 7727   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7728 
 7729   ins_cost(VOLATILE_REF_COST);
 7730   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7731 
 7732   ins_encode(aarch64_enc_ldar(dst, mem));
 7733 
 7734   ins_pipe(pipe_serial);
 7735 %}
 7736 
 7737 // Load Compressed Pointer
 7738 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7739 %{
 7740   match(Set dst (LoadN mem));
 7741 
 7742   ins_cost(VOLATILE_REF_COST);
 7743   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7744 
 7745   ins_encode(aarch64_enc_ldarw(dst, mem));
 7746 
 7747   ins_pipe(pipe_serial);
 7748 %}
 7749 
 7750 // Load Float
 7751 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7752 %{
 7753   match(Set dst (LoadF mem));
 7754 
 7755   ins_cost(VOLATILE_REF_COST);
 7756   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7757 
 7758   ins_encode( aarch64_enc_fldars(dst, mem) );
 7759 
 7760   ins_pipe(pipe_serial);
 7761 %}
 7762 
 7763 // Load Double
 7764 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7765 %{
 7766   match(Set dst (LoadD mem));
 7767 
 7768   ins_cost(VOLATILE_REF_COST);
 7769   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7770 
 7771   ins_encode( aarch64_enc_fldard(dst, mem) );
 7772 
 7773   ins_pipe(pipe_serial);
 7774 %}
 7775 
 7776 // Store Byte
 7777 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7778 %{
 7779   match(Set mem (StoreB mem src));
 7780 
 7781   ins_cost(VOLATILE_REF_COST);
 7782   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7783 
 7784   ins_encode(aarch64_enc_stlrb(src, mem));
 7785 
 7786   ins_pipe(pipe_class_memory);
 7787 %}
 7788 
 7789 // Store Char/Short
 7790 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7791 %{
 7792   match(Set mem (StoreC mem src));
 7793 
 7794   ins_cost(VOLATILE_REF_COST);
 7795   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7796 
 7797   ins_encode(aarch64_enc_stlrh(src, mem));
 7798 
 7799   ins_pipe(pipe_class_memory);
 7800 %}
 7801 
 7802 // Store Integer
 7803 
 7804 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7805 %{
 7806   match(Set mem(StoreI mem src));
 7807 
 7808   ins_cost(VOLATILE_REF_COST);
 7809   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7810 
 7811   ins_encode(aarch64_enc_stlrw(src, mem));
 7812 
 7813   ins_pipe(pipe_class_memory);
 7814 %}
 7815 
 7816 // Store Long (64 bit signed)
 7817 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7818 %{
 7819   match(Set mem (StoreL mem src));
 7820 
 7821   ins_cost(VOLATILE_REF_COST);
 7822   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7823 
 7824   ins_encode(aarch64_enc_stlr(src, mem));
 7825 
 7826   ins_pipe(pipe_class_memory);
 7827 %}
 7828 
 7829 // Store Pointer
 7830 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7831 %{
 7832   match(Set mem (StoreP mem src));
 7833 
 7834   ins_cost(VOLATILE_REF_COST);
 7835   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7836 
 7837   ins_encode(aarch64_enc_stlr(src, mem));
 7838 
 7839   ins_pipe(pipe_class_memory);
 7840 %}
 7841 
 7842 // Store Compressed Pointer
 7843 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7844 %{
 7845   match(Set mem (StoreN mem src));
 7846 
 7847   ins_cost(VOLATILE_REF_COST);
 7848   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7849 
 7850   ins_encode(aarch64_enc_stlrw(src, mem));
 7851 
 7852   ins_pipe(pipe_class_memory);
 7853 %}
 7854 
 7855 // Store Float
 7856 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7857 %{
 7858   match(Set mem (StoreF mem src));
 7859 
 7860   ins_cost(VOLATILE_REF_COST);
 7861   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7862 
 7863   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7864 
 7865   ins_pipe(pipe_class_memory);
 7866 %}
 7867 
 7868 // TODO
 7869 // implement storeImmF0 and storeFImmPacked
 7870 
 7871 // Store Double
 7872 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7873 %{
 7874   match(Set mem (StoreD mem src));
 7875 
 7876   ins_cost(VOLATILE_REF_COST);
 7877   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7878 
 7879   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7880 
 7881   ins_pipe(pipe_class_memory);
 7882 %}
 7883 
 7884 //  ---------------- end of volatile loads and stores ----------------
 7885 
 7886 instruct cacheWB(indirect addr)
 7887 %{
 7888   predicate(VM_Version::supports_data_cache_line_flush());
 7889   match(CacheWB addr);
 7890 
 7891   ins_cost(100);
 7892   format %{&quot;cache wb $addr&quot; %}
 7893   ins_encode %{
 7894     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7895     assert($addr$$disp == 0, &quot;should be&quot;);
 7896     __ cache_wb(Address($addr$$base$$Register, 0));
 7897   %}
 7898   ins_pipe(pipe_slow); // XXX
 7899 %}
 7900 
 7901 instruct cacheWBPreSync()
 7902 %{
 7903   predicate(VM_Version::supports_data_cache_line_flush());
 7904   match(CacheWBPreSync);
 7905 
 7906   ins_cost(100);
 7907   format %{&quot;cache wb presync&quot; %}
 7908   ins_encode %{
 7909     __ cache_wbsync(true);
 7910   %}
 7911   ins_pipe(pipe_slow); // XXX
 7912 %}
 7913 
 7914 instruct cacheWBPostSync()
 7915 %{
 7916   predicate(VM_Version::supports_data_cache_line_flush());
 7917   match(CacheWBPostSync);
 7918 
 7919   ins_cost(100);
 7920   format %{&quot;cache wb postsync&quot; %}
 7921   ins_encode %{
 7922     __ cache_wbsync(false);
 7923   %}
 7924   ins_pipe(pipe_slow); // XXX
 7925 %}
 7926 
 7927 // ============================================================================
 7928 // BSWAP Instructions
 7929 
 7930 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7931   match(Set dst (ReverseBytesI src));
 7932 
 7933   ins_cost(INSN_COST);
 7934   format %{ &quot;revw  $dst, $src&quot; %}
 7935 
 7936   ins_encode %{
 7937     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7938   %}
 7939 
 7940   ins_pipe(ialu_reg);
 7941 %}
 7942 
 7943 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7944   match(Set dst (ReverseBytesL src));
 7945 
 7946   ins_cost(INSN_COST);
 7947   format %{ &quot;rev  $dst, $src&quot; %}
 7948 
 7949   ins_encode %{
 7950     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7951   %}
 7952 
 7953   ins_pipe(ialu_reg);
 7954 %}
 7955 
 7956 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7957   match(Set dst (ReverseBytesUS src));
 7958 
 7959   ins_cost(INSN_COST);
 7960   format %{ &quot;rev16w  $dst, $src&quot; %}
 7961 
 7962   ins_encode %{
 7963     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7964   %}
 7965 
 7966   ins_pipe(ialu_reg);
 7967 %}
 7968 
 7969 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7970   match(Set dst (ReverseBytesS src));
 7971 
 7972   ins_cost(INSN_COST);
 7973   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7974             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7975 
 7976   ins_encode %{
 7977     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7978     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7979   %}
 7980 
 7981   ins_pipe(ialu_reg);
 7982 %}
 7983 
 7984 // ============================================================================
 7985 // Zero Count Instructions
 7986 
 7987 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7988   match(Set dst (CountLeadingZerosI src));
 7989 
 7990   ins_cost(INSN_COST);
 7991   format %{ &quot;clzw  $dst, $src&quot; %}
 7992   ins_encode %{
 7993     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7994   %}
 7995 
 7996   ins_pipe(ialu_reg);
 7997 %}
 7998 
 7999 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 8000   match(Set dst (CountLeadingZerosL src));
 8001 
 8002   ins_cost(INSN_COST);
 8003   format %{ &quot;clz   $dst, $src&quot; %}
 8004   ins_encode %{
 8005     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 8006   %}
 8007 
 8008   ins_pipe(ialu_reg);
 8009 %}
 8010 
 8011 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8012   match(Set dst (CountTrailingZerosI src));
 8013 
 8014   ins_cost(INSN_COST * 2);
 8015   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8016             &quot;clzw   $dst, $dst&quot; %}
 8017   ins_encode %{
 8018     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8019     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8020   %}
 8021 
 8022   ins_pipe(ialu_reg);
 8023 %}
 8024 
 8025 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8026   match(Set dst (CountTrailingZerosL src));
 8027 
 8028   ins_cost(INSN_COST * 2);
 8029   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8030             &quot;clz    $dst, $dst&quot; %}
 8031   ins_encode %{
 8032     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8033     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8034   %}
 8035 
 8036   ins_pipe(ialu_reg);
 8037 %}
 8038 
 8039 //---------- Population Count Instructions -------------------------------------
 8040 //
 8041 
 8042 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8043   predicate(UsePopCountInstruction);
 8044   match(Set dst (PopCountI src));
 8045   effect(TEMP tmp);
 8046   ins_cost(INSN_COST * 13);
 8047 
 8048   format %{ &quot;movw   $src, $src\n\t&quot;
 8049             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8050             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8051             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8052             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8053   ins_encode %{
 8054     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8055     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8056     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8057     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8058     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8059   %}
 8060 
 8061   ins_pipe(pipe_class_default);
 8062 %}
 8063 
 8064 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8065   predicate(UsePopCountInstruction);
 8066   match(Set dst (PopCountI (LoadI mem)));
 8067   effect(TEMP tmp);
 8068   ins_cost(INSN_COST * 13);
 8069 
 8070   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8071             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8072             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8073             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8074   ins_encode %{
 8075     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8076     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8077               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8078     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8079     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8080     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8081   %}
 8082 
 8083   ins_pipe(pipe_class_default);
 8084 %}
 8085 
 8086 // Note: Long.bitCount(long) returns an int.
 8087 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8088   predicate(UsePopCountInstruction);
 8089   match(Set dst (PopCountL src));
 8090   effect(TEMP tmp);
 8091   ins_cost(INSN_COST * 13);
 8092 
 8093   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8094             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8095             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8096             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8097   ins_encode %{
 8098     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8099     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8100     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8101     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8102   %}
 8103 
 8104   ins_pipe(pipe_class_default);
 8105 %}
 8106 
 8107 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8108   predicate(UsePopCountInstruction);
 8109   match(Set dst (PopCountL (LoadL mem)));
 8110   effect(TEMP tmp);
 8111   ins_cost(INSN_COST * 13);
 8112 
 8113   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8114             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8115             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8116             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8117   ins_encode %{
 8118     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8119     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8120               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8121     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8122     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8123     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8124   %}
 8125 
 8126   ins_pipe(pipe_class_default);
 8127 %}
 8128 
 8129 // ============================================================================
 8130 // MemBar Instruction
 8131 
 8132 instruct load_fence() %{
 8133   match(LoadFence);
 8134   ins_cost(VOLATILE_REF_COST);
 8135 
 8136   format %{ &quot;load_fence&quot; %}
 8137 
 8138   ins_encode %{
 8139     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8140   %}
 8141   ins_pipe(pipe_serial);
 8142 %}
 8143 
 8144 instruct unnecessary_membar_acquire() %{
 8145   predicate(unnecessary_acquire(n));
 8146   match(MemBarAcquire);
 8147   ins_cost(0);
 8148 
 8149   format %{ &quot;membar_acquire (elided)&quot; %}
 8150 
 8151   ins_encode %{
 8152     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8153   %}
 8154 
 8155   ins_pipe(pipe_class_empty);
 8156 %}
 8157 
 8158 instruct membar_acquire() %{
 8159   match(MemBarAcquire);
 8160   ins_cost(VOLATILE_REF_COST);
 8161 
 8162   format %{ &quot;membar_acquire\n\t&quot;
 8163             &quot;dmb ish&quot; %}
 8164 
 8165   ins_encode %{
 8166     __ block_comment(&quot;membar_acquire&quot;);
 8167     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8168   %}
 8169 
 8170   ins_pipe(pipe_serial);
 8171 %}
 8172 
 8173 
 8174 instruct membar_acquire_lock() %{
 8175   match(MemBarAcquireLock);
 8176   ins_cost(VOLATILE_REF_COST);
 8177 
 8178   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8179 
 8180   ins_encode %{
 8181     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8182   %}
 8183 
 8184   ins_pipe(pipe_serial);
 8185 %}
 8186 
 8187 instruct store_fence() %{
 8188   match(StoreFence);
 8189   ins_cost(VOLATILE_REF_COST);
 8190 
 8191   format %{ &quot;store_fence&quot; %}
 8192 
 8193   ins_encode %{
 8194     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8195   %}
 8196   ins_pipe(pipe_serial);
 8197 %}
 8198 
 8199 instruct unnecessary_membar_release() %{
 8200   predicate(unnecessary_release(n));
 8201   match(MemBarRelease);
 8202   ins_cost(0);
 8203 
 8204   format %{ &quot;membar_release (elided)&quot; %}
 8205 
 8206   ins_encode %{
 8207     __ block_comment(&quot;membar_release (elided)&quot;);
 8208   %}
 8209   ins_pipe(pipe_serial);
 8210 %}
 8211 
 8212 instruct membar_release() %{
 8213   match(MemBarRelease);
 8214   ins_cost(VOLATILE_REF_COST);
 8215 
 8216   format %{ &quot;membar_release\n\t&quot;
 8217             &quot;dmb ish&quot; %}
 8218 
 8219   ins_encode %{
 8220     __ block_comment(&quot;membar_release&quot;);
 8221     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8222   %}
 8223   ins_pipe(pipe_serial);
 8224 %}
 8225 
 8226 instruct membar_storestore() %{
 8227   match(MemBarStoreStore);
 8228   ins_cost(VOLATILE_REF_COST);
 8229 
 8230   format %{ &quot;MEMBAR-store-store&quot; %}
 8231 
 8232   ins_encode %{
 8233     __ membar(Assembler::StoreStore);
 8234   %}
 8235   ins_pipe(pipe_serial);
 8236 %}
 8237 
 8238 instruct membar_release_lock() %{
 8239   match(MemBarReleaseLock);
 8240   ins_cost(VOLATILE_REF_COST);
 8241 
 8242   format %{ &quot;membar_release_lock (elided)&quot; %}
 8243 
 8244   ins_encode %{
 8245     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8246   %}
 8247 
 8248   ins_pipe(pipe_serial);
 8249 %}
 8250 
 8251 instruct unnecessary_membar_volatile() %{
 8252   predicate(unnecessary_volatile(n));
 8253   match(MemBarVolatile);
 8254   ins_cost(0);
 8255 
 8256   format %{ &quot;membar_volatile (elided)&quot; %}
 8257 
 8258   ins_encode %{
 8259     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8260   %}
 8261 
 8262   ins_pipe(pipe_serial);
 8263 %}
 8264 
 8265 instruct membar_volatile() %{
 8266   match(MemBarVolatile);
 8267   ins_cost(VOLATILE_REF_COST*100);
 8268 
 8269   format %{ &quot;membar_volatile\n\t&quot;
 8270              &quot;dmb ish&quot;%}
 8271 
 8272   ins_encode %{
 8273     __ block_comment(&quot;membar_volatile&quot;);
 8274     __ membar(Assembler::StoreLoad);
 8275   %}
 8276 
 8277   ins_pipe(pipe_serial);
 8278 %}
 8279 
 8280 // ============================================================================
 8281 // Cast/Convert Instructions
 8282 
 8283 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8284   match(Set dst (CastX2P src));
 8285 
 8286   ins_cost(INSN_COST);
<a name="17" id="anc17"></a><span class="line-modified"> 8287   format %{ &quot;mov $dst, $src\t# int64_t -&gt; ptr&quot; %}</span>
 8288 
 8289   ins_encode %{
 8290     if ($dst$$reg != $src$$reg) {
 8291       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8292     }
 8293   %}
 8294 
 8295   ins_pipe(ialu_reg);
 8296 %}
 8297 
 8298 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8299   match(Set dst (CastP2X src));
 8300 
 8301   ins_cost(INSN_COST);
<a name="18" id="anc18"></a><span class="line-modified"> 8302   format %{ &quot;mov $dst, $src\t# ptr -&gt; int64_t&quot; %}</span>
 8303 
 8304   ins_encode %{
 8305     if ($dst$$reg != $src$$reg) {
 8306       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8307     }
 8308   %}
 8309 
 8310   ins_pipe(ialu_reg);
 8311 %}
 8312 
 8313 // Convert oop into int for vectors alignment masking
 8314 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8315   match(Set dst (ConvL2I (CastP2X src)));
 8316 
 8317   ins_cost(INSN_COST);
 8318   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8319   ins_encode %{
 8320     __ movw($dst$$Register, $src$$Register);
 8321   %}
 8322 
 8323   ins_pipe(ialu_reg);
 8324 %}
 8325 
 8326 // Convert compressed oop into int for vectors alignment masking
 8327 // in case of 32bit oops (heap &lt; 4Gb).
 8328 instruct convN2I(iRegINoSp dst, iRegN src)
 8329 %{
 8330   predicate(CompressedOops::shift() == 0);
 8331   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8332 
 8333   ins_cost(INSN_COST);
 8334   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8335   ins_encode %{
 8336     __ movw($dst$$Register, $src$$Register);
 8337   %}
 8338 
 8339   ins_pipe(ialu_reg);
 8340 %}
 8341 
 8342 
 8343 // Convert oop pointer into compressed form
 8344 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8345   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8346   match(Set dst (EncodeP src));
 8347   effect(KILL cr);
 8348   ins_cost(INSN_COST * 3);
 8349   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8350   ins_encode %{
 8351     Register s = $src$$Register;
 8352     Register d = $dst$$Register;
 8353     __ encode_heap_oop(d, s);
 8354   %}
 8355   ins_pipe(ialu_reg);
 8356 %}
 8357 
 8358 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8359   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8360   match(Set dst (EncodeP src));
 8361   ins_cost(INSN_COST * 3);
 8362   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8363   ins_encode %{
 8364     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8365   %}
 8366   ins_pipe(ialu_reg);
 8367 %}
 8368 
 8369 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8370   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8371             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8372   match(Set dst (DecodeN src));
 8373   ins_cost(INSN_COST * 3);
 8374   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8375   ins_encode %{
 8376     Register s = $src$$Register;
 8377     Register d = $dst$$Register;
 8378     __ decode_heap_oop(d, s);
 8379   %}
 8380   ins_pipe(ialu_reg);
 8381 %}
 8382 
 8383 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8384   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8385             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8386   match(Set dst (DecodeN src));
 8387   ins_cost(INSN_COST * 3);
 8388   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8389   ins_encode %{
 8390     Register s = $src$$Register;
 8391     Register d = $dst$$Register;
 8392     __ decode_heap_oop_not_null(d, s);
 8393   %}
 8394   ins_pipe(ialu_reg);
 8395 %}
 8396 
 8397 // n.b. AArch64 implementations of encode_klass_not_null and
 8398 // decode_klass_not_null do not modify the flags register so, unlike
 8399 // Intel, we don&#39;t kill CR as a side effect here
 8400 
 8401 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8402   match(Set dst (EncodePKlass src));
 8403 
 8404   ins_cost(INSN_COST * 3);
 8405   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8406 
 8407   ins_encode %{
 8408     Register src_reg = as_Register($src$$reg);
 8409     Register dst_reg = as_Register($dst$$reg);
 8410     __ encode_klass_not_null(dst_reg, src_reg);
 8411   %}
 8412 
 8413    ins_pipe(ialu_reg);
 8414 %}
 8415 
 8416 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8417   match(Set dst (DecodeNKlass src));
 8418 
 8419   ins_cost(INSN_COST * 3);
 8420   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8421 
 8422   ins_encode %{
 8423     Register src_reg = as_Register($src$$reg);
 8424     Register dst_reg = as_Register($dst$$reg);
 8425     if (dst_reg != src_reg) {
 8426       __ decode_klass_not_null(dst_reg, src_reg);
 8427     } else {
 8428       __ decode_klass_not_null(dst_reg);
 8429     }
 8430   %}
 8431 
 8432    ins_pipe(ialu_reg);
 8433 %}
 8434 
 8435 instruct checkCastPP(iRegPNoSp dst)
 8436 %{
 8437   match(Set dst (CheckCastPP dst));
 8438 
 8439   size(0);
 8440   format %{ &quot;# checkcastPP of $dst&quot; %}
 8441   ins_encode(/* empty encoding */);
 8442   ins_pipe(pipe_class_empty);
 8443 %}
 8444 
 8445 instruct castPP(iRegPNoSp dst)
 8446 %{
 8447   match(Set dst (CastPP dst));
 8448 
 8449   size(0);
 8450   format %{ &quot;# castPP of $dst&quot; %}
 8451   ins_encode(/* empty encoding */);
 8452   ins_pipe(pipe_class_empty);
 8453 %}
 8454 
 8455 instruct castII(iRegI dst)
 8456 %{
 8457   match(Set dst (CastII dst));
 8458 
 8459   size(0);
 8460   format %{ &quot;# castII of $dst&quot; %}
 8461   ins_encode(/* empty encoding */);
 8462   ins_cost(0);
 8463   ins_pipe(pipe_class_empty);
 8464 %}
 8465 
 8466 instruct castLL(iRegL dst)
 8467 %{
 8468   match(Set dst (CastLL dst));
 8469 
 8470   size(0);
 8471   format %{ &quot;# castLL of $dst&quot; %}
 8472   ins_encode(/* empty encoding */);
 8473   ins_cost(0);
 8474   ins_pipe(pipe_class_empty);
 8475 %}
 8476 
 8477 // ============================================================================
 8478 // Atomic operation instructions
 8479 //
 8480 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8481 // Store{PIL}Conditional instructions using a normal load for the
 8482 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8483 //
 8484 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8485 // pair to lock object allocations from Eden space when not using
 8486 // TLABs.
 8487 //
 8488 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8489 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8490 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8491 // only for 64-bit.
 8492 //
 8493 // We implement LoadPLocked and StorePLocked instructions using,
 8494 // respectively the AArch64 hw load-exclusive and store-conditional
 8495 // instructions. Whereas we must implement each of
 8496 // Store{IL}Conditional using a CAS which employs a pair of
 8497 // instructions comprising a load-exclusive followed by a
 8498 // store-conditional.
 8499 
 8500 
 8501 // Locked-load (linked load) of the current heap-top
 8502 // used when updating the eden heap top
 8503 // implemented using ldaxr on AArch64
 8504 
 8505 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8506 %{
 8507   match(Set dst (LoadPLocked mem));
 8508 
 8509   ins_cost(VOLATILE_REF_COST);
 8510 
 8511   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8512 
 8513   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8514 
 8515   ins_pipe(pipe_serial);
 8516 %}
 8517 
 8518 // Conditional-store of the updated heap-top.
 8519 // Used during allocation of the shared heap.
 8520 // Sets flag (EQ) on success.
 8521 // implemented using stlxr on AArch64.
 8522 
 8523 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8524 %{
 8525   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8526 
 8527   ins_cost(VOLATILE_REF_COST);
 8528 
 8529  // TODO
 8530  // do we need to do a store-conditional release or can we just use a
 8531  // plain store-conditional?
 8532 
 8533   format %{
 8534     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8535     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8536   %}
 8537 
 8538   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8539 
 8540   ins_pipe(pipe_serial);
 8541 %}
 8542 
 8543 
 8544 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8545 // when attempting to rebias a lock towards the current thread.  We
 8546 // must use the acquire form of cmpxchg in order to guarantee acquire
 8547 // semantics in this case.
 8548 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8549 %{
 8550   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8551 
 8552   ins_cost(VOLATILE_REF_COST);
 8553 
 8554   format %{
 8555     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8556     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8557   %}
 8558 
 8559   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8560 
 8561   ins_pipe(pipe_slow);
 8562 %}
 8563 
 8564 // storeIConditional also has acquire semantics, for no better reason
 8565 // than matching storeLConditional.  At the time of writing this
 8566 // comment storeIConditional was not used anywhere by AArch64.
 8567 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8568 %{
 8569   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8570 
 8571   ins_cost(VOLATILE_REF_COST);
 8572 
 8573   format %{
 8574     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8575     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8576   %}
 8577 
 8578   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8579 
 8580   ins_pipe(pipe_slow);
 8581 %}
 8582 
 8583 // standard CompareAndSwapX when we are using barriers
 8584 // these have higher priority than the rules selected by a predicate
 8585 
 8586 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8587 // can&#39;t match them
 8588 
 8589 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8590 
 8591   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8592   ins_cost(2 * VOLATILE_REF_COST);
 8593 
 8594   effect(KILL cr);
 8595 
 8596   format %{
 8597     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8598     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8599   %}
 8600 
 8601   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8602             aarch64_enc_cset_eq(res));
 8603 
 8604   ins_pipe(pipe_slow);
 8605 %}
 8606 
 8607 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8608 
 8609   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8610   ins_cost(2 * VOLATILE_REF_COST);
 8611 
 8612   effect(KILL cr);
 8613 
 8614   format %{
 8615     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8616     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8617   %}
 8618 
 8619   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8620             aarch64_enc_cset_eq(res));
 8621 
 8622   ins_pipe(pipe_slow);
 8623 %}
 8624 
 8625 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8626 
 8627   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8628   ins_cost(2 * VOLATILE_REF_COST);
 8629 
 8630   effect(KILL cr);
 8631 
 8632  format %{
 8633     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8634     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8635  %}
 8636 
 8637  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8638             aarch64_enc_cset_eq(res));
 8639 
 8640   ins_pipe(pipe_slow);
 8641 %}
 8642 
 8643 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8644 
 8645   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8646   ins_cost(2 * VOLATILE_REF_COST);
 8647 
 8648   effect(KILL cr);
 8649 
 8650  format %{
<a name="19" id="anc19"></a><span class="line-modified"> 8651     &quot;cmpxchg $mem, $oldval, $newval\t# (int64_t) if $mem == $oldval then $mem &lt;-- $newval&quot;</span>
 8652     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8653  %}
 8654 
 8655  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8656             aarch64_enc_cset_eq(res));
 8657 
 8658   ins_pipe(pipe_slow);
 8659 %}
 8660 
 8661 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8662 
 8663   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8664   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8665   ins_cost(2 * VOLATILE_REF_COST);
 8666 
 8667   effect(KILL cr);
 8668 
 8669  format %{
 8670     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8671     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8672  %}
 8673 
 8674  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8675             aarch64_enc_cset_eq(res));
 8676 
 8677   ins_pipe(pipe_slow);
 8678 %}
 8679 
 8680 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8681 
 8682   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8683   ins_cost(2 * VOLATILE_REF_COST);
 8684 
 8685   effect(KILL cr);
 8686 
 8687  format %{
 8688     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8689     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8690  %}
 8691 
 8692  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8693             aarch64_enc_cset_eq(res));
 8694 
 8695   ins_pipe(pipe_slow);
 8696 %}
 8697 
 8698 // alternative CompareAndSwapX when we are eliding barriers
 8699 
 8700 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8701 
 8702   predicate(needs_acquiring_load_exclusive(n));
 8703   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8704   ins_cost(VOLATILE_REF_COST);
 8705 
 8706   effect(KILL cr);
 8707 
 8708   format %{
 8709     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8710     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8711   %}
 8712 
 8713   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8714             aarch64_enc_cset_eq(res));
 8715 
 8716   ins_pipe(pipe_slow);
 8717 %}
 8718 
 8719 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8720 
 8721   predicate(needs_acquiring_load_exclusive(n));
 8722   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8723   ins_cost(VOLATILE_REF_COST);
 8724 
 8725   effect(KILL cr);
 8726 
 8727   format %{
 8728     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8729     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8730   %}
 8731 
 8732   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8733             aarch64_enc_cset_eq(res));
 8734 
 8735   ins_pipe(pipe_slow);
 8736 %}
 8737 
 8738 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8739 
 8740   predicate(needs_acquiring_load_exclusive(n));
 8741   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8742   ins_cost(VOLATILE_REF_COST);
 8743 
 8744   effect(KILL cr);
 8745 
 8746  format %{
 8747     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8748     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8749  %}
 8750 
 8751  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8752             aarch64_enc_cset_eq(res));
 8753 
 8754   ins_pipe(pipe_slow);
 8755 %}
 8756 
 8757 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8758 
 8759   predicate(needs_acquiring_load_exclusive(n));
 8760   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8761   ins_cost(VOLATILE_REF_COST);
 8762 
 8763   effect(KILL cr);
 8764 
 8765  format %{
<a name="20" id="anc20"></a><span class="line-modified"> 8766     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (int64_t) if $mem == $oldval then $mem &lt;-- $newval&quot;</span>
 8767     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8768  %}
 8769 
 8770  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8771             aarch64_enc_cset_eq(res));
 8772 
 8773   ins_pipe(pipe_slow);
 8774 %}
 8775 
 8776 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8777 
 8778   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8779   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8780   ins_cost(VOLATILE_REF_COST);
 8781 
 8782   effect(KILL cr);
 8783 
 8784  format %{
 8785     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8786     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8787  %}
 8788 
 8789  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8790             aarch64_enc_cset_eq(res));
 8791 
 8792   ins_pipe(pipe_slow);
 8793 %}
 8794 
 8795 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8796 
 8797   predicate(needs_acquiring_load_exclusive(n));
 8798   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8799   ins_cost(VOLATILE_REF_COST);
 8800 
 8801   effect(KILL cr);
 8802 
 8803  format %{
 8804     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8805     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8806  %}
 8807 
 8808  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8809             aarch64_enc_cset_eq(res));
 8810 
 8811   ins_pipe(pipe_slow);
 8812 %}
 8813 
 8814 
 8815 // ---------------------------------------------------------------------
 8816 
 8817 
 8818 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8819 
 8820 // Sundry CAS operations.  Note that release is always true,
 8821 // regardless of the memory ordering of the CAS.  This is because we
 8822 // need the volatile case to be sequentially consistent but there is
 8823 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8824 // can&#39;t check the type of memory ordering here, so we always emit a
 8825 // STLXR.
 8826 
 8827 // This section is generated from aarch64_ad_cas.m4
 8828 
 8829 
 8830 
 8831 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8832   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8833   ins_cost(2 * VOLATILE_REF_COST);
 8834   effect(TEMP_DEF res, KILL cr);
 8835   format %{
 8836     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8837   %}
 8838   ins_encode %{
 8839     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8840                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8841                /*weak*/ false, $res$$Register);
 8842     __ sxtbw($res$$Register, $res$$Register);
 8843   %}
 8844   ins_pipe(pipe_slow);
 8845 %}
 8846 
 8847 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8848   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8849   ins_cost(2 * VOLATILE_REF_COST);
 8850   effect(TEMP_DEF res, KILL cr);
 8851   format %{
 8852     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8853   %}
 8854   ins_encode %{
 8855     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8856                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8857                /*weak*/ false, $res$$Register);
 8858     __ sxthw($res$$Register, $res$$Register);
 8859   %}
 8860   ins_pipe(pipe_slow);
 8861 %}
 8862 
 8863 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8864   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8865   ins_cost(2 * VOLATILE_REF_COST);
 8866   effect(TEMP_DEF res, KILL cr);
 8867   format %{
 8868     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8869   %}
 8870   ins_encode %{
 8871     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8872                Assembler::word, /*acquire*/ false, /*release*/ true,
 8873                /*weak*/ false, $res$$Register);
 8874   %}
 8875   ins_pipe(pipe_slow);
 8876 %}
 8877 
 8878 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8879   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8880   ins_cost(2 * VOLATILE_REF_COST);
 8881   effect(TEMP_DEF res, KILL cr);
 8882   format %{
<a name="21" id="anc21"></a><span class="line-modified"> 8883     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (int64_t, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;</span>
 8884   %}
 8885   ins_encode %{
 8886     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8887                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8888                /*weak*/ false, $res$$Register);
 8889   %}
 8890   ins_pipe(pipe_slow);
 8891 %}
 8892 
 8893 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8894   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8895   ins_cost(2 * VOLATILE_REF_COST);
 8896   effect(TEMP_DEF res, KILL cr);
 8897   format %{
 8898     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8899   %}
 8900   ins_encode %{
 8901     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8902                Assembler::word, /*acquire*/ false, /*release*/ true,
 8903                /*weak*/ false, $res$$Register);
 8904   %}
 8905   ins_pipe(pipe_slow);
 8906 %}
 8907 
 8908 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8909   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8910   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8911   ins_cost(2 * VOLATILE_REF_COST);
 8912   effect(TEMP_DEF res, KILL cr);
 8913   format %{
 8914     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8915   %}
 8916   ins_encode %{
 8917     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8918                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8919                /*weak*/ false, $res$$Register);
 8920   %}
 8921   ins_pipe(pipe_slow);
 8922 %}
 8923 
 8924 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8925   predicate(needs_acquiring_load_exclusive(n));
 8926   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8927   ins_cost(VOLATILE_REF_COST);
 8928   effect(TEMP_DEF res, KILL cr);
 8929   format %{
 8930     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8931   %}
 8932   ins_encode %{
 8933     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8934                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8935                /*weak*/ false, $res$$Register);
 8936     __ sxtbw($res$$Register, $res$$Register);
 8937   %}
 8938   ins_pipe(pipe_slow);
 8939 %}
 8940 
 8941 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8942   predicate(needs_acquiring_load_exclusive(n));
 8943   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8944   ins_cost(VOLATILE_REF_COST);
 8945   effect(TEMP_DEF res, KILL cr);
 8946   format %{
 8947     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8948   %}
 8949   ins_encode %{
 8950     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8951                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8952                /*weak*/ false, $res$$Register);
 8953     __ sxthw($res$$Register, $res$$Register);
 8954   %}
 8955   ins_pipe(pipe_slow);
 8956 %}
 8957 
 8958 
 8959 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8960   predicate(needs_acquiring_load_exclusive(n));
 8961   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8962   ins_cost(VOLATILE_REF_COST);
 8963   effect(TEMP_DEF res, KILL cr);
 8964   format %{
 8965     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8966   %}
 8967   ins_encode %{
 8968     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8969                Assembler::word, /*acquire*/ true, /*release*/ true,
 8970                /*weak*/ false, $res$$Register);
 8971   %}
 8972   ins_pipe(pipe_slow);
 8973 %}
 8974 
 8975 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8976   predicate(needs_acquiring_load_exclusive(n));
 8977   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8978   ins_cost(VOLATILE_REF_COST);
 8979   effect(TEMP_DEF res, KILL cr);
 8980   format %{
<a name="22" id="anc22"></a><span class="line-modified"> 8981     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (int64_t, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;</span>
 8982   %}
 8983   ins_encode %{
 8984     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8985                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8986                /*weak*/ false, $res$$Register);
 8987   %}
 8988   ins_pipe(pipe_slow);
 8989 %}
 8990 
 8991 
 8992 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8993   predicate(needs_acquiring_load_exclusive(n));
 8994   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8995   ins_cost(VOLATILE_REF_COST);
 8996   effect(TEMP_DEF res, KILL cr);
 8997   format %{
 8998     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8999   %}
 9000   ins_encode %{
 9001     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9002                Assembler::word, /*acquire*/ true, /*release*/ true,
 9003                /*weak*/ false, $res$$Register);
 9004   %}
 9005   ins_pipe(pipe_slow);
 9006 %}
 9007 
 9008 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9009   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9010   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 9011   ins_cost(VOLATILE_REF_COST);
 9012   effect(TEMP_DEF res, KILL cr);
 9013   format %{
 9014     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9015   %}
 9016   ins_encode %{
 9017     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9018                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9019                /*weak*/ false, $res$$Register);
 9020   %}
 9021   ins_pipe(pipe_slow);
 9022 %}
 9023 
 9024 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9025   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9026   ins_cost(2 * VOLATILE_REF_COST);
 9027   effect(KILL cr);
 9028   format %{
 9029     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9030     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9031   %}
 9032   ins_encode %{
 9033     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9034                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9035                /*weak*/ true, noreg);
 9036     __ csetw($res$$Register, Assembler::EQ);
 9037   %}
 9038   ins_pipe(pipe_slow);
 9039 %}
 9040 
 9041 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9042   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9043   ins_cost(2 * VOLATILE_REF_COST);
 9044   effect(KILL cr);
 9045   format %{
 9046     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9047     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9048   %}
 9049   ins_encode %{
 9050     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9051                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9052                /*weak*/ true, noreg);
 9053     __ csetw($res$$Register, Assembler::EQ);
 9054   %}
 9055   ins_pipe(pipe_slow);
 9056 %}
 9057 
 9058 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9059   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9060   ins_cost(2 * VOLATILE_REF_COST);
 9061   effect(KILL cr);
 9062   format %{
 9063     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9064     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9065   %}
 9066   ins_encode %{
 9067     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9068                Assembler::word, /*acquire*/ false, /*release*/ true,
 9069                /*weak*/ true, noreg);
 9070     __ csetw($res$$Register, Assembler::EQ);
 9071   %}
 9072   ins_pipe(pipe_slow);
 9073 %}
 9074 
 9075 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9076   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9077   ins_cost(2 * VOLATILE_REF_COST);
 9078   effect(KILL cr);
 9079   format %{
<a name="23" id="anc23"></a><span class="line-modified"> 9080     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (int64_t, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;</span>
 9081     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9082   %}
 9083   ins_encode %{
 9084     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9085                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9086                /*weak*/ true, noreg);
 9087     __ csetw($res$$Register, Assembler::EQ);
 9088   %}
 9089   ins_pipe(pipe_slow);
 9090 %}
 9091 
 9092 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9093   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9094   ins_cost(2 * VOLATILE_REF_COST);
 9095   effect(KILL cr);
 9096   format %{
 9097     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9098     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9099   %}
 9100   ins_encode %{
 9101     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9102                Assembler::word, /*acquire*/ false, /*release*/ true,
 9103                /*weak*/ true, noreg);
 9104     __ csetw($res$$Register, Assembler::EQ);
 9105   %}
 9106   ins_pipe(pipe_slow);
 9107 %}
 9108 
 9109 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9110   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9111   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9112   ins_cost(2 * VOLATILE_REF_COST);
 9113   effect(KILL cr);
 9114   format %{
 9115     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9116     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9117   %}
 9118   ins_encode %{
 9119     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9120                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9121                /*weak*/ true, noreg);
 9122     __ csetw($res$$Register, Assembler::EQ);
 9123   %}
 9124   ins_pipe(pipe_slow);
 9125 %}
 9126 
 9127 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9128   predicate(needs_acquiring_load_exclusive(n));
 9129   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9130   ins_cost(VOLATILE_REF_COST);
 9131   effect(KILL cr);
 9132   format %{
 9133     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9134     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9135   %}
 9136   ins_encode %{
 9137     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9138                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9139                /*weak*/ true, noreg);
 9140     __ csetw($res$$Register, Assembler::EQ);
 9141   %}
 9142   ins_pipe(pipe_slow);
 9143 %}
 9144 
 9145 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9146   predicate(needs_acquiring_load_exclusive(n));
 9147   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9148   ins_cost(VOLATILE_REF_COST);
 9149   effect(KILL cr);
 9150   format %{
 9151     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9152     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9153   %}
 9154   ins_encode %{
 9155     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9156                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9157                /*weak*/ true, noreg);
 9158     __ csetw($res$$Register, Assembler::EQ);
 9159   %}
 9160   ins_pipe(pipe_slow);
 9161 %}
 9162 
 9163 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9164   predicate(needs_acquiring_load_exclusive(n));
 9165   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9166   ins_cost(VOLATILE_REF_COST);
 9167   effect(KILL cr);
 9168   format %{
 9169     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9170     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9171   %}
 9172   ins_encode %{
 9173     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9174                Assembler::word, /*acquire*/ true, /*release*/ true,
 9175                /*weak*/ true, noreg);
 9176     __ csetw($res$$Register, Assembler::EQ);
 9177   %}
 9178   ins_pipe(pipe_slow);
 9179 %}
 9180 
 9181 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9182   predicate(needs_acquiring_load_exclusive(n));
 9183   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9184   ins_cost(VOLATILE_REF_COST);
 9185   effect(KILL cr);
 9186   format %{
<a name="24" id="anc24"></a><span class="line-modified"> 9187     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (int64_t, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;</span>
 9188     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9189   %}
 9190   ins_encode %{
 9191     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9192                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9193                /*weak*/ true, noreg);
 9194     __ csetw($res$$Register, Assembler::EQ);
 9195   %}
 9196   ins_pipe(pipe_slow);
 9197 %}
 9198 
 9199 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9200   predicate(needs_acquiring_load_exclusive(n));
 9201   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9202   ins_cost(VOLATILE_REF_COST);
 9203   effect(KILL cr);
 9204   format %{
 9205     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9206     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9207   %}
 9208   ins_encode %{
 9209     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9210                Assembler::word, /*acquire*/ true, /*release*/ true,
 9211                /*weak*/ true, noreg);
 9212     __ csetw($res$$Register, Assembler::EQ);
 9213   %}
 9214   ins_pipe(pipe_slow);
 9215 %}
 9216 
 9217 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9218   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9219   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9220   ins_cost(VOLATILE_REF_COST);
 9221   effect(KILL cr);
 9222   format %{
 9223     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9224     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9225   %}
 9226   ins_encode %{
 9227     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9228                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9229                /*weak*/ true, noreg);
 9230     __ csetw($res$$Register, Assembler::EQ);
 9231   %}
 9232   ins_pipe(pipe_slow);
 9233 %}
 9234 
 9235 // END This section of the file is automatically generated. Do not edit --------------
 9236 // ---------------------------------------------------------------------
 9237 
 9238 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9239   match(Set prev (GetAndSetI mem newv));
 9240   ins_cost(2 * VOLATILE_REF_COST);
 9241   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9242   ins_encode %{
 9243     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9244   %}
 9245   ins_pipe(pipe_serial);
 9246 %}
 9247 
 9248 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9249   match(Set prev (GetAndSetL mem newv));
 9250   ins_cost(2 * VOLATILE_REF_COST);
 9251   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9252   ins_encode %{
 9253     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9254   %}
 9255   ins_pipe(pipe_serial);
 9256 %}
 9257 
 9258 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9259   match(Set prev (GetAndSetN mem newv));
 9260   ins_cost(2 * VOLATILE_REF_COST);
 9261   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9262   ins_encode %{
 9263     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9264   %}
 9265   ins_pipe(pipe_serial);
 9266 %}
 9267 
 9268 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9269   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9270   match(Set prev (GetAndSetP mem newv));
 9271   ins_cost(2 * VOLATILE_REF_COST);
 9272   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9273   ins_encode %{
 9274     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9275   %}
 9276   ins_pipe(pipe_serial);
 9277 %}
 9278 
 9279 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9280   predicate(needs_acquiring_load_exclusive(n));
 9281   match(Set prev (GetAndSetI mem newv));
 9282   ins_cost(VOLATILE_REF_COST);
 9283   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9284   ins_encode %{
 9285     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9286   %}
 9287   ins_pipe(pipe_serial);
 9288 %}
 9289 
 9290 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9291   predicate(needs_acquiring_load_exclusive(n));
 9292   match(Set prev (GetAndSetL mem newv));
 9293   ins_cost(VOLATILE_REF_COST);
 9294   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9295   ins_encode %{
 9296     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9297   %}
 9298   ins_pipe(pipe_serial);
 9299 %}
 9300 
 9301 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9302   predicate(needs_acquiring_load_exclusive(n));
 9303   match(Set prev (GetAndSetN mem newv));
 9304   ins_cost(VOLATILE_REF_COST);
 9305   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9306   ins_encode %{
 9307     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9308   %}
 9309   ins_pipe(pipe_serial);
 9310 %}
 9311 
 9312 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9313   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9314   match(Set prev (GetAndSetP mem newv));
 9315   ins_cost(VOLATILE_REF_COST);
 9316   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9317   ins_encode %{
 9318     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9319   %}
 9320   ins_pipe(pipe_serial);
 9321 %}
 9322 
 9323 
 9324 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9325   match(Set newval (GetAndAddL mem incr));
 9326   ins_cost(2 * VOLATILE_REF_COST + 1);
 9327   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9328   ins_encode %{
 9329     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9330   %}
 9331   ins_pipe(pipe_serial);
 9332 %}
 9333 
 9334 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9335   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9336   match(Set dummy (GetAndAddL mem incr));
 9337   ins_cost(2 * VOLATILE_REF_COST);
 9338   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9339   ins_encode %{
 9340     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9341   %}
 9342   ins_pipe(pipe_serial);
 9343 %}
 9344 
 9345 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9346   match(Set newval (GetAndAddL mem incr));
 9347   ins_cost(2 * VOLATILE_REF_COST + 1);
 9348   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9349   ins_encode %{
 9350     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9351   %}
 9352   ins_pipe(pipe_serial);
 9353 %}
 9354 
 9355 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9356   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9357   match(Set dummy (GetAndAddL mem incr));
 9358   ins_cost(2 * VOLATILE_REF_COST);
 9359   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9360   ins_encode %{
 9361     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9362   %}
 9363   ins_pipe(pipe_serial);
 9364 %}
 9365 
 9366 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9367   match(Set newval (GetAndAddI mem incr));
 9368   ins_cost(2 * VOLATILE_REF_COST + 1);
 9369   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9370   ins_encode %{
 9371     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9372   %}
 9373   ins_pipe(pipe_serial);
 9374 %}
 9375 
 9376 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9377   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9378   match(Set dummy (GetAndAddI mem incr));
 9379   ins_cost(2 * VOLATILE_REF_COST);
 9380   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9381   ins_encode %{
 9382     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9383   %}
 9384   ins_pipe(pipe_serial);
 9385 %}
 9386 
 9387 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9388   match(Set newval (GetAndAddI mem incr));
 9389   ins_cost(2 * VOLATILE_REF_COST + 1);
 9390   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9391   ins_encode %{
 9392     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9393   %}
 9394   ins_pipe(pipe_serial);
 9395 %}
 9396 
 9397 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9398   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9399   match(Set dummy (GetAndAddI mem incr));
 9400   ins_cost(2 * VOLATILE_REF_COST);
 9401   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9402   ins_encode %{
 9403     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9404   %}
 9405   ins_pipe(pipe_serial);
 9406 %}
 9407 
 9408 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9409   predicate(needs_acquiring_load_exclusive(n));
 9410   match(Set newval (GetAndAddL mem incr));
 9411   ins_cost(VOLATILE_REF_COST + 1);
 9412   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9413   ins_encode %{
 9414     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9415   %}
 9416   ins_pipe(pipe_serial);
 9417 %}
 9418 
 9419 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9420   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9421   match(Set dummy (GetAndAddL mem incr));
 9422   ins_cost(VOLATILE_REF_COST);
 9423   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9424   ins_encode %{
 9425     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9426   %}
 9427   ins_pipe(pipe_serial);
 9428 %}
 9429 
 9430 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9431   predicate(needs_acquiring_load_exclusive(n));
 9432   match(Set newval (GetAndAddL mem incr));
 9433   ins_cost(VOLATILE_REF_COST + 1);
 9434   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9435   ins_encode %{
 9436     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9437   %}
 9438   ins_pipe(pipe_serial);
 9439 %}
 9440 
 9441 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9442   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9443   match(Set dummy (GetAndAddL mem incr));
 9444   ins_cost(VOLATILE_REF_COST);
 9445   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9446   ins_encode %{
 9447     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9448   %}
 9449   ins_pipe(pipe_serial);
 9450 %}
 9451 
 9452 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9453   predicate(needs_acquiring_load_exclusive(n));
 9454   match(Set newval (GetAndAddI mem incr));
 9455   ins_cost(VOLATILE_REF_COST + 1);
 9456   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9457   ins_encode %{
 9458     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9459   %}
 9460   ins_pipe(pipe_serial);
 9461 %}
 9462 
 9463 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9464   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9465   match(Set dummy (GetAndAddI mem incr));
 9466   ins_cost(VOLATILE_REF_COST);
 9467   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9468   ins_encode %{
 9469     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9470   %}
 9471   ins_pipe(pipe_serial);
 9472 %}
 9473 
 9474 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9475   predicate(needs_acquiring_load_exclusive(n));
 9476   match(Set newval (GetAndAddI mem incr));
 9477   ins_cost(VOLATILE_REF_COST + 1);
 9478   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9479   ins_encode %{
 9480     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9481   %}
 9482   ins_pipe(pipe_serial);
 9483 %}
 9484 
 9485 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9486   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9487   match(Set dummy (GetAndAddI mem incr));
 9488   ins_cost(VOLATILE_REF_COST);
 9489   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9490   ins_encode %{
 9491     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9492   %}
 9493   ins_pipe(pipe_serial);
 9494 %}
 9495 
 9496 // Manifest a CmpL result in an integer register.
 9497 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9498 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9499 %{
 9500   match(Set dst (CmpL3 src1 src2));
 9501   effect(KILL flags);
 9502 
 9503   ins_cost(INSN_COST * 6);
 9504   format %{
 9505       &quot;cmp $src1, $src2&quot;
 9506       &quot;csetw $dst, ne&quot;
 9507       &quot;cnegw $dst, lt&quot;
 9508   %}
 9509   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9510   ins_encode %{
 9511     __ cmp($src1$$Register, $src2$$Register);
 9512     __ csetw($dst$$Register, Assembler::NE);
 9513     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9514   %}
 9515 
 9516   ins_pipe(pipe_class_default);
 9517 %}
 9518 
 9519 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9520 %{
 9521   match(Set dst (CmpL3 src1 src2));
 9522   effect(KILL flags);
 9523 
 9524   ins_cost(INSN_COST * 6);
 9525   format %{
 9526       &quot;cmp $src1, $src2&quot;
 9527       &quot;csetw $dst, ne&quot;
 9528       &quot;cnegw $dst, lt&quot;
 9529   %}
 9530   ins_encode %{
 9531     int32_t con = (int32_t)$src2$$constant;
 9532      if (con &lt; 0) {
 9533       __ adds(zr, $src1$$Register, -con);
 9534     } else {
 9535       __ subs(zr, $src1$$Register, con);
 9536     }
 9537     __ csetw($dst$$Register, Assembler::NE);
 9538     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9539   %}
 9540 
 9541   ins_pipe(pipe_class_default);
 9542 %}
 9543 
 9544 // ============================================================================
 9545 // Conditional Move Instructions
 9546 
 9547 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9548 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9549 // define an op class which merged both inputs and use it to type the
 9550 // argument to a single rule. unfortunatelyt his fails because the
 9551 // opclass does not live up to the COND_INTER interface of its
 9552 // component operands. When the generic code tries to negate the
 9553 // operand it ends up running the generci Machoper::negate method
 9554 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9555 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9556 
 9557 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9558   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9559 
 9560   ins_cost(INSN_COST * 2);
 9561   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9562 
 9563   ins_encode %{
 9564     __ cselw(as_Register($dst$$reg),
 9565              as_Register($src2$$reg),
 9566              as_Register($src1$$reg),
 9567              (Assembler::Condition)$cmp$$cmpcode);
 9568   %}
 9569 
 9570   ins_pipe(icond_reg_reg);
 9571 %}
 9572 
 9573 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9574   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9575 
 9576   ins_cost(INSN_COST * 2);
 9577   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9578 
 9579   ins_encode %{
 9580     __ cselw(as_Register($dst$$reg),
 9581              as_Register($src2$$reg),
 9582              as_Register($src1$$reg),
 9583              (Assembler::Condition)$cmp$$cmpcode);
 9584   %}
 9585 
 9586   ins_pipe(icond_reg_reg);
 9587 %}
 9588 
 9589 // special cases where one arg is zero
 9590 
 9591 // n.b. this is selected in preference to the rule above because it
 9592 // avoids loading constant 0 into a source register
 9593 
 9594 // TODO
 9595 // we ought only to be able to cull one of these variants as the ideal
 9596 // transforms ought always to order the zero consistently (to left/right?)
 9597 
 9598 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9599   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9600 
 9601   ins_cost(INSN_COST * 2);
 9602   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9603 
 9604   ins_encode %{
 9605     __ cselw(as_Register($dst$$reg),
 9606              as_Register($src$$reg),
 9607              zr,
 9608              (Assembler::Condition)$cmp$$cmpcode);
 9609   %}
 9610 
 9611   ins_pipe(icond_reg);
 9612 %}
 9613 
 9614 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9615   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9616 
 9617   ins_cost(INSN_COST * 2);
 9618   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9619 
 9620   ins_encode %{
 9621     __ cselw(as_Register($dst$$reg),
 9622              as_Register($src$$reg),
 9623              zr,
 9624              (Assembler::Condition)$cmp$$cmpcode);
 9625   %}
 9626 
 9627   ins_pipe(icond_reg);
 9628 %}
 9629 
 9630 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9631   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9632 
 9633   ins_cost(INSN_COST * 2);
 9634   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9635 
 9636   ins_encode %{
 9637     __ cselw(as_Register($dst$$reg),
 9638              zr,
 9639              as_Register($src$$reg),
 9640              (Assembler::Condition)$cmp$$cmpcode);
 9641   %}
 9642 
 9643   ins_pipe(icond_reg);
 9644 %}
 9645 
 9646 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9647   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9648 
 9649   ins_cost(INSN_COST * 2);
 9650   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9651 
 9652   ins_encode %{
 9653     __ cselw(as_Register($dst$$reg),
 9654              zr,
 9655              as_Register($src$$reg),
 9656              (Assembler::Condition)$cmp$$cmpcode);
 9657   %}
 9658 
 9659   ins_pipe(icond_reg);
 9660 %}
 9661 
 9662 // special case for creating a boolean 0 or 1
 9663 
 9664 // n.b. this is selected in preference to the rule above because it
 9665 // avoids loading constants 0 and 1 into a source register
 9666 
 9667 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9668   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9669 
 9670   ins_cost(INSN_COST * 2);
 9671   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9672 
 9673   ins_encode %{
 9674     // equivalently
 9675     // cset(as_Register($dst$$reg),
 9676     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9677     __ csincw(as_Register($dst$$reg),
 9678              zr,
 9679              zr,
 9680              (Assembler::Condition)$cmp$$cmpcode);
 9681   %}
 9682 
 9683   ins_pipe(icond_none);
 9684 %}
 9685 
 9686 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9687   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9688 
 9689   ins_cost(INSN_COST * 2);
 9690   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9691 
 9692   ins_encode %{
 9693     // equivalently
 9694     // cset(as_Register($dst$$reg),
 9695     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9696     __ csincw(as_Register($dst$$reg),
 9697              zr,
 9698              zr,
 9699              (Assembler::Condition)$cmp$$cmpcode);
 9700   %}
 9701 
 9702   ins_pipe(icond_none);
 9703 %}
 9704 
 9705 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9706   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9707 
 9708   ins_cost(INSN_COST * 2);
<a name="25" id="anc25"></a><span class="line-modified"> 9709   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, int64_t&quot;  %}</span>
 9710 
 9711   ins_encode %{
 9712     __ csel(as_Register($dst$$reg),
 9713             as_Register($src2$$reg),
 9714             as_Register($src1$$reg),
 9715             (Assembler::Condition)$cmp$$cmpcode);
 9716   %}
 9717 
 9718   ins_pipe(icond_reg_reg);
 9719 %}
 9720 
 9721 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9722   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9723 
 9724   ins_cost(INSN_COST * 2);
<a name="26" id="anc26"></a><span class="line-modified"> 9725   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, int64_t&quot;  %}</span>
 9726 
 9727   ins_encode %{
 9728     __ csel(as_Register($dst$$reg),
 9729             as_Register($src2$$reg),
 9730             as_Register($src1$$reg),
 9731             (Assembler::Condition)$cmp$$cmpcode);
 9732   %}
 9733 
 9734   ins_pipe(icond_reg_reg);
 9735 %}
 9736 
 9737 // special cases where one arg is zero
 9738 
 9739 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9740   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9741 
 9742   ins_cost(INSN_COST * 2);
<a name="27" id="anc27"></a><span class="line-modified"> 9743   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, int64_t&quot;  %}</span>
 9744 
 9745   ins_encode %{
 9746     __ csel(as_Register($dst$$reg),
 9747             zr,
 9748             as_Register($src$$reg),
 9749             (Assembler::Condition)$cmp$$cmpcode);
 9750   %}
 9751 
 9752   ins_pipe(icond_reg);
 9753 %}
 9754 
 9755 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9756   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9757 
 9758   ins_cost(INSN_COST * 2);
<a name="28" id="anc28"></a><span class="line-modified"> 9759   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, int64_t&quot;  %}</span>
 9760 
 9761   ins_encode %{
 9762     __ csel(as_Register($dst$$reg),
 9763             zr,
 9764             as_Register($src$$reg),
 9765             (Assembler::Condition)$cmp$$cmpcode);
 9766   %}
 9767 
 9768   ins_pipe(icond_reg);
 9769 %}
 9770 
 9771 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9772   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9773 
 9774   ins_cost(INSN_COST * 2);
<a name="29" id="anc29"></a><span class="line-modified"> 9775   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, int64_t&quot;  %}</span>
 9776 
 9777   ins_encode %{
 9778     __ csel(as_Register($dst$$reg),
 9779             as_Register($src$$reg),
 9780             zr,
 9781             (Assembler::Condition)$cmp$$cmpcode);
 9782   %}
 9783 
 9784   ins_pipe(icond_reg);
 9785 %}
 9786 
 9787 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9788   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9789 
 9790   ins_cost(INSN_COST * 2);
<a name="30" id="anc30"></a><span class="line-modified"> 9791   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, int64_t&quot;  %}</span>
 9792 
 9793   ins_encode %{
 9794     __ csel(as_Register($dst$$reg),
 9795             as_Register($src$$reg),
 9796             zr,
 9797             (Assembler::Condition)$cmp$$cmpcode);
 9798   %}
 9799 
 9800   ins_pipe(icond_reg);
 9801 %}
 9802 
 9803 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9804   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9805 
 9806   ins_cost(INSN_COST * 2);
 9807   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9808 
 9809   ins_encode %{
 9810     __ csel(as_Register($dst$$reg),
 9811             as_Register($src2$$reg),
 9812             as_Register($src1$$reg),
 9813             (Assembler::Condition)$cmp$$cmpcode);
 9814   %}
 9815 
 9816   ins_pipe(icond_reg_reg);
 9817 %}
 9818 
 9819 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9820   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9821 
 9822   ins_cost(INSN_COST * 2);
 9823   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9824 
 9825   ins_encode %{
 9826     __ csel(as_Register($dst$$reg),
 9827             as_Register($src2$$reg),
 9828             as_Register($src1$$reg),
 9829             (Assembler::Condition)$cmp$$cmpcode);
 9830   %}
 9831 
 9832   ins_pipe(icond_reg_reg);
 9833 %}
 9834 
 9835 // special cases where one arg is zero
 9836 
 9837 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9838   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9839 
 9840   ins_cost(INSN_COST * 2);
 9841   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9842 
 9843   ins_encode %{
 9844     __ csel(as_Register($dst$$reg),
 9845             zr,
 9846             as_Register($src$$reg),
 9847             (Assembler::Condition)$cmp$$cmpcode);
 9848   %}
 9849 
 9850   ins_pipe(icond_reg);
 9851 %}
 9852 
 9853 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9854   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9855 
 9856   ins_cost(INSN_COST * 2);
 9857   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9858 
 9859   ins_encode %{
 9860     __ csel(as_Register($dst$$reg),
 9861             zr,
 9862             as_Register($src$$reg),
 9863             (Assembler::Condition)$cmp$$cmpcode);
 9864   %}
 9865 
 9866   ins_pipe(icond_reg);
 9867 %}
 9868 
 9869 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9870   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9871 
 9872   ins_cost(INSN_COST * 2);
 9873   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9874 
 9875   ins_encode %{
 9876     __ csel(as_Register($dst$$reg),
 9877             as_Register($src$$reg),
 9878             zr,
 9879             (Assembler::Condition)$cmp$$cmpcode);
 9880   %}
 9881 
 9882   ins_pipe(icond_reg);
 9883 %}
 9884 
 9885 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9886   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9887 
 9888   ins_cost(INSN_COST * 2);
 9889   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9890 
 9891   ins_encode %{
 9892     __ csel(as_Register($dst$$reg),
 9893             as_Register($src$$reg),
 9894             zr,
 9895             (Assembler::Condition)$cmp$$cmpcode);
 9896   %}
 9897 
 9898   ins_pipe(icond_reg);
 9899 %}
 9900 
 9901 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9902   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9903 
 9904   ins_cost(INSN_COST * 2);
 9905   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9906 
 9907   ins_encode %{
 9908     __ cselw(as_Register($dst$$reg),
 9909              as_Register($src2$$reg),
 9910              as_Register($src1$$reg),
 9911              (Assembler::Condition)$cmp$$cmpcode);
 9912   %}
 9913 
 9914   ins_pipe(icond_reg_reg);
 9915 %}
 9916 
 9917 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9918   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9919 
 9920   ins_cost(INSN_COST * 2);
 9921   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9922 
 9923   ins_encode %{
 9924     __ cselw(as_Register($dst$$reg),
 9925              as_Register($src2$$reg),
 9926              as_Register($src1$$reg),
 9927              (Assembler::Condition)$cmp$$cmpcode);
 9928   %}
 9929 
 9930   ins_pipe(icond_reg_reg);
 9931 %}
 9932 
 9933 // special cases where one arg is zero
 9934 
 9935 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9936   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9937 
 9938   ins_cost(INSN_COST * 2);
 9939   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9940 
 9941   ins_encode %{
 9942     __ cselw(as_Register($dst$$reg),
 9943              zr,
 9944              as_Register($src$$reg),
 9945              (Assembler::Condition)$cmp$$cmpcode);
 9946   %}
 9947 
 9948   ins_pipe(icond_reg);
 9949 %}
 9950 
 9951 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9952   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9953 
 9954   ins_cost(INSN_COST * 2);
 9955   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9956 
 9957   ins_encode %{
 9958     __ cselw(as_Register($dst$$reg),
 9959              zr,
 9960              as_Register($src$$reg),
 9961              (Assembler::Condition)$cmp$$cmpcode);
 9962   %}
 9963 
 9964   ins_pipe(icond_reg);
 9965 %}
 9966 
 9967 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9968   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9969 
 9970   ins_cost(INSN_COST * 2);
 9971   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
 9972 
 9973   ins_encode %{
 9974     __ cselw(as_Register($dst$$reg),
 9975              as_Register($src$$reg),
 9976              zr,
 9977              (Assembler::Condition)$cmp$$cmpcode);
 9978   %}
 9979 
 9980   ins_pipe(icond_reg);
 9981 %}
 9982 
 9983 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9984   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9985 
 9986   ins_cost(INSN_COST * 2);
 9987   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
 9988 
 9989   ins_encode %{
 9990     __ cselw(as_Register($dst$$reg),
 9991              as_Register($src$$reg),
 9992              zr,
 9993              (Assembler::Condition)$cmp$$cmpcode);
 9994   %}
 9995 
 9996   ins_pipe(icond_reg);
 9997 %}
 9998 
 9999 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
10000 %{
10001   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10002 
10003   ins_cost(INSN_COST * 3);
10004 
10005   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10006   ins_encode %{
10007     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10008     __ fcsels(as_FloatRegister($dst$$reg),
10009               as_FloatRegister($src2$$reg),
10010               as_FloatRegister($src1$$reg),
10011               cond);
10012   %}
10013 
10014   ins_pipe(fp_cond_reg_reg_s);
10015 %}
10016 
10017 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
10018 %{
10019   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10020 
10021   ins_cost(INSN_COST * 3);
10022 
10023   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10024   ins_encode %{
10025     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10026     __ fcsels(as_FloatRegister($dst$$reg),
10027               as_FloatRegister($src2$$reg),
10028               as_FloatRegister($src1$$reg),
10029               cond);
10030   %}
10031 
10032   ins_pipe(fp_cond_reg_reg_s);
10033 %}
10034 
10035 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10036 %{
10037   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10038 
10039   ins_cost(INSN_COST * 3);
10040 
10041   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10042   ins_encode %{
10043     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10044     __ fcseld(as_FloatRegister($dst$$reg),
10045               as_FloatRegister($src2$$reg),
10046               as_FloatRegister($src1$$reg),
10047               cond);
10048   %}
10049 
10050   ins_pipe(fp_cond_reg_reg_d);
10051 %}
10052 
10053 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10054 %{
10055   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10056 
10057   ins_cost(INSN_COST * 3);
10058 
10059   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10060   ins_encode %{
10061     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10062     __ fcseld(as_FloatRegister($dst$$reg),
10063               as_FloatRegister($src2$$reg),
10064               as_FloatRegister($src1$$reg),
10065               cond);
10066   %}
10067 
10068   ins_pipe(fp_cond_reg_reg_d);
10069 %}
10070 
10071 // ============================================================================
10072 // Arithmetic Instructions
10073 //
10074 
10075 // Integer Addition
10076 
10077 // TODO
10078 // these currently employ operations which do not set CR and hence are
10079 // not flagged as killing CR but we would like to isolate the cases
10080 // where we want to set flags from those where we don&#39;t. need to work
10081 // out how to do that.
10082 
10083 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10084   match(Set dst (AddI src1 src2));
10085 
10086   ins_cost(INSN_COST);
10087   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10088 
10089   ins_encode %{
10090     __ addw(as_Register($dst$$reg),
10091             as_Register($src1$$reg),
10092             as_Register($src2$$reg));
10093   %}
10094 
10095   ins_pipe(ialu_reg_reg);
10096 %}
10097 
10098 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10099   match(Set dst (AddI src1 src2));
10100 
10101   ins_cost(INSN_COST);
10102   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10103 
10104   // use opcode to indicate that this is an add not a sub
10105   opcode(0x0);
10106 
10107   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10108 
10109   ins_pipe(ialu_reg_imm);
10110 %}
10111 
10112 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10113   match(Set dst (AddI (ConvL2I src1) src2));
10114 
10115   ins_cost(INSN_COST);
10116   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10117 
10118   // use opcode to indicate that this is an add not a sub
10119   opcode(0x0);
10120 
10121   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10122 
10123   ins_pipe(ialu_reg_imm);
10124 %}
10125 
10126 // Pointer Addition
10127 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10128   match(Set dst (AddP src1 src2));
10129 
10130   ins_cost(INSN_COST);
10131   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10132 
10133   ins_encode %{
10134     __ add(as_Register($dst$$reg),
10135            as_Register($src1$$reg),
10136            as_Register($src2$$reg));
10137   %}
10138 
10139   ins_pipe(ialu_reg_reg);
10140 %}
10141 
10142 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10143   match(Set dst (AddP src1 (ConvI2L src2)));
10144 
10145   ins_cost(1.9 * INSN_COST);
10146   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10147 
10148   ins_encode %{
10149     __ add(as_Register($dst$$reg),
10150            as_Register($src1$$reg),
10151            as_Register($src2$$reg), ext::sxtw);
10152   %}
10153 
10154   ins_pipe(ialu_reg_reg);
10155 %}
10156 
10157 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10158   match(Set dst (AddP src1 (LShiftL src2 scale)));
10159 
10160   ins_cost(1.9 * INSN_COST);
10161   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10162 
10163   ins_encode %{
10164     __ lea(as_Register($dst$$reg),
10165            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10166                    Address::lsl($scale$$constant)));
10167   %}
10168 
10169   ins_pipe(ialu_reg_reg_shift);
10170 %}
10171 
10172 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10173   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10174 
10175   ins_cost(1.9 * INSN_COST);
10176   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10177 
10178   ins_encode %{
10179     __ lea(as_Register($dst$$reg),
10180            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10181                    Address::sxtw($scale$$constant)));
10182   %}
10183 
10184   ins_pipe(ialu_reg_reg_shift);
10185 %}
10186 
10187 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10188   match(Set dst (LShiftL (ConvI2L src) scale));
10189 
10190   ins_cost(INSN_COST);
10191   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10192 
10193   ins_encode %{
10194     __ sbfiz(as_Register($dst$$reg),
10195           as_Register($src$$reg),
<a name="31" id="anc31"></a><span class="line-modified">10196           $scale$$constant &amp; 63, MIN2((intptr_t)32, (-$scale$$constant) &amp; 63));</span>
10197   %}
10198 
10199   ins_pipe(ialu_reg_shift);
10200 %}
10201 
10202 // Pointer Immediate Addition
10203 // n.b. this needs to be more expensive than using an indirect memory
10204 // operand
10205 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10206   match(Set dst (AddP src1 src2));
10207 
10208   ins_cost(INSN_COST);
10209   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10210 
10211   // use opcode to indicate that this is an add not a sub
10212   opcode(0x0);
10213 
10214   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10215 
10216   ins_pipe(ialu_reg_imm);
10217 %}
10218 
10219 // Long Addition
10220 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10221 
10222   match(Set dst (AddL src1 src2));
10223 
10224   ins_cost(INSN_COST);
10225   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10226 
10227   ins_encode %{
10228     __ add(as_Register($dst$$reg),
10229            as_Register($src1$$reg),
10230            as_Register($src2$$reg));
10231   %}
10232 
10233   ins_pipe(ialu_reg_reg);
10234 %}
10235 
10236 // No constant pool entries requiredLong Immediate Addition.
10237 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10238   match(Set dst (AddL src1 src2));
10239 
10240   ins_cost(INSN_COST);
10241   format %{ &quot;add $dst, $src1, $src2&quot; %}
10242 
10243   // use opcode to indicate that this is an add not a sub
10244   opcode(0x0);
10245 
10246   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10247 
10248   ins_pipe(ialu_reg_imm);
10249 %}
10250 
10251 // Integer Subtraction
10252 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10253   match(Set dst (SubI src1 src2));
10254 
10255   ins_cost(INSN_COST);
10256   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10257 
10258   ins_encode %{
10259     __ subw(as_Register($dst$$reg),
10260             as_Register($src1$$reg),
10261             as_Register($src2$$reg));
10262   %}
10263 
10264   ins_pipe(ialu_reg_reg);
10265 %}
10266 
10267 // Immediate Subtraction
10268 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10269   match(Set dst (SubI src1 src2));
10270 
10271   ins_cost(INSN_COST);
10272   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10273 
10274   // use opcode to indicate that this is a sub not an add
10275   opcode(0x1);
10276 
10277   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10278 
10279   ins_pipe(ialu_reg_imm);
10280 %}
10281 
10282 // Long Subtraction
10283 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10284 
10285   match(Set dst (SubL src1 src2));
10286 
10287   ins_cost(INSN_COST);
10288   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10289 
10290   ins_encode %{
10291     __ sub(as_Register($dst$$reg),
10292            as_Register($src1$$reg),
10293            as_Register($src2$$reg));
10294   %}
10295 
10296   ins_pipe(ialu_reg_reg);
10297 %}
10298 
10299 // No constant pool entries requiredLong Immediate Subtraction.
10300 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10301   match(Set dst (SubL src1 src2));
10302 
10303   ins_cost(INSN_COST);
10304   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10305 
10306   // use opcode to indicate that this is a sub not an add
10307   opcode(0x1);
10308 
10309   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10310 
10311   ins_pipe(ialu_reg_imm);
10312 %}
10313 
10314 // Integer Negation (special case for sub)
10315 
10316 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10317   match(Set dst (SubI zero src));
10318 
10319   ins_cost(INSN_COST);
10320   format %{ &quot;negw $dst, $src\t# int&quot; %}
10321 
10322   ins_encode %{
10323     __ negw(as_Register($dst$$reg),
10324             as_Register($src$$reg));
10325   %}
10326 
10327   ins_pipe(ialu_reg);
10328 %}
10329 
10330 // Long Negation
10331 
10332 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10333   match(Set dst (SubL zero src));
10334 
10335   ins_cost(INSN_COST);
<a name="32" id="anc32"></a><span class="line-modified">10336   format %{ &quot;neg $dst, $src\t# int64_t&quot; %}</span>
10337 
10338   ins_encode %{
10339     __ neg(as_Register($dst$$reg),
10340            as_Register($src$$reg));
10341   %}
10342 
10343   ins_pipe(ialu_reg);
10344 %}
10345 
10346 // Integer Multiply
10347 
10348 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10349   match(Set dst (MulI src1 src2));
10350 
10351   ins_cost(INSN_COST * 3);
10352   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10353 
10354   ins_encode %{
10355     __ mulw(as_Register($dst$$reg),
10356             as_Register($src1$$reg),
10357             as_Register($src2$$reg));
10358   %}
10359 
10360   ins_pipe(imul_reg_reg);
10361 %}
10362 
10363 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10364   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10365 
10366   ins_cost(INSN_COST * 3);
10367   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10368 
10369   ins_encode %{
10370     __ smull(as_Register($dst$$reg),
10371              as_Register($src1$$reg),
10372              as_Register($src2$$reg));
10373   %}
10374 
10375   ins_pipe(imul_reg_reg);
10376 %}
10377 
10378 // Long Multiply
10379 
10380 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10381   match(Set dst (MulL src1 src2));
10382 
10383   ins_cost(INSN_COST * 5);
10384   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10385 
10386   ins_encode %{
10387     __ mul(as_Register($dst$$reg),
10388            as_Register($src1$$reg),
10389            as_Register($src2$$reg));
10390   %}
10391 
10392   ins_pipe(lmul_reg_reg);
10393 %}
10394 
10395 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10396 %{
10397   match(Set dst (MulHiL src1 src2));
10398 
10399   ins_cost(INSN_COST * 7);
10400   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10401 
10402   ins_encode %{
10403     __ smulh(as_Register($dst$$reg),
10404              as_Register($src1$$reg),
10405              as_Register($src2$$reg));
10406   %}
10407 
10408   ins_pipe(lmul_reg_reg);
10409 %}
10410 
10411 // Combined Integer Multiply &amp; Add/Sub
10412 
10413 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10414   match(Set dst (AddI src3 (MulI src1 src2)));
10415 
10416   ins_cost(INSN_COST * 3);
10417   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10418 
10419   ins_encode %{
10420     __ maddw(as_Register($dst$$reg),
10421              as_Register($src1$$reg),
10422              as_Register($src2$$reg),
10423              as_Register($src3$$reg));
10424   %}
10425 
10426   ins_pipe(imac_reg_reg);
10427 %}
10428 
10429 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10430   match(Set dst (SubI src3 (MulI src1 src2)));
10431 
10432   ins_cost(INSN_COST * 3);
10433   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10434 
10435   ins_encode %{
10436     __ msubw(as_Register($dst$$reg),
10437              as_Register($src1$$reg),
10438              as_Register($src2$$reg),
10439              as_Register($src3$$reg));
10440   %}
10441 
10442   ins_pipe(imac_reg_reg);
10443 %}
10444 
10445 // Combined Integer Multiply &amp; Neg
10446 
10447 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10448   match(Set dst (MulI (SubI zero src1) src2));
10449   match(Set dst (MulI src1 (SubI zero src2)));
10450 
10451   ins_cost(INSN_COST * 3);
10452   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10453 
10454   ins_encode %{
10455     __ mnegw(as_Register($dst$$reg),
10456              as_Register($src1$$reg),
10457              as_Register($src2$$reg));
10458   %}
10459 
10460   ins_pipe(imac_reg_reg);
10461 %}
10462 
10463 // Combined Long Multiply &amp; Add/Sub
10464 
10465 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10466   match(Set dst (AddL src3 (MulL src1 src2)));
10467 
10468   ins_cost(INSN_COST * 5);
10469   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10470 
10471   ins_encode %{
10472     __ madd(as_Register($dst$$reg),
10473             as_Register($src1$$reg),
10474             as_Register($src2$$reg),
10475             as_Register($src3$$reg));
10476   %}
10477 
10478   ins_pipe(lmac_reg_reg);
10479 %}
10480 
10481 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10482   match(Set dst (SubL src3 (MulL src1 src2)));
10483 
10484   ins_cost(INSN_COST * 5);
10485   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10486 
10487   ins_encode %{
10488     __ msub(as_Register($dst$$reg),
10489             as_Register($src1$$reg),
10490             as_Register($src2$$reg),
10491             as_Register($src3$$reg));
10492   %}
10493 
10494   ins_pipe(lmac_reg_reg);
10495 %}
10496 
10497 // Combined Long Multiply &amp; Neg
10498 
10499 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10500   match(Set dst (MulL (SubL zero src1) src2));
10501   match(Set dst (MulL src1 (SubL zero src2)));
10502 
10503   ins_cost(INSN_COST * 5);
10504   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10505 
10506   ins_encode %{
10507     __ mneg(as_Register($dst$$reg),
10508             as_Register($src1$$reg),
10509             as_Register($src2$$reg));
10510   %}
10511 
10512   ins_pipe(lmac_reg_reg);
10513 %}
10514 
10515 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10516 
10517 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10518   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10519 
10520   ins_cost(INSN_COST * 3);
10521   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10522 
10523   ins_encode %{
10524     __ smaddl(as_Register($dst$$reg),
10525               as_Register($src1$$reg),
10526               as_Register($src2$$reg),
10527               as_Register($src3$$reg));
10528   %}
10529 
10530   ins_pipe(imac_reg_reg);
10531 %}
10532 
10533 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10534   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10535 
10536   ins_cost(INSN_COST * 3);
10537   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10538 
10539   ins_encode %{
10540     __ smsubl(as_Register($dst$$reg),
10541               as_Register($src1$$reg),
10542               as_Register($src2$$reg),
10543               as_Register($src3$$reg));
10544   %}
10545 
10546   ins_pipe(imac_reg_reg);
10547 %}
10548 
10549 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10550   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10551   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10552 
10553   ins_cost(INSN_COST * 3);
10554   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10555 
10556   ins_encode %{
10557     __ smnegl(as_Register($dst$$reg),
10558               as_Register($src1$$reg),
10559               as_Register($src2$$reg));
10560   %}
10561 
10562   ins_pipe(imac_reg_reg);
10563 %}
10564 
10565 // Integer Divide
10566 
10567 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10568   match(Set dst (DivI src1 src2));
10569 
10570   ins_cost(INSN_COST * 19);
10571   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10572 
10573   ins_encode(aarch64_enc_divw(dst, src1, src2));
10574   ins_pipe(idiv_reg_reg);
10575 %}
10576 
10577 instruct signExtract(iRegINoSp dst, iRegIorL2I src1, immI_31 div1, immI_31 div2) %{
10578   match(Set dst (URShiftI (RShiftI src1 div1) div2));
10579   ins_cost(INSN_COST);
10580   format %{ &quot;lsrw $dst, $src1, $div1&quot; %}
10581   ins_encode %{
10582     __ lsrw(as_Register($dst$$reg), as_Register($src1$$reg), 31);
10583   %}
10584   ins_pipe(ialu_reg_shift);
10585 %}
10586 
10587 instruct div2Round(iRegINoSp dst, iRegIorL2I src, immI_31 div1, immI_31 div2) %{
10588   match(Set dst (AddI src (URShiftI (RShiftI src div1) div2)));
10589   ins_cost(INSN_COST);
10590   format %{ &quot;addw $dst, $src, LSR $div1&quot; %}
10591 
10592   ins_encode %{
10593     __ addw(as_Register($dst$$reg),
10594               as_Register($src$$reg),
10595               as_Register($src$$reg),
10596               Assembler::LSR, 31);
10597   %}
10598   ins_pipe(ialu_reg);
10599 %}
10600 
10601 // Long Divide
10602 
10603 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10604   match(Set dst (DivL src1 src2));
10605 
10606   ins_cost(INSN_COST * 35);
10607   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10608 
10609   ins_encode(aarch64_enc_div(dst, src1, src2));
10610   ins_pipe(ldiv_reg_reg);
10611 %}
10612 
10613 instruct signExtractL(iRegLNoSp dst, iRegL src1, immI_63 div1, immI_63 div2) %{
10614   match(Set dst (URShiftL (RShiftL src1 div1) div2));
10615   ins_cost(INSN_COST);
10616   format %{ &quot;lsr $dst, $src1, $div1&quot; %}
10617   ins_encode %{
10618     __ lsr(as_Register($dst$$reg), as_Register($src1$$reg), 63);
10619   %}
10620   ins_pipe(ialu_reg_shift);
10621 %}
10622 
10623 instruct div2RoundL(iRegLNoSp dst, iRegL src, immI_63 div1, immI_63 div2) %{
10624   match(Set dst (AddL src (URShiftL (RShiftL src div1) div2)));
10625   ins_cost(INSN_COST);
10626   format %{ &quot;add $dst, $src, $div1&quot; %}
10627 
10628   ins_encode %{
10629     __ add(as_Register($dst$$reg),
10630               as_Register($src$$reg),
10631               as_Register($src$$reg),
10632               Assembler::LSR, 63);
10633   %}
10634   ins_pipe(ialu_reg);
10635 %}
10636 
10637 // Integer Remainder
10638 
10639 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10640   match(Set dst (ModI src1 src2));
10641 
10642   ins_cost(INSN_COST * 22);
10643   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10644             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10645 
10646   ins_encode(aarch64_enc_modw(dst, src1, src2));
10647   ins_pipe(idiv_reg_reg);
10648 %}
10649 
10650 // Long Remainder
10651 
10652 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10653   match(Set dst (ModL src1 src2));
10654 
10655   ins_cost(INSN_COST * 38);
10656   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10657             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10658 
10659   ins_encode(aarch64_enc_mod(dst, src1, src2));
10660   ins_pipe(ldiv_reg_reg);
10661 %}
10662 
10663 // Integer Shifts
10664 
10665 // Shift Left Register
10666 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10667   match(Set dst (LShiftI src1 src2));
10668 
10669   ins_cost(INSN_COST * 2);
10670   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10671 
10672   ins_encode %{
10673     __ lslvw(as_Register($dst$$reg),
10674              as_Register($src1$$reg),
10675              as_Register($src2$$reg));
10676   %}
10677 
10678   ins_pipe(ialu_reg_reg_vshift);
10679 %}
10680 
10681 // Shift Left Immediate
10682 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10683   match(Set dst (LShiftI src1 src2));
10684 
10685   ins_cost(INSN_COST);
10686   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10687 
10688   ins_encode %{
10689     __ lslw(as_Register($dst$$reg),
10690             as_Register($src1$$reg),
10691             $src2$$constant &amp; 0x1f);
10692   %}
10693 
10694   ins_pipe(ialu_reg_shift);
10695 %}
10696 
10697 // Shift Right Logical Register
10698 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10699   match(Set dst (URShiftI src1 src2));
10700 
10701   ins_cost(INSN_COST * 2);
10702   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10703 
10704   ins_encode %{
10705     __ lsrvw(as_Register($dst$$reg),
10706              as_Register($src1$$reg),
10707              as_Register($src2$$reg));
10708   %}
10709 
10710   ins_pipe(ialu_reg_reg_vshift);
10711 %}
10712 
10713 // Shift Right Logical Immediate
10714 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10715   match(Set dst (URShiftI src1 src2));
10716 
10717   ins_cost(INSN_COST);
10718   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10719 
10720   ins_encode %{
10721     __ lsrw(as_Register($dst$$reg),
10722             as_Register($src1$$reg),
10723             $src2$$constant &amp; 0x1f);
10724   %}
10725 
10726   ins_pipe(ialu_reg_shift);
10727 %}
10728 
10729 // Shift Right Arithmetic Register
10730 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10731   match(Set dst (RShiftI src1 src2));
10732 
10733   ins_cost(INSN_COST * 2);
10734   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10735 
10736   ins_encode %{
10737     __ asrvw(as_Register($dst$$reg),
10738              as_Register($src1$$reg),
10739              as_Register($src2$$reg));
10740   %}
10741 
10742   ins_pipe(ialu_reg_reg_vshift);
10743 %}
10744 
10745 // Shift Right Arithmetic Immediate
10746 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10747   match(Set dst (RShiftI src1 src2));
10748 
10749   ins_cost(INSN_COST);
10750   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10751 
10752   ins_encode %{
10753     __ asrw(as_Register($dst$$reg),
10754             as_Register($src1$$reg),
10755             $src2$$constant &amp; 0x1f);
10756   %}
10757 
10758   ins_pipe(ialu_reg_shift);
10759 %}
10760 
10761 // Combined Int Mask and Right Shift (using UBFM)
10762 // TODO
10763 
10764 // Long Shifts
10765 
10766 // Shift Left Register
10767 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10768   match(Set dst (LShiftL src1 src2));
10769 
10770   ins_cost(INSN_COST * 2);
10771   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10772 
10773   ins_encode %{
10774     __ lslv(as_Register($dst$$reg),
10775             as_Register($src1$$reg),
10776             as_Register($src2$$reg));
10777   %}
10778 
10779   ins_pipe(ialu_reg_reg_vshift);
10780 %}
10781 
10782 // Shift Left Immediate
10783 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10784   match(Set dst (LShiftL src1 src2));
10785 
10786   ins_cost(INSN_COST);
10787   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10788 
10789   ins_encode %{
10790     __ lsl(as_Register($dst$$reg),
10791             as_Register($src1$$reg),
10792             $src2$$constant &amp; 0x3f);
10793   %}
10794 
10795   ins_pipe(ialu_reg_shift);
10796 %}
10797 
10798 // Shift Right Logical Register
10799 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10800   match(Set dst (URShiftL src1 src2));
10801 
10802   ins_cost(INSN_COST * 2);
10803   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10804 
10805   ins_encode %{
10806     __ lsrv(as_Register($dst$$reg),
10807             as_Register($src1$$reg),
10808             as_Register($src2$$reg));
10809   %}
10810 
10811   ins_pipe(ialu_reg_reg_vshift);
10812 %}
10813 
10814 // Shift Right Logical Immediate
10815 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10816   match(Set dst (URShiftL src1 src2));
10817 
10818   ins_cost(INSN_COST);
10819   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10820 
10821   ins_encode %{
10822     __ lsr(as_Register($dst$$reg),
10823            as_Register($src1$$reg),
10824            $src2$$constant &amp; 0x3f);
10825   %}
10826 
10827   ins_pipe(ialu_reg_shift);
10828 %}
10829 
10830 // A special-case pattern for card table stores.
10831 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10832   match(Set dst (URShiftL (CastP2X src1) src2));
10833 
10834   ins_cost(INSN_COST);
10835   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10836 
10837   ins_encode %{
10838     __ lsr(as_Register($dst$$reg),
10839            as_Register($src1$$reg),
10840            $src2$$constant &amp; 0x3f);
10841   %}
10842 
10843   ins_pipe(ialu_reg_shift);
10844 %}
10845 
10846 // Shift Right Arithmetic Register
10847 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10848   match(Set dst (RShiftL src1 src2));
10849 
10850   ins_cost(INSN_COST * 2);
10851   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10852 
10853   ins_encode %{
10854     __ asrv(as_Register($dst$$reg),
10855             as_Register($src1$$reg),
10856             as_Register($src2$$reg));
10857   %}
10858 
10859   ins_pipe(ialu_reg_reg_vshift);
10860 %}
10861 
10862 // Shift Right Arithmetic Immediate
10863 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10864   match(Set dst (RShiftL src1 src2));
10865 
10866   ins_cost(INSN_COST);
10867   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10868 
10869   ins_encode %{
10870     __ asr(as_Register($dst$$reg),
10871            as_Register($src1$$reg),
10872            $src2$$constant &amp; 0x3f);
10873   %}
10874 
10875   ins_pipe(ialu_reg_shift);
10876 %}
10877 
10878 // BEGIN This section of the file is automatically generated. Do not edit --------------
10879 
10880 instruct regL_not_reg(iRegLNoSp dst,
10881                          iRegL src1, immL_M1 m1,
10882                          rFlagsReg cr) %{
10883   match(Set dst (XorL src1 m1));
10884   ins_cost(INSN_COST);
10885   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10886 
10887   ins_encode %{
10888     __ eon(as_Register($dst$$reg),
10889               as_Register($src1$$reg),
10890               zr,
10891               Assembler::LSL, 0);
10892   %}
10893 
10894   ins_pipe(ialu_reg);
10895 %}
10896 instruct regI_not_reg(iRegINoSp dst,
10897                          iRegIorL2I src1, immI_M1 m1,
10898                          rFlagsReg cr) %{
10899   match(Set dst (XorI src1 m1));
10900   ins_cost(INSN_COST);
10901   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10902 
10903   ins_encode %{
10904     __ eonw(as_Register($dst$$reg),
10905               as_Register($src1$$reg),
10906               zr,
10907               Assembler::LSL, 0);
10908   %}
10909 
10910   ins_pipe(ialu_reg);
10911 %}
10912 
10913 instruct AndI_reg_not_reg(iRegINoSp dst,
10914                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10915                          rFlagsReg cr) %{
10916   match(Set dst (AndI src1 (XorI src2 m1)));
10917   ins_cost(INSN_COST);
10918   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10919 
10920   ins_encode %{
10921     __ bicw(as_Register($dst$$reg),
10922               as_Register($src1$$reg),
10923               as_Register($src2$$reg),
10924               Assembler::LSL, 0);
10925   %}
10926 
10927   ins_pipe(ialu_reg_reg);
10928 %}
10929 
10930 instruct AndL_reg_not_reg(iRegLNoSp dst,
10931                          iRegL src1, iRegL src2, immL_M1 m1,
10932                          rFlagsReg cr) %{
10933   match(Set dst (AndL src1 (XorL src2 m1)));
10934   ins_cost(INSN_COST);
10935   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10936 
10937   ins_encode %{
10938     __ bic(as_Register($dst$$reg),
10939               as_Register($src1$$reg),
10940               as_Register($src2$$reg),
10941               Assembler::LSL, 0);
10942   %}
10943 
10944   ins_pipe(ialu_reg_reg);
10945 %}
10946 
10947 instruct OrI_reg_not_reg(iRegINoSp dst,
10948                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10949                          rFlagsReg cr) %{
10950   match(Set dst (OrI src1 (XorI src2 m1)));
10951   ins_cost(INSN_COST);
10952   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10953 
10954   ins_encode %{
10955     __ ornw(as_Register($dst$$reg),
10956               as_Register($src1$$reg),
10957               as_Register($src2$$reg),
10958               Assembler::LSL, 0);
10959   %}
10960 
10961   ins_pipe(ialu_reg_reg);
10962 %}
10963 
10964 instruct OrL_reg_not_reg(iRegLNoSp dst,
10965                          iRegL src1, iRegL src2, immL_M1 m1,
10966                          rFlagsReg cr) %{
10967   match(Set dst (OrL src1 (XorL src2 m1)));
10968   ins_cost(INSN_COST);
10969   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10970 
10971   ins_encode %{
10972     __ orn(as_Register($dst$$reg),
10973               as_Register($src1$$reg),
10974               as_Register($src2$$reg),
10975               Assembler::LSL, 0);
10976   %}
10977 
10978   ins_pipe(ialu_reg_reg);
10979 %}
10980 
10981 instruct XorI_reg_not_reg(iRegINoSp dst,
10982                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10983                          rFlagsReg cr) %{
10984   match(Set dst (XorI m1 (XorI src2 src1)));
10985   ins_cost(INSN_COST);
10986   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10987 
10988   ins_encode %{
10989     __ eonw(as_Register($dst$$reg),
10990               as_Register($src1$$reg),
10991               as_Register($src2$$reg),
10992               Assembler::LSL, 0);
10993   %}
10994 
10995   ins_pipe(ialu_reg_reg);
10996 %}
10997 
10998 instruct XorL_reg_not_reg(iRegLNoSp dst,
10999                          iRegL src1, iRegL src2, immL_M1 m1,
11000                          rFlagsReg cr) %{
11001   match(Set dst (XorL m1 (XorL src2 src1)));
11002   ins_cost(INSN_COST);
11003   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
11004 
11005   ins_encode %{
11006     __ eon(as_Register($dst$$reg),
11007               as_Register($src1$$reg),
11008               as_Register($src2$$reg),
11009               Assembler::LSL, 0);
11010   %}
11011 
11012   ins_pipe(ialu_reg_reg);
11013 %}
11014 
11015 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11016                          iRegIorL2I src1, iRegIorL2I src2,
11017                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11018   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11019   ins_cost(1.9 * INSN_COST);
11020   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11021 
11022   ins_encode %{
11023     __ bicw(as_Register($dst$$reg),
11024               as_Register($src1$$reg),
11025               as_Register($src2$$reg),
11026               Assembler::LSR,
11027               $src3$$constant &amp; 0x1f);
11028   %}
11029 
11030   ins_pipe(ialu_reg_reg_shift);
11031 %}
11032 
11033 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11034                          iRegL src1, iRegL src2,
11035                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11036   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11037   ins_cost(1.9 * INSN_COST);
11038   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11039 
11040   ins_encode %{
11041     __ bic(as_Register($dst$$reg),
11042               as_Register($src1$$reg),
11043               as_Register($src2$$reg),
11044               Assembler::LSR,
11045               $src3$$constant &amp; 0x3f);
11046   %}
11047 
11048   ins_pipe(ialu_reg_reg_shift);
11049 %}
11050 
11051 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11052                          iRegIorL2I src1, iRegIorL2I src2,
11053                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11054   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11055   ins_cost(1.9 * INSN_COST);
11056   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11057 
11058   ins_encode %{
11059     __ bicw(as_Register($dst$$reg),
11060               as_Register($src1$$reg),
11061               as_Register($src2$$reg),
11062               Assembler::ASR,
11063               $src3$$constant &amp; 0x1f);
11064   %}
11065 
11066   ins_pipe(ialu_reg_reg_shift);
11067 %}
11068 
11069 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11070                          iRegL src1, iRegL src2,
11071                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11072   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11073   ins_cost(1.9 * INSN_COST);
11074   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11075 
11076   ins_encode %{
11077     __ bic(as_Register($dst$$reg),
11078               as_Register($src1$$reg),
11079               as_Register($src2$$reg),
11080               Assembler::ASR,
11081               $src3$$constant &amp; 0x3f);
11082   %}
11083 
11084   ins_pipe(ialu_reg_reg_shift);
11085 %}
11086 
11087 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11088                          iRegIorL2I src1, iRegIorL2I src2,
11089                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11090   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11091   ins_cost(1.9 * INSN_COST);
11092   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11093 
11094   ins_encode %{
11095     __ bicw(as_Register($dst$$reg),
11096               as_Register($src1$$reg),
11097               as_Register($src2$$reg),
11098               Assembler::LSL,
11099               $src3$$constant &amp; 0x1f);
11100   %}
11101 
11102   ins_pipe(ialu_reg_reg_shift);
11103 %}
11104 
11105 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11106                          iRegL src1, iRegL src2,
11107                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11108   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11109   ins_cost(1.9 * INSN_COST);
11110   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11111 
11112   ins_encode %{
11113     __ bic(as_Register($dst$$reg),
11114               as_Register($src1$$reg),
11115               as_Register($src2$$reg),
11116               Assembler::LSL,
11117               $src3$$constant &amp; 0x3f);
11118   %}
11119 
11120   ins_pipe(ialu_reg_reg_shift);
11121 %}
11122 
11123 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11124                          iRegIorL2I src1, iRegIorL2I src2,
11125                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11126   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11127   ins_cost(1.9 * INSN_COST);
11128   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11129 
11130   ins_encode %{
11131     __ eonw(as_Register($dst$$reg),
11132               as_Register($src1$$reg),
11133               as_Register($src2$$reg),
11134               Assembler::LSR,
11135               $src3$$constant &amp; 0x1f);
11136   %}
11137 
11138   ins_pipe(ialu_reg_reg_shift);
11139 %}
11140 
11141 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11142                          iRegL src1, iRegL src2,
11143                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11144   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11145   ins_cost(1.9 * INSN_COST);
11146   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11147 
11148   ins_encode %{
11149     __ eon(as_Register($dst$$reg),
11150               as_Register($src1$$reg),
11151               as_Register($src2$$reg),
11152               Assembler::LSR,
11153               $src3$$constant &amp; 0x3f);
11154   %}
11155 
11156   ins_pipe(ialu_reg_reg_shift);
11157 %}
11158 
11159 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11160                          iRegIorL2I src1, iRegIorL2I src2,
11161                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11162   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11163   ins_cost(1.9 * INSN_COST);
11164   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11165 
11166   ins_encode %{
11167     __ eonw(as_Register($dst$$reg),
11168               as_Register($src1$$reg),
11169               as_Register($src2$$reg),
11170               Assembler::ASR,
11171               $src3$$constant &amp; 0x1f);
11172   %}
11173 
11174   ins_pipe(ialu_reg_reg_shift);
11175 %}
11176 
11177 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11178                          iRegL src1, iRegL src2,
11179                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11180   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11181   ins_cost(1.9 * INSN_COST);
11182   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11183 
11184   ins_encode %{
11185     __ eon(as_Register($dst$$reg),
11186               as_Register($src1$$reg),
11187               as_Register($src2$$reg),
11188               Assembler::ASR,
11189               $src3$$constant &amp; 0x3f);
11190   %}
11191 
11192   ins_pipe(ialu_reg_reg_shift);
11193 %}
11194 
11195 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11196                          iRegIorL2I src1, iRegIorL2I src2,
11197                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11198   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11199   ins_cost(1.9 * INSN_COST);
11200   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11201 
11202   ins_encode %{
11203     __ eonw(as_Register($dst$$reg),
11204               as_Register($src1$$reg),
11205               as_Register($src2$$reg),
11206               Assembler::LSL,
11207               $src3$$constant &amp; 0x1f);
11208   %}
11209 
11210   ins_pipe(ialu_reg_reg_shift);
11211 %}
11212 
11213 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11214                          iRegL src1, iRegL src2,
11215                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11216   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11217   ins_cost(1.9 * INSN_COST);
11218   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11219 
11220   ins_encode %{
11221     __ eon(as_Register($dst$$reg),
11222               as_Register($src1$$reg),
11223               as_Register($src2$$reg),
11224               Assembler::LSL,
11225               $src3$$constant &amp; 0x3f);
11226   %}
11227 
11228   ins_pipe(ialu_reg_reg_shift);
11229 %}
11230 
11231 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11232                          iRegIorL2I src1, iRegIorL2I src2,
11233                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11234   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11235   ins_cost(1.9 * INSN_COST);
11236   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11237 
11238   ins_encode %{
11239     __ ornw(as_Register($dst$$reg),
11240               as_Register($src1$$reg),
11241               as_Register($src2$$reg),
11242               Assembler::LSR,
11243               $src3$$constant &amp; 0x1f);
11244   %}
11245 
11246   ins_pipe(ialu_reg_reg_shift);
11247 %}
11248 
11249 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11250                          iRegL src1, iRegL src2,
11251                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11252   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11253   ins_cost(1.9 * INSN_COST);
11254   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11255 
11256   ins_encode %{
11257     __ orn(as_Register($dst$$reg),
11258               as_Register($src1$$reg),
11259               as_Register($src2$$reg),
11260               Assembler::LSR,
11261               $src3$$constant &amp; 0x3f);
11262   %}
11263 
11264   ins_pipe(ialu_reg_reg_shift);
11265 %}
11266 
11267 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11268                          iRegIorL2I src1, iRegIorL2I src2,
11269                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11270   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11271   ins_cost(1.9 * INSN_COST);
11272   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11273 
11274   ins_encode %{
11275     __ ornw(as_Register($dst$$reg),
11276               as_Register($src1$$reg),
11277               as_Register($src2$$reg),
11278               Assembler::ASR,
11279               $src3$$constant &amp; 0x1f);
11280   %}
11281 
11282   ins_pipe(ialu_reg_reg_shift);
11283 %}
11284 
11285 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11286                          iRegL src1, iRegL src2,
11287                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11288   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11289   ins_cost(1.9 * INSN_COST);
11290   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11291 
11292   ins_encode %{
11293     __ orn(as_Register($dst$$reg),
11294               as_Register($src1$$reg),
11295               as_Register($src2$$reg),
11296               Assembler::ASR,
11297               $src3$$constant &amp; 0x3f);
11298   %}
11299 
11300   ins_pipe(ialu_reg_reg_shift);
11301 %}
11302 
11303 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11304                          iRegIorL2I src1, iRegIorL2I src2,
11305                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11306   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11307   ins_cost(1.9 * INSN_COST);
11308   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11309 
11310   ins_encode %{
11311     __ ornw(as_Register($dst$$reg),
11312               as_Register($src1$$reg),
11313               as_Register($src2$$reg),
11314               Assembler::LSL,
11315               $src3$$constant &amp; 0x1f);
11316   %}
11317 
11318   ins_pipe(ialu_reg_reg_shift);
11319 %}
11320 
11321 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11322                          iRegL src1, iRegL src2,
11323                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11324   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11325   ins_cost(1.9 * INSN_COST);
11326   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11327 
11328   ins_encode %{
11329     __ orn(as_Register($dst$$reg),
11330               as_Register($src1$$reg),
11331               as_Register($src2$$reg),
11332               Assembler::LSL,
11333               $src3$$constant &amp; 0x3f);
11334   %}
11335 
11336   ins_pipe(ialu_reg_reg_shift);
11337 %}
11338 
11339 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11340                          iRegIorL2I src1, iRegIorL2I src2,
11341                          immI src3, rFlagsReg cr) %{
11342   match(Set dst (AndI src1 (URShiftI src2 src3)));
11343 
11344   ins_cost(1.9 * INSN_COST);
11345   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11346 
11347   ins_encode %{
11348     __ andw(as_Register($dst$$reg),
11349               as_Register($src1$$reg),
11350               as_Register($src2$$reg),
11351               Assembler::LSR,
11352               $src3$$constant &amp; 0x1f);
11353   %}
11354 
11355   ins_pipe(ialu_reg_reg_shift);
11356 %}
11357 
11358 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11359                          iRegL src1, iRegL src2,
11360                          immI src3, rFlagsReg cr) %{
11361   match(Set dst (AndL src1 (URShiftL src2 src3)));
11362 
11363   ins_cost(1.9 * INSN_COST);
11364   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11365 
11366   ins_encode %{
11367     __ andr(as_Register($dst$$reg),
11368               as_Register($src1$$reg),
11369               as_Register($src2$$reg),
11370               Assembler::LSR,
11371               $src3$$constant &amp; 0x3f);
11372   %}
11373 
11374   ins_pipe(ialu_reg_reg_shift);
11375 %}
11376 
11377 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11378                          iRegIorL2I src1, iRegIorL2I src2,
11379                          immI src3, rFlagsReg cr) %{
11380   match(Set dst (AndI src1 (RShiftI src2 src3)));
11381 
11382   ins_cost(1.9 * INSN_COST);
11383   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11384 
11385   ins_encode %{
11386     __ andw(as_Register($dst$$reg),
11387               as_Register($src1$$reg),
11388               as_Register($src2$$reg),
11389               Assembler::ASR,
11390               $src3$$constant &amp; 0x1f);
11391   %}
11392 
11393   ins_pipe(ialu_reg_reg_shift);
11394 %}
11395 
11396 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11397                          iRegL src1, iRegL src2,
11398                          immI src3, rFlagsReg cr) %{
11399   match(Set dst (AndL src1 (RShiftL src2 src3)));
11400 
11401   ins_cost(1.9 * INSN_COST);
11402   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11403 
11404   ins_encode %{
11405     __ andr(as_Register($dst$$reg),
11406               as_Register($src1$$reg),
11407               as_Register($src2$$reg),
11408               Assembler::ASR,
11409               $src3$$constant &amp; 0x3f);
11410   %}
11411 
11412   ins_pipe(ialu_reg_reg_shift);
11413 %}
11414 
11415 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11416                          iRegIorL2I src1, iRegIorL2I src2,
11417                          immI src3, rFlagsReg cr) %{
11418   match(Set dst (AndI src1 (LShiftI src2 src3)));
11419 
11420   ins_cost(1.9 * INSN_COST);
11421   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11422 
11423   ins_encode %{
11424     __ andw(as_Register($dst$$reg),
11425               as_Register($src1$$reg),
11426               as_Register($src2$$reg),
11427               Assembler::LSL,
11428               $src3$$constant &amp; 0x1f);
11429   %}
11430 
11431   ins_pipe(ialu_reg_reg_shift);
11432 %}
11433 
11434 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11435                          iRegL src1, iRegL src2,
11436                          immI src3, rFlagsReg cr) %{
11437   match(Set dst (AndL src1 (LShiftL src2 src3)));
11438 
11439   ins_cost(1.9 * INSN_COST);
11440   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11441 
11442   ins_encode %{
11443     __ andr(as_Register($dst$$reg),
11444               as_Register($src1$$reg),
11445               as_Register($src2$$reg),
11446               Assembler::LSL,
11447               $src3$$constant &amp; 0x3f);
11448   %}
11449 
11450   ins_pipe(ialu_reg_reg_shift);
11451 %}
11452 
11453 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11454                          iRegIorL2I src1, iRegIorL2I src2,
11455                          immI src3, rFlagsReg cr) %{
11456   match(Set dst (XorI src1 (URShiftI src2 src3)));
11457 
11458   ins_cost(1.9 * INSN_COST);
11459   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11460 
11461   ins_encode %{
11462     __ eorw(as_Register($dst$$reg),
11463               as_Register($src1$$reg),
11464               as_Register($src2$$reg),
11465               Assembler::LSR,
11466               $src3$$constant &amp; 0x1f);
11467   %}
11468 
11469   ins_pipe(ialu_reg_reg_shift);
11470 %}
11471 
11472 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11473                          iRegL src1, iRegL src2,
11474                          immI src3, rFlagsReg cr) %{
11475   match(Set dst (XorL src1 (URShiftL src2 src3)));
11476 
11477   ins_cost(1.9 * INSN_COST);
11478   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11479 
11480   ins_encode %{
11481     __ eor(as_Register($dst$$reg),
11482               as_Register($src1$$reg),
11483               as_Register($src2$$reg),
11484               Assembler::LSR,
11485               $src3$$constant &amp; 0x3f);
11486   %}
11487 
11488   ins_pipe(ialu_reg_reg_shift);
11489 %}
11490 
11491 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11492                          iRegIorL2I src1, iRegIorL2I src2,
11493                          immI src3, rFlagsReg cr) %{
11494   match(Set dst (XorI src1 (RShiftI src2 src3)));
11495 
11496   ins_cost(1.9 * INSN_COST);
11497   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11498 
11499   ins_encode %{
11500     __ eorw(as_Register($dst$$reg),
11501               as_Register($src1$$reg),
11502               as_Register($src2$$reg),
11503               Assembler::ASR,
11504               $src3$$constant &amp; 0x1f);
11505   %}
11506 
11507   ins_pipe(ialu_reg_reg_shift);
11508 %}
11509 
11510 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11511                          iRegL src1, iRegL src2,
11512                          immI src3, rFlagsReg cr) %{
11513   match(Set dst (XorL src1 (RShiftL src2 src3)));
11514 
11515   ins_cost(1.9 * INSN_COST);
11516   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11517 
11518   ins_encode %{
11519     __ eor(as_Register($dst$$reg),
11520               as_Register($src1$$reg),
11521               as_Register($src2$$reg),
11522               Assembler::ASR,
11523               $src3$$constant &amp; 0x3f);
11524   %}
11525 
11526   ins_pipe(ialu_reg_reg_shift);
11527 %}
11528 
11529 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11530                          iRegIorL2I src1, iRegIorL2I src2,
11531                          immI src3, rFlagsReg cr) %{
11532   match(Set dst (XorI src1 (LShiftI src2 src3)));
11533 
11534   ins_cost(1.9 * INSN_COST);
11535   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11536 
11537   ins_encode %{
11538     __ eorw(as_Register($dst$$reg),
11539               as_Register($src1$$reg),
11540               as_Register($src2$$reg),
11541               Assembler::LSL,
11542               $src3$$constant &amp; 0x1f);
11543   %}
11544 
11545   ins_pipe(ialu_reg_reg_shift);
11546 %}
11547 
11548 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11549                          iRegL src1, iRegL src2,
11550                          immI src3, rFlagsReg cr) %{
11551   match(Set dst (XorL src1 (LShiftL src2 src3)));
11552 
11553   ins_cost(1.9 * INSN_COST);
11554   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11555 
11556   ins_encode %{
11557     __ eor(as_Register($dst$$reg),
11558               as_Register($src1$$reg),
11559               as_Register($src2$$reg),
11560               Assembler::LSL,
11561               $src3$$constant &amp; 0x3f);
11562   %}
11563 
11564   ins_pipe(ialu_reg_reg_shift);
11565 %}
11566 
11567 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11568                          iRegIorL2I src1, iRegIorL2I src2,
11569                          immI src3, rFlagsReg cr) %{
11570   match(Set dst (OrI src1 (URShiftI src2 src3)));
11571 
11572   ins_cost(1.9 * INSN_COST);
11573   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11574 
11575   ins_encode %{
11576     __ orrw(as_Register($dst$$reg),
11577               as_Register($src1$$reg),
11578               as_Register($src2$$reg),
11579               Assembler::LSR,
11580               $src3$$constant &amp; 0x1f);
11581   %}
11582 
11583   ins_pipe(ialu_reg_reg_shift);
11584 %}
11585 
11586 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11587                          iRegL src1, iRegL src2,
11588                          immI src3, rFlagsReg cr) %{
11589   match(Set dst (OrL src1 (URShiftL src2 src3)));
11590 
11591   ins_cost(1.9 * INSN_COST);
11592   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11593 
11594   ins_encode %{
11595     __ orr(as_Register($dst$$reg),
11596               as_Register($src1$$reg),
11597               as_Register($src2$$reg),
11598               Assembler::LSR,
11599               $src3$$constant &amp; 0x3f);
11600   %}
11601 
11602   ins_pipe(ialu_reg_reg_shift);
11603 %}
11604 
11605 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11606                          iRegIorL2I src1, iRegIorL2I src2,
11607                          immI src3, rFlagsReg cr) %{
11608   match(Set dst (OrI src1 (RShiftI src2 src3)));
11609 
11610   ins_cost(1.9 * INSN_COST);
11611   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11612 
11613   ins_encode %{
11614     __ orrw(as_Register($dst$$reg),
11615               as_Register($src1$$reg),
11616               as_Register($src2$$reg),
11617               Assembler::ASR,
11618               $src3$$constant &amp; 0x1f);
11619   %}
11620 
11621   ins_pipe(ialu_reg_reg_shift);
11622 %}
11623 
11624 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11625                          iRegL src1, iRegL src2,
11626                          immI src3, rFlagsReg cr) %{
11627   match(Set dst (OrL src1 (RShiftL src2 src3)));
11628 
11629   ins_cost(1.9 * INSN_COST);
11630   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11631 
11632   ins_encode %{
11633     __ orr(as_Register($dst$$reg),
11634               as_Register($src1$$reg),
11635               as_Register($src2$$reg),
11636               Assembler::ASR,
11637               $src3$$constant &amp; 0x3f);
11638   %}
11639 
11640   ins_pipe(ialu_reg_reg_shift);
11641 %}
11642 
11643 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11644                          iRegIorL2I src1, iRegIorL2I src2,
11645                          immI src3, rFlagsReg cr) %{
11646   match(Set dst (OrI src1 (LShiftI src2 src3)));
11647 
11648   ins_cost(1.9 * INSN_COST);
11649   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11650 
11651   ins_encode %{
11652     __ orrw(as_Register($dst$$reg),
11653               as_Register($src1$$reg),
11654               as_Register($src2$$reg),
11655               Assembler::LSL,
11656               $src3$$constant &amp; 0x1f);
11657   %}
11658 
11659   ins_pipe(ialu_reg_reg_shift);
11660 %}
11661 
11662 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11663                          iRegL src1, iRegL src2,
11664                          immI src3, rFlagsReg cr) %{
11665   match(Set dst (OrL src1 (LShiftL src2 src3)));
11666 
11667   ins_cost(1.9 * INSN_COST);
11668   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11669 
11670   ins_encode %{
11671     __ orr(as_Register($dst$$reg),
11672               as_Register($src1$$reg),
11673               as_Register($src2$$reg),
11674               Assembler::LSL,
11675               $src3$$constant &amp; 0x3f);
11676   %}
11677 
11678   ins_pipe(ialu_reg_reg_shift);
11679 %}
11680 
11681 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11682                          iRegIorL2I src1, iRegIorL2I src2,
11683                          immI src3, rFlagsReg cr) %{
11684   match(Set dst (AddI src1 (URShiftI src2 src3)));
11685 
11686   ins_cost(1.9 * INSN_COST);
11687   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11688 
11689   ins_encode %{
11690     __ addw(as_Register($dst$$reg),
11691               as_Register($src1$$reg),
11692               as_Register($src2$$reg),
11693               Assembler::LSR,
11694               $src3$$constant &amp; 0x1f);
11695   %}
11696 
11697   ins_pipe(ialu_reg_reg_shift);
11698 %}
11699 
11700 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11701                          iRegL src1, iRegL src2,
11702                          immI src3, rFlagsReg cr) %{
11703   match(Set dst (AddL src1 (URShiftL src2 src3)));
11704 
11705   ins_cost(1.9 * INSN_COST);
11706   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11707 
11708   ins_encode %{
11709     __ add(as_Register($dst$$reg),
11710               as_Register($src1$$reg),
11711               as_Register($src2$$reg),
11712               Assembler::LSR,
11713               $src3$$constant &amp; 0x3f);
11714   %}
11715 
11716   ins_pipe(ialu_reg_reg_shift);
11717 %}
11718 
11719 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11720                          iRegIorL2I src1, iRegIorL2I src2,
11721                          immI src3, rFlagsReg cr) %{
11722   match(Set dst (AddI src1 (RShiftI src2 src3)));
11723 
11724   ins_cost(1.9 * INSN_COST);
11725   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11726 
11727   ins_encode %{
11728     __ addw(as_Register($dst$$reg),
11729               as_Register($src1$$reg),
11730               as_Register($src2$$reg),
11731               Assembler::ASR,
11732               $src3$$constant &amp; 0x1f);
11733   %}
11734 
11735   ins_pipe(ialu_reg_reg_shift);
11736 %}
11737 
11738 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11739                          iRegL src1, iRegL src2,
11740                          immI src3, rFlagsReg cr) %{
11741   match(Set dst (AddL src1 (RShiftL src2 src3)));
11742 
11743   ins_cost(1.9 * INSN_COST);
11744   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11745 
11746   ins_encode %{
11747     __ add(as_Register($dst$$reg),
11748               as_Register($src1$$reg),
11749               as_Register($src2$$reg),
11750               Assembler::ASR,
11751               $src3$$constant &amp; 0x3f);
11752   %}
11753 
11754   ins_pipe(ialu_reg_reg_shift);
11755 %}
11756 
11757 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11758                          iRegIorL2I src1, iRegIorL2I src2,
11759                          immI src3, rFlagsReg cr) %{
11760   match(Set dst (AddI src1 (LShiftI src2 src3)));
11761 
11762   ins_cost(1.9 * INSN_COST);
11763   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11764 
11765   ins_encode %{
11766     __ addw(as_Register($dst$$reg),
11767               as_Register($src1$$reg),
11768               as_Register($src2$$reg),
11769               Assembler::LSL,
11770               $src3$$constant &amp; 0x1f);
11771   %}
11772 
11773   ins_pipe(ialu_reg_reg_shift);
11774 %}
11775 
11776 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11777                          iRegL src1, iRegL src2,
11778                          immI src3, rFlagsReg cr) %{
11779   match(Set dst (AddL src1 (LShiftL src2 src3)));
11780 
11781   ins_cost(1.9 * INSN_COST);
11782   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11783 
11784   ins_encode %{
11785     __ add(as_Register($dst$$reg),
11786               as_Register($src1$$reg),
11787               as_Register($src2$$reg),
11788               Assembler::LSL,
11789               $src3$$constant &amp; 0x3f);
11790   %}
11791 
11792   ins_pipe(ialu_reg_reg_shift);
11793 %}
11794 
11795 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11796                          iRegIorL2I src1, iRegIorL2I src2,
11797                          immI src3, rFlagsReg cr) %{
11798   match(Set dst (SubI src1 (URShiftI src2 src3)));
11799 
11800   ins_cost(1.9 * INSN_COST);
11801   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11802 
11803   ins_encode %{
11804     __ subw(as_Register($dst$$reg),
11805               as_Register($src1$$reg),
11806               as_Register($src2$$reg),
11807               Assembler::LSR,
11808               $src3$$constant &amp; 0x1f);
11809   %}
11810 
11811   ins_pipe(ialu_reg_reg_shift);
11812 %}
11813 
11814 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11815                          iRegL src1, iRegL src2,
11816                          immI src3, rFlagsReg cr) %{
11817   match(Set dst (SubL src1 (URShiftL src2 src3)));
11818 
11819   ins_cost(1.9 * INSN_COST);
11820   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11821 
11822   ins_encode %{
11823     __ sub(as_Register($dst$$reg),
11824               as_Register($src1$$reg),
11825               as_Register($src2$$reg),
11826               Assembler::LSR,
11827               $src3$$constant &amp; 0x3f);
11828   %}
11829 
11830   ins_pipe(ialu_reg_reg_shift);
11831 %}
11832 
11833 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11834                          iRegIorL2I src1, iRegIorL2I src2,
11835                          immI src3, rFlagsReg cr) %{
11836   match(Set dst (SubI src1 (RShiftI src2 src3)));
11837 
11838   ins_cost(1.9 * INSN_COST);
11839   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11840 
11841   ins_encode %{
11842     __ subw(as_Register($dst$$reg),
11843               as_Register($src1$$reg),
11844               as_Register($src2$$reg),
11845               Assembler::ASR,
11846               $src3$$constant &amp; 0x1f);
11847   %}
11848 
11849   ins_pipe(ialu_reg_reg_shift);
11850 %}
11851 
11852 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11853                          iRegL src1, iRegL src2,
11854                          immI src3, rFlagsReg cr) %{
11855   match(Set dst (SubL src1 (RShiftL src2 src3)));
11856 
11857   ins_cost(1.9 * INSN_COST);
11858   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11859 
11860   ins_encode %{
11861     __ sub(as_Register($dst$$reg),
11862               as_Register($src1$$reg),
11863               as_Register($src2$$reg),
11864               Assembler::ASR,
11865               $src3$$constant &amp; 0x3f);
11866   %}
11867 
11868   ins_pipe(ialu_reg_reg_shift);
11869 %}
11870 
11871 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11872                          iRegIorL2I src1, iRegIorL2I src2,
11873                          immI src3, rFlagsReg cr) %{
11874   match(Set dst (SubI src1 (LShiftI src2 src3)));
11875 
11876   ins_cost(1.9 * INSN_COST);
11877   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11878 
11879   ins_encode %{
11880     __ subw(as_Register($dst$$reg),
11881               as_Register($src1$$reg),
11882               as_Register($src2$$reg),
11883               Assembler::LSL,
11884               $src3$$constant &amp; 0x1f);
11885   %}
11886 
11887   ins_pipe(ialu_reg_reg_shift);
11888 %}
11889 
11890 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11891                          iRegL src1, iRegL src2,
11892                          immI src3, rFlagsReg cr) %{
11893   match(Set dst (SubL src1 (LShiftL src2 src3)));
11894 
11895   ins_cost(1.9 * INSN_COST);
11896   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11897 
11898   ins_encode %{
11899     __ sub(as_Register($dst$$reg),
11900               as_Register($src1$$reg),
11901               as_Register($src2$$reg),
11902               Assembler::LSL,
11903               $src3$$constant &amp; 0x3f);
11904   %}
11905 
11906   ins_pipe(ialu_reg_reg_shift);
11907 %}
11908 
11909 
11910 
11911 // Shift Left followed by Shift Right.
11912 // This idiom is used by the compiler for the i2b bytecode etc.
11913 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11914 %{
11915   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11916   ins_cost(INSN_COST * 2);
11917   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11918   ins_encode %{
11919     int lshift = $lshift_count$$constant &amp; 63;
11920     int rshift = $rshift_count$$constant &amp; 63;
11921     int s = 63 - lshift;
11922     int r = (rshift - lshift) &amp; 63;
11923     __ sbfm(as_Register($dst$$reg),
11924             as_Register($src$$reg),
11925             r, s);
11926   %}
11927 
11928   ins_pipe(ialu_reg_shift);
11929 %}
11930 
11931 // Shift Left followed by Shift Right.
11932 // This idiom is used by the compiler for the i2b bytecode etc.
11933 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11934 %{
11935   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11936   ins_cost(INSN_COST * 2);
11937   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11938   ins_encode %{
11939     int lshift = $lshift_count$$constant &amp; 31;
11940     int rshift = $rshift_count$$constant &amp; 31;
11941     int s = 31 - lshift;
11942     int r = (rshift - lshift) &amp; 31;
11943     __ sbfmw(as_Register($dst$$reg),
11944             as_Register($src$$reg),
11945             r, s);
11946   %}
11947 
11948   ins_pipe(ialu_reg_shift);
11949 %}
11950 
11951 // Shift Left followed by Shift Right.
11952 // This idiom is used by the compiler for the i2b bytecode etc.
11953 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11954 %{
11955   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11956   ins_cost(INSN_COST * 2);
11957   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11958   ins_encode %{
11959     int lshift = $lshift_count$$constant &amp; 63;
11960     int rshift = $rshift_count$$constant &amp; 63;
11961     int s = 63 - lshift;
11962     int r = (rshift - lshift) &amp; 63;
11963     __ ubfm(as_Register($dst$$reg),
11964             as_Register($src$$reg),
11965             r, s);
11966   %}
11967 
11968   ins_pipe(ialu_reg_shift);
11969 %}
11970 
11971 // Shift Left followed by Shift Right.
11972 // This idiom is used by the compiler for the i2b bytecode etc.
11973 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11974 %{
11975   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
11976   ins_cost(INSN_COST * 2);
11977   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11978   ins_encode %{
11979     int lshift = $lshift_count$$constant &amp; 31;
11980     int rshift = $rshift_count$$constant &amp; 31;
11981     int s = 31 - lshift;
11982     int r = (rshift - lshift) &amp; 31;
11983     __ ubfmw(as_Register($dst$$reg),
11984             as_Register($src$$reg),
11985             r, s);
11986   %}
11987 
11988   ins_pipe(ialu_reg_shift);
11989 %}
11990 // Bitfield extract with shift &amp; mask
11991 
11992 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
11993 %{
11994   match(Set dst (AndI (URShiftI src rshift) mask));
11995   // Make sure we are not going to exceed what ubfxw can do.
11996   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11997 
11998   ins_cost(INSN_COST);
11999   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
12000   ins_encode %{
12001     int rshift = $rshift$$constant &amp; 31;
<a name="33" id="anc33"></a><span class="line-modified">12002     int64_t mask = $mask$$constant;</span>
12003     int width = exact_log2(mask+1);
12004     __ ubfxw(as_Register($dst$$reg),
12005             as_Register($src$$reg), rshift, width);
12006   %}
12007   ins_pipe(ialu_reg_shift);
12008 %}
12009 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12010 %{
12011   match(Set dst (AndL (URShiftL src rshift) mask));
12012   // Make sure we are not going to exceed what ubfx can do.
12013   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12014 
12015   ins_cost(INSN_COST);
12016   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12017   ins_encode %{
12018     int rshift = $rshift$$constant &amp; 63;
<a name="34" id="anc34"></a><span class="line-modified">12019     int64_t mask = $mask$$constant;</span>
12020     int width = exact_log2_long(mask+1);
12021     __ ubfx(as_Register($dst$$reg),
12022             as_Register($src$$reg), rshift, width);
12023   %}
12024   ins_pipe(ialu_reg_shift);
12025 %}
12026 
12027 // We can use ubfx when extending an And with a mask when we know mask
12028 // is positive.  We know that because immI_bitmask guarantees it.
12029 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12030 %{
12031   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12032   // Make sure we are not going to exceed what ubfxw can do.
12033   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12034 
12035   ins_cost(INSN_COST * 2);
12036   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12037   ins_encode %{
12038     int rshift = $rshift$$constant &amp; 31;
<a name="35" id="anc35"></a><span class="line-modified">12039     int64_t mask = $mask$$constant;</span>
12040     int width = exact_log2(mask+1);
12041     __ ubfx(as_Register($dst$$reg),
12042             as_Register($src$$reg), rshift, width);
12043   %}
12044   ins_pipe(ialu_reg_shift);
12045 %}
12046 
12047 // We can use ubfiz when masking by a positive number and then left shifting the result.
12048 // We know that the mask is positive because immI_bitmask guarantees it.
12049 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12050 %{
12051   match(Set dst (LShiftI (AndI src mask) lshift));
12052   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12053 
12054   ins_cost(INSN_COST);
12055   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12056   ins_encode %{
12057     int lshift = $lshift$$constant &amp; 31;
<a name="36" id="anc36"></a><span class="line-modified">12058     int64_t mask = $mask$$constant;</span>
12059     int width = exact_log2(mask+1);
12060     __ ubfizw(as_Register($dst$$reg),
12061           as_Register($src$$reg), lshift, width);
12062   %}
12063   ins_pipe(ialu_reg_shift);
12064 %}
12065 // We can use ubfiz when masking by a positive number and then left shifting the result.
12066 // We know that the mask is positive because immL_bitmask guarantees it.
12067 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12068 %{
12069   match(Set dst (LShiftL (AndL src mask) lshift));
12070   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12071 
12072   ins_cost(INSN_COST);
12073   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12074   ins_encode %{
12075     int lshift = $lshift$$constant &amp; 63;
<a name="37" id="anc37"></a><span class="line-modified">12076     int64_t mask = $mask$$constant;</span>
12077     int width = exact_log2_long(mask+1);
12078     __ ubfiz(as_Register($dst$$reg),
12079           as_Register($src$$reg), lshift, width);
12080   %}
12081   ins_pipe(ialu_reg_shift);
12082 %}
12083 
12084 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12085 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12086 %{
12087   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12088   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12089 
12090   ins_cost(INSN_COST);
12091   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12092   ins_encode %{
12093     int lshift = $lshift$$constant &amp; 63;
<a name="38" id="anc38"></a><span class="line-modified">12094     int64_t mask = $mask$$constant;</span>
12095     int width = exact_log2(mask+1);
12096     __ ubfiz(as_Register($dst$$reg),
12097              as_Register($src$$reg), lshift, width);
12098   %}
12099   ins_pipe(ialu_reg_shift);
12100 %}
12101 
12102 // Rotations
12103 
12104 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12105 %{
12106   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12107   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12108 
12109   ins_cost(INSN_COST);
12110   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12111 
12112   ins_encode %{
12113     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12114             $rshift$$constant &amp; 63);
12115   %}
12116   ins_pipe(ialu_reg_reg_extr);
12117 %}
12118 
12119 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12120 %{
12121   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12122   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12123 
12124   ins_cost(INSN_COST);
12125   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12126 
12127   ins_encode %{
12128     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12129             $rshift$$constant &amp; 31);
12130   %}
12131   ins_pipe(ialu_reg_reg_extr);
12132 %}
12133 
12134 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12135 %{
12136   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12137   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12138 
12139   ins_cost(INSN_COST);
12140   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12141 
12142   ins_encode %{
12143     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12144             $rshift$$constant &amp; 63);
12145   %}
12146   ins_pipe(ialu_reg_reg_extr);
12147 %}
12148 
12149 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12150 %{
12151   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12152   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12153 
12154   ins_cost(INSN_COST);
12155   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12156 
12157   ins_encode %{
12158     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12159             $rshift$$constant &amp; 31);
12160   %}
12161   ins_pipe(ialu_reg_reg_extr);
12162 %}
12163 
12164 
12165 // rol expander
12166 
12167 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12168 %{
12169   effect(DEF dst, USE src, USE shift);
12170 
12171   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12172   ins_cost(INSN_COST * 3);
12173   ins_encode %{
12174     __ subw(rscratch1, zr, as_Register($shift$$reg));
12175     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12176             rscratch1);
12177     %}
12178   ins_pipe(ialu_reg_reg_vshift);
12179 %}
12180 
12181 // rol expander
12182 
12183 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12184 %{
12185   effect(DEF dst, USE src, USE shift);
12186 
12187   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12188   ins_cost(INSN_COST * 3);
12189   ins_encode %{
12190     __ subw(rscratch1, zr, as_Register($shift$$reg));
12191     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12192             rscratch1);
12193     %}
12194   ins_pipe(ialu_reg_reg_vshift);
12195 %}
12196 
12197 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12198 %{
12199   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12200 
12201   expand %{
12202     rolL_rReg(dst, src, shift, cr);
12203   %}
12204 %}
12205 
12206 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12207 %{
12208   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12209 
12210   expand %{
12211     rolL_rReg(dst, src, shift, cr);
12212   %}
12213 %}
12214 
12215 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12216 %{
12217   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12218 
12219   expand %{
12220     rolI_rReg(dst, src, shift, cr);
12221   %}
12222 %}
12223 
12224 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12225 %{
12226   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12227 
12228   expand %{
12229     rolI_rReg(dst, src, shift, cr);
12230   %}
12231 %}
12232 
12233 // ror expander
12234 
12235 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12236 %{
12237   effect(DEF dst, USE src, USE shift);
12238 
12239   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12240   ins_cost(INSN_COST);
12241   ins_encode %{
12242     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12243             as_Register($shift$$reg));
12244     %}
12245   ins_pipe(ialu_reg_reg_vshift);
12246 %}
12247 
12248 // ror expander
12249 
12250 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12251 %{
12252   effect(DEF dst, USE src, USE shift);
12253 
12254   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12255   ins_cost(INSN_COST);
12256   ins_encode %{
12257     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12258             as_Register($shift$$reg));
12259     %}
12260   ins_pipe(ialu_reg_reg_vshift);
12261 %}
12262 
12263 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12264 %{
12265   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12266 
12267   expand %{
12268     rorL_rReg(dst, src, shift, cr);
12269   %}
12270 %}
12271 
12272 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12273 %{
12274   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12275 
12276   expand %{
12277     rorL_rReg(dst, src, shift, cr);
12278   %}
12279 %}
12280 
12281 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12282 %{
12283   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12284 
12285   expand %{
12286     rorI_rReg(dst, src, shift, cr);
12287   %}
12288 %}
12289 
12290 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12291 %{
12292   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12293 
12294   expand %{
12295     rorI_rReg(dst, src, shift, cr);
12296   %}
12297 %}
12298 
12299 // Add/subtract (extended)
12300 
12301 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12302 %{
12303   match(Set dst (AddL src1 (ConvI2L src2)));
12304   ins_cost(INSN_COST);
12305   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12306 
12307    ins_encode %{
12308      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12309             as_Register($src2$$reg), ext::sxtw);
12310    %}
12311   ins_pipe(ialu_reg_reg);
12312 %};
12313 
12314 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12315 %{
12316   match(Set dst (SubL src1 (ConvI2L src2)));
12317   ins_cost(INSN_COST);
12318   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12319 
12320    ins_encode %{
12321      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12322             as_Register($src2$$reg), ext::sxtw);
12323    %}
12324   ins_pipe(ialu_reg_reg);
12325 %};
12326 
12327 
12328 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12329 %{
12330   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12331   ins_cost(INSN_COST);
12332   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12333 
12334    ins_encode %{
12335      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12336             as_Register($src2$$reg), ext::sxth);
12337    %}
12338   ins_pipe(ialu_reg_reg);
12339 %}
12340 
12341 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12342 %{
12343   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12344   ins_cost(INSN_COST);
12345   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12346 
12347    ins_encode %{
12348      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12349             as_Register($src2$$reg), ext::sxtb);
12350    %}
12351   ins_pipe(ialu_reg_reg);
12352 %}
12353 
12354 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12355 %{
12356   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12357   ins_cost(INSN_COST);
12358   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12359 
12360    ins_encode %{
12361      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12362             as_Register($src2$$reg), ext::uxtb);
12363    %}
12364   ins_pipe(ialu_reg_reg);
12365 %}
12366 
12367 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12368 %{
12369   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12370   ins_cost(INSN_COST);
12371   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12372 
12373    ins_encode %{
12374      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12375             as_Register($src2$$reg), ext::sxth);
12376    %}
12377   ins_pipe(ialu_reg_reg);
12378 %}
12379 
12380 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12381 %{
12382   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12383   ins_cost(INSN_COST);
12384   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12385 
12386    ins_encode %{
12387      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12388             as_Register($src2$$reg), ext::sxtw);
12389    %}
12390   ins_pipe(ialu_reg_reg);
12391 %}
12392 
12393 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12394 %{
12395   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12396   ins_cost(INSN_COST);
12397   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12398 
12399    ins_encode %{
12400      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12401             as_Register($src2$$reg), ext::sxtb);
12402    %}
12403   ins_pipe(ialu_reg_reg);
12404 %}
12405 
12406 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12407 %{
12408   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12409   ins_cost(INSN_COST);
12410   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12411 
12412    ins_encode %{
12413      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12414             as_Register($src2$$reg), ext::uxtb);
12415    %}
12416   ins_pipe(ialu_reg_reg);
12417 %}
12418 
12419 
12420 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12421 %{
12422   match(Set dst (AddI src1 (AndI src2 mask)));
12423   ins_cost(INSN_COST);
12424   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12425 
12426    ins_encode %{
12427      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12428             as_Register($src2$$reg), ext::uxtb);
12429    %}
12430   ins_pipe(ialu_reg_reg);
12431 %}
12432 
12433 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12434 %{
12435   match(Set dst (AddI src1 (AndI src2 mask)));
12436   ins_cost(INSN_COST);
12437   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12438 
12439    ins_encode %{
12440      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12441             as_Register($src2$$reg), ext::uxth);
12442    %}
12443   ins_pipe(ialu_reg_reg);
12444 %}
12445 
12446 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12447 %{
12448   match(Set dst (AddL src1 (AndL src2 mask)));
12449   ins_cost(INSN_COST);
12450   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12451 
12452    ins_encode %{
12453      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12454             as_Register($src2$$reg), ext::uxtb);
12455    %}
12456   ins_pipe(ialu_reg_reg);
12457 %}
12458 
12459 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12460 %{
12461   match(Set dst (AddL src1 (AndL src2 mask)));
12462   ins_cost(INSN_COST);
12463   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12464 
12465    ins_encode %{
12466      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12467             as_Register($src2$$reg), ext::uxth);
12468    %}
12469   ins_pipe(ialu_reg_reg);
12470 %}
12471 
12472 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12473 %{
12474   match(Set dst (AddL src1 (AndL src2 mask)));
12475   ins_cost(INSN_COST);
12476   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12477 
12478    ins_encode %{
12479      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12480             as_Register($src2$$reg), ext::uxtw);
12481    %}
12482   ins_pipe(ialu_reg_reg);
12483 %}
12484 
12485 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12486 %{
12487   match(Set dst (SubI src1 (AndI src2 mask)));
12488   ins_cost(INSN_COST);
12489   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12490 
12491    ins_encode %{
12492      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12493             as_Register($src2$$reg), ext::uxtb);
12494    %}
12495   ins_pipe(ialu_reg_reg);
12496 %}
12497 
12498 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12499 %{
12500   match(Set dst (SubI src1 (AndI src2 mask)));
12501   ins_cost(INSN_COST);
12502   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12503 
12504    ins_encode %{
12505      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12506             as_Register($src2$$reg), ext::uxth);
12507    %}
12508   ins_pipe(ialu_reg_reg);
12509 %}
12510 
12511 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12512 %{
12513   match(Set dst (SubL src1 (AndL src2 mask)));
12514   ins_cost(INSN_COST);
12515   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12516 
12517    ins_encode %{
12518      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12519             as_Register($src2$$reg), ext::uxtb);
12520    %}
12521   ins_pipe(ialu_reg_reg);
12522 %}
12523 
12524 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12525 %{
12526   match(Set dst (SubL src1 (AndL src2 mask)));
12527   ins_cost(INSN_COST);
12528   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12529 
12530    ins_encode %{
12531      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12532             as_Register($src2$$reg), ext::uxth);
12533    %}
12534   ins_pipe(ialu_reg_reg);
12535 %}
12536 
12537 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12538 %{
12539   match(Set dst (SubL src1 (AndL src2 mask)));
12540   ins_cost(INSN_COST);
12541   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12542 
12543    ins_encode %{
12544      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12545             as_Register($src2$$reg), ext::uxtw);
12546    %}
12547   ins_pipe(ialu_reg_reg);
12548 %}
12549 
12550 
12551 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12552 %{
12553   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12554   ins_cost(1.9 * INSN_COST);
12555   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12556 
12557    ins_encode %{
12558      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12559             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12560    %}
12561   ins_pipe(ialu_reg_reg_shift);
12562 %}
12563 
12564 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12565 %{
12566   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12567   ins_cost(1.9 * INSN_COST);
12568   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12569 
12570    ins_encode %{
12571      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12572             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12573    %}
12574   ins_pipe(ialu_reg_reg_shift);
12575 %}
12576 
12577 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12578 %{
12579   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12580   ins_cost(1.9 * INSN_COST);
12581   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12582 
12583    ins_encode %{
12584      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12585             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12586    %}
12587   ins_pipe(ialu_reg_reg_shift);
12588 %}
12589 
12590 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12591 %{
12592   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12593   ins_cost(1.9 * INSN_COST);
12594   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12595 
12596    ins_encode %{
12597      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12598             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12599    %}
12600   ins_pipe(ialu_reg_reg_shift);
12601 %}
12602 
12603 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12604 %{
12605   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12606   ins_cost(1.9 * INSN_COST);
12607   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12608 
12609    ins_encode %{
12610      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12611             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12612    %}
12613   ins_pipe(ialu_reg_reg_shift);
12614 %}
12615 
12616 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12617 %{
12618   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12619   ins_cost(1.9 * INSN_COST);
12620   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12621 
12622    ins_encode %{
12623      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12624             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12625    %}
12626   ins_pipe(ialu_reg_reg_shift);
12627 %}
12628 
12629 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12630 %{
12631   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12632   ins_cost(1.9 * INSN_COST);
12633   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12634 
12635    ins_encode %{
12636      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12637             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12638    %}
12639   ins_pipe(ialu_reg_reg_shift);
12640 %}
12641 
12642 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12643 %{
12644   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12645   ins_cost(1.9 * INSN_COST);
12646   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12647 
12648    ins_encode %{
12649      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12650             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12651    %}
12652   ins_pipe(ialu_reg_reg_shift);
12653 %}
12654 
12655 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12656 %{
12657   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12658   ins_cost(1.9 * INSN_COST);
12659   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12660 
12661    ins_encode %{
12662      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12663             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12664    %}
12665   ins_pipe(ialu_reg_reg_shift);
12666 %}
12667 
12668 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12669 %{
12670   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12671   ins_cost(1.9 * INSN_COST);
12672   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12673 
12674    ins_encode %{
12675      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12676             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12677    %}
12678   ins_pipe(ialu_reg_reg_shift);
12679 %}
12680 
12681 
12682 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12683 %{
12684   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12685   ins_cost(1.9 * INSN_COST);
12686   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12687 
12688    ins_encode %{
12689      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12690             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12691    %}
12692   ins_pipe(ialu_reg_reg_shift);
12693 %};
12694 
12695 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12696 %{
12697   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12698   ins_cost(1.9 * INSN_COST);
12699   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12700 
12701    ins_encode %{
12702      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12703             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12704    %}
12705   ins_pipe(ialu_reg_reg_shift);
12706 %};
12707 
12708 
12709 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12710 %{
12711   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12712   ins_cost(1.9 * INSN_COST);
12713   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12714 
12715    ins_encode %{
12716      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12717             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12718    %}
12719   ins_pipe(ialu_reg_reg_shift);
12720 %}
12721 
12722 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12723 %{
12724   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12725   ins_cost(1.9 * INSN_COST);
12726   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12727 
12728    ins_encode %{
12729      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12730             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12731    %}
12732   ins_pipe(ialu_reg_reg_shift);
12733 %}
12734 
12735 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12736 %{
12737   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12738   ins_cost(1.9 * INSN_COST);
12739   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12740 
12741    ins_encode %{
12742      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12743             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12744    %}
12745   ins_pipe(ialu_reg_reg_shift);
12746 %}
12747 
12748 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12749 %{
12750   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12751   ins_cost(1.9 * INSN_COST);
12752   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12753 
12754    ins_encode %{
12755      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12756             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12757    %}
12758   ins_pipe(ialu_reg_reg_shift);
12759 %}
12760 
12761 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12762 %{
12763   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12764   ins_cost(1.9 * INSN_COST);
12765   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12766 
12767    ins_encode %{
12768      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12769             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12770    %}
12771   ins_pipe(ialu_reg_reg_shift);
12772 %}
12773 
12774 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12775 %{
12776   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12777   ins_cost(1.9 * INSN_COST);
12778   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12779 
12780    ins_encode %{
12781      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12782             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12783    %}
12784   ins_pipe(ialu_reg_reg_shift);
12785 %}
12786 
12787 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12788 %{
12789   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12790   ins_cost(1.9 * INSN_COST);
12791   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12792 
12793    ins_encode %{
12794      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12795             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12796    %}
12797   ins_pipe(ialu_reg_reg_shift);
12798 %}
12799 
12800 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12801 %{
12802   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12803   ins_cost(1.9 * INSN_COST);
12804   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12805 
12806    ins_encode %{
12807      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12808             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12809    %}
12810   ins_pipe(ialu_reg_reg_shift);
12811 %}
12812 
12813 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12814 %{
12815   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12816   ins_cost(1.9 * INSN_COST);
12817   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12818 
12819    ins_encode %{
12820      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12821             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12822    %}
12823   ins_pipe(ialu_reg_reg_shift);
12824 %}
12825 
12826 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12827 %{
12828   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12829   ins_cost(1.9 * INSN_COST);
12830   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12831 
12832    ins_encode %{
12833      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12834             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12835    %}
12836   ins_pipe(ialu_reg_reg_shift);
12837 %}
12838 // END This section of the file is automatically generated. Do not edit --------------
12839 
12840 // ============================================================================
12841 // Floating Point Arithmetic Instructions
12842 
12843 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12844   match(Set dst (AddF src1 src2));
12845 
12846   ins_cost(INSN_COST * 5);
12847   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12848 
12849   ins_encode %{
12850     __ fadds(as_FloatRegister($dst$$reg),
12851              as_FloatRegister($src1$$reg),
12852              as_FloatRegister($src2$$reg));
12853   %}
12854 
12855   ins_pipe(fp_dop_reg_reg_s);
12856 %}
12857 
12858 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12859   match(Set dst (AddD src1 src2));
12860 
12861   ins_cost(INSN_COST * 5);
12862   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12863 
12864   ins_encode %{
12865     __ faddd(as_FloatRegister($dst$$reg),
12866              as_FloatRegister($src1$$reg),
12867              as_FloatRegister($src2$$reg));
12868   %}
12869 
12870   ins_pipe(fp_dop_reg_reg_d);
12871 %}
12872 
12873 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12874   match(Set dst (SubF src1 src2));
12875 
12876   ins_cost(INSN_COST * 5);
12877   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12878 
12879   ins_encode %{
12880     __ fsubs(as_FloatRegister($dst$$reg),
12881              as_FloatRegister($src1$$reg),
12882              as_FloatRegister($src2$$reg));
12883   %}
12884 
12885   ins_pipe(fp_dop_reg_reg_s);
12886 %}
12887 
12888 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12889   match(Set dst (SubD src1 src2));
12890 
12891   ins_cost(INSN_COST * 5);
12892   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12893 
12894   ins_encode %{
12895     __ fsubd(as_FloatRegister($dst$$reg),
12896              as_FloatRegister($src1$$reg),
12897              as_FloatRegister($src2$$reg));
12898   %}
12899 
12900   ins_pipe(fp_dop_reg_reg_d);
12901 %}
12902 
12903 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12904   match(Set dst (MulF src1 src2));
12905 
12906   ins_cost(INSN_COST * 6);
12907   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12908 
12909   ins_encode %{
12910     __ fmuls(as_FloatRegister($dst$$reg),
12911              as_FloatRegister($src1$$reg),
12912              as_FloatRegister($src2$$reg));
12913   %}
12914 
12915   ins_pipe(fp_dop_reg_reg_s);
12916 %}
12917 
12918 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12919   match(Set dst (MulD src1 src2));
12920 
12921   ins_cost(INSN_COST * 6);
12922   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12923 
12924   ins_encode %{
12925     __ fmuld(as_FloatRegister($dst$$reg),
12926              as_FloatRegister($src1$$reg),
12927              as_FloatRegister($src2$$reg));
12928   %}
12929 
12930   ins_pipe(fp_dop_reg_reg_d);
12931 %}
12932 
12933 // src1 * src2 + src3
12934 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12935   predicate(UseFMA);
12936   match(Set dst (FmaF src3 (Binary src1 src2)));
12937 
12938   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12939 
12940   ins_encode %{
12941     __ fmadds(as_FloatRegister($dst$$reg),
12942              as_FloatRegister($src1$$reg),
12943              as_FloatRegister($src2$$reg),
12944              as_FloatRegister($src3$$reg));
12945   %}
12946 
12947   ins_pipe(pipe_class_default);
12948 %}
12949 
12950 // src1 * src2 + src3
12951 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12952   predicate(UseFMA);
12953   match(Set dst (FmaD src3 (Binary src1 src2)));
12954 
12955   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12956 
12957   ins_encode %{
12958     __ fmaddd(as_FloatRegister($dst$$reg),
12959              as_FloatRegister($src1$$reg),
12960              as_FloatRegister($src2$$reg),
12961              as_FloatRegister($src3$$reg));
12962   %}
12963 
12964   ins_pipe(pipe_class_default);
12965 %}
12966 
12967 // -src1 * src2 + src3
12968 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12969   predicate(UseFMA);
12970   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
12971   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
12972 
12973   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
12974 
12975   ins_encode %{
12976     __ fmsubs(as_FloatRegister($dst$$reg),
12977               as_FloatRegister($src1$$reg),
12978               as_FloatRegister($src2$$reg),
12979               as_FloatRegister($src3$$reg));
12980   %}
12981 
12982   ins_pipe(pipe_class_default);
12983 %}
12984 
12985 // -src1 * src2 + src3
12986 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12987   predicate(UseFMA);
12988   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
12989   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
12990 
12991   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
12992 
12993   ins_encode %{
12994     __ fmsubd(as_FloatRegister($dst$$reg),
12995               as_FloatRegister($src1$$reg),
12996               as_FloatRegister($src2$$reg),
12997               as_FloatRegister($src3$$reg));
12998   %}
12999 
13000   ins_pipe(pipe_class_default);
13001 %}
13002 
13003 // -src1 * src2 - src3
13004 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13005   predicate(UseFMA);
13006   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13007   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13008 
13009   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13010 
13011   ins_encode %{
13012     __ fnmadds(as_FloatRegister($dst$$reg),
13013                as_FloatRegister($src1$$reg),
13014                as_FloatRegister($src2$$reg),
13015                as_FloatRegister($src3$$reg));
13016   %}
13017 
13018   ins_pipe(pipe_class_default);
13019 %}
13020 
13021 // -src1 * src2 - src3
13022 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13023   predicate(UseFMA);
13024   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13025   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13026 
13027   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13028 
13029   ins_encode %{
13030     __ fnmaddd(as_FloatRegister($dst$$reg),
13031                as_FloatRegister($src1$$reg),
13032                as_FloatRegister($src2$$reg),
13033                as_FloatRegister($src3$$reg));
13034   %}
13035 
13036   ins_pipe(pipe_class_default);
13037 %}
13038 
13039 // src1 * src2 - src3
13040 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13041   predicate(UseFMA);
13042   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13043 
13044   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13045 
13046   ins_encode %{
13047     __ fnmsubs(as_FloatRegister($dst$$reg),
13048                as_FloatRegister($src1$$reg),
13049                as_FloatRegister($src2$$reg),
13050                as_FloatRegister($src3$$reg));
13051   %}
13052 
13053   ins_pipe(pipe_class_default);
13054 %}
13055 
13056 // src1 * src2 - src3
13057 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13058   predicate(UseFMA);
13059   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13060 
13061   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13062 
13063   ins_encode %{
13064   // n.b. insn name should be fnmsubd
13065     __ fnmsub(as_FloatRegister($dst$$reg),
13066               as_FloatRegister($src1$$reg),
13067               as_FloatRegister($src2$$reg),
13068               as_FloatRegister($src3$$reg));
13069   %}
13070 
13071   ins_pipe(pipe_class_default);
13072 %}
13073 
13074 
13075 // Math.max(FF)F
13076 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13077   match(Set dst (MaxF src1 src2));
13078 
13079   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13080   ins_encode %{
13081     __ fmaxs(as_FloatRegister($dst$$reg),
13082              as_FloatRegister($src1$$reg),
13083              as_FloatRegister($src2$$reg));
13084   %}
13085 
13086   ins_pipe(fp_dop_reg_reg_s);
13087 %}
13088 
13089 // Math.min(FF)F
13090 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13091   match(Set dst (MinF src1 src2));
13092 
13093   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13094   ins_encode %{
13095     __ fmins(as_FloatRegister($dst$$reg),
13096              as_FloatRegister($src1$$reg),
13097              as_FloatRegister($src2$$reg));
13098   %}
13099 
13100   ins_pipe(fp_dop_reg_reg_s);
13101 %}
13102 
13103 // Math.max(DD)D
13104 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13105   match(Set dst (MaxD src1 src2));
13106 
13107   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13108   ins_encode %{
13109     __ fmaxd(as_FloatRegister($dst$$reg),
13110              as_FloatRegister($src1$$reg),
13111              as_FloatRegister($src2$$reg));
13112   %}
13113 
13114   ins_pipe(fp_dop_reg_reg_d);
13115 %}
13116 
13117 // Math.min(DD)D
13118 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13119   match(Set dst (MinD src1 src2));
13120 
13121   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13122   ins_encode %{
13123     __ fmind(as_FloatRegister($dst$$reg),
13124              as_FloatRegister($src1$$reg),
13125              as_FloatRegister($src2$$reg));
13126   %}
13127 
13128   ins_pipe(fp_dop_reg_reg_d);
13129 %}
13130 
13131 
13132 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13133   match(Set dst (DivF src1  src2));
13134 
13135   ins_cost(INSN_COST * 18);
13136   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13137 
13138   ins_encode %{
13139     __ fdivs(as_FloatRegister($dst$$reg),
13140              as_FloatRegister($src1$$reg),
13141              as_FloatRegister($src2$$reg));
13142   %}
13143 
13144   ins_pipe(fp_div_s);
13145 %}
13146 
13147 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13148   match(Set dst (DivD src1  src2));
13149 
13150   ins_cost(INSN_COST * 32);
13151   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13152 
13153   ins_encode %{
13154     __ fdivd(as_FloatRegister($dst$$reg),
13155              as_FloatRegister($src1$$reg),
13156              as_FloatRegister($src2$$reg));
13157   %}
13158 
13159   ins_pipe(fp_div_d);
13160 %}
13161 
13162 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13163   match(Set dst (NegF src));
13164 
13165   ins_cost(INSN_COST * 3);
13166   format %{ &quot;fneg   $dst, $src&quot; %}
13167 
13168   ins_encode %{
13169     __ fnegs(as_FloatRegister($dst$$reg),
13170              as_FloatRegister($src$$reg));
13171   %}
13172 
13173   ins_pipe(fp_uop_s);
13174 %}
13175 
13176 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13177   match(Set dst (NegD src));
13178 
13179   ins_cost(INSN_COST * 3);
13180   format %{ &quot;fnegd   $dst, $src&quot; %}
13181 
13182   ins_encode %{
13183     __ fnegd(as_FloatRegister($dst$$reg),
13184              as_FloatRegister($src$$reg));
13185   %}
13186 
13187   ins_pipe(fp_uop_d);
13188 %}
13189 
13190 instruct absF_reg(vRegF dst, vRegF src) %{
13191   match(Set dst (AbsF src));
13192 
13193   ins_cost(INSN_COST * 3);
13194   format %{ &quot;fabss   $dst, $src&quot; %}
13195   ins_encode %{
13196     __ fabss(as_FloatRegister($dst$$reg),
13197              as_FloatRegister($src$$reg));
13198   %}
13199 
13200   ins_pipe(fp_uop_s);
13201 %}
13202 
13203 instruct absD_reg(vRegD dst, vRegD src) %{
13204   match(Set dst (AbsD src));
13205 
13206   ins_cost(INSN_COST * 3);
13207   format %{ &quot;fabsd   $dst, $src&quot; %}
13208   ins_encode %{
13209     __ fabsd(as_FloatRegister($dst$$reg),
13210              as_FloatRegister($src$$reg));
13211   %}
13212 
13213   ins_pipe(fp_uop_d);
13214 %}
13215 
13216 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13217   match(Set dst (SqrtD src));
13218 
13219   ins_cost(INSN_COST * 50);
13220   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13221   ins_encode %{
13222     __ fsqrtd(as_FloatRegister($dst$$reg),
13223              as_FloatRegister($src$$reg));
13224   %}
13225 
13226   ins_pipe(fp_div_s);
13227 %}
13228 
13229 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13230   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
13231 
13232   ins_cost(INSN_COST * 50);
13233   format %{ &quot;fsqrts  $dst, $src&quot; %}
13234   ins_encode %{
13235     __ fsqrts(as_FloatRegister($dst$$reg),
13236              as_FloatRegister($src$$reg));
13237   %}
13238 
13239   ins_pipe(fp_div_d);
13240 %}
13241 
13242 // Math.rint, floor, ceil
13243 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13244   match(Set dst (RoundDoubleMode src rmode));
13245   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13246   ins_encode %{
13247     switch ($rmode$$constant) {
13248       case RoundDoubleModeNode::rmode_rint:
13249         __ frintnd(as_FloatRegister($dst$$reg),
13250                    as_FloatRegister($src$$reg));
13251         break;
13252       case RoundDoubleModeNode::rmode_floor:
13253         __ frintmd(as_FloatRegister($dst$$reg),
13254                    as_FloatRegister($src$$reg));
13255         break;
13256       case RoundDoubleModeNode::rmode_ceil:
13257         __ frintpd(as_FloatRegister($dst$$reg),
13258                    as_FloatRegister($src$$reg));
13259         break;
13260     }
13261   %}
13262   ins_pipe(fp_uop_d);
13263 %}
13264 
13265 // ============================================================================
13266 // Logical Instructions
13267 
13268 // Integer Logical Instructions
13269 
13270 // And Instructions
13271 
13272 
13273 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13274   match(Set dst (AndI src1 src2));
13275 
13276   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13277 
13278   ins_cost(INSN_COST);
13279   ins_encode %{
13280     __ andw(as_Register($dst$$reg),
13281             as_Register($src1$$reg),
13282             as_Register($src2$$reg));
13283   %}
13284 
13285   ins_pipe(ialu_reg_reg);
13286 %}
13287 
13288 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13289   match(Set dst (AndI src1 src2));
13290 
13291   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13292 
13293   ins_cost(INSN_COST);
13294   ins_encode %{
13295     __ andw(as_Register($dst$$reg),
13296             as_Register($src1$$reg),
<a name="39" id="anc39"></a><span class="line-modified">13297             (uint64_t)($src2$$constant));</span>
13298   %}
13299 
13300   ins_pipe(ialu_reg_imm);
13301 %}
13302 
13303 // Or Instructions
13304 
13305 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13306   match(Set dst (OrI src1 src2));
13307 
13308   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13309 
13310   ins_cost(INSN_COST);
13311   ins_encode %{
13312     __ orrw(as_Register($dst$$reg),
13313             as_Register($src1$$reg),
13314             as_Register($src2$$reg));
13315   %}
13316 
13317   ins_pipe(ialu_reg_reg);
13318 %}
13319 
13320 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13321   match(Set dst (OrI src1 src2));
13322 
13323   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13324 
13325   ins_cost(INSN_COST);
13326   ins_encode %{
13327     __ orrw(as_Register($dst$$reg),
13328             as_Register($src1$$reg),
<a name="40" id="anc40"></a><span class="line-modified">13329             (uint64_t)($src2$$constant));</span>
13330   %}
13331 
13332   ins_pipe(ialu_reg_imm);
13333 %}
13334 
13335 // Xor Instructions
13336 
13337 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13338   match(Set dst (XorI src1 src2));
13339 
13340   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13341 
13342   ins_cost(INSN_COST);
13343   ins_encode %{
13344     __ eorw(as_Register($dst$$reg),
13345             as_Register($src1$$reg),
13346             as_Register($src2$$reg));
13347   %}
13348 
13349   ins_pipe(ialu_reg_reg);
13350 %}
13351 
13352 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13353   match(Set dst (XorI src1 src2));
13354 
13355   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13356 
13357   ins_cost(INSN_COST);
13358   ins_encode %{
13359     __ eorw(as_Register($dst$$reg),
13360             as_Register($src1$$reg),
<a name="41" id="anc41"></a><span class="line-modified">13361             (uint64_t)($src2$$constant));</span>
13362   %}
13363 
13364   ins_pipe(ialu_reg_imm);
13365 %}
13366 
13367 // Long Logical Instructions
13368 // TODO
13369 
13370 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13371   match(Set dst (AndL src1 src2));
13372 
13373   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13374 
13375   ins_cost(INSN_COST);
13376   ins_encode %{
13377     __ andr(as_Register($dst$$reg),
13378             as_Register($src1$$reg),
13379             as_Register($src2$$reg));
13380   %}
13381 
13382   ins_pipe(ialu_reg_reg);
13383 %}
13384 
13385 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13386   match(Set dst (AndL src1 src2));
13387 
13388   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13389 
13390   ins_cost(INSN_COST);
13391   ins_encode %{
13392     __ andr(as_Register($dst$$reg),
13393             as_Register($src1$$reg),
<a name="42" id="anc42"></a><span class="line-modified">13394             (uint64_t)($src2$$constant));</span>
13395   %}
13396 
13397   ins_pipe(ialu_reg_imm);
13398 %}
13399 
13400 // Or Instructions
13401 
13402 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13403   match(Set dst (OrL src1 src2));
13404 
13405   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13406 
13407   ins_cost(INSN_COST);
13408   ins_encode %{
13409     __ orr(as_Register($dst$$reg),
13410            as_Register($src1$$reg),
13411            as_Register($src2$$reg));
13412   %}
13413 
13414   ins_pipe(ialu_reg_reg);
13415 %}
13416 
13417 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13418   match(Set dst (OrL src1 src2));
13419 
13420   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13421 
13422   ins_cost(INSN_COST);
13423   ins_encode %{
13424     __ orr(as_Register($dst$$reg),
13425            as_Register($src1$$reg),
<a name="43" id="anc43"></a><span class="line-modified">13426            (uint64_t)($src2$$constant));</span>
13427   %}
13428 
13429   ins_pipe(ialu_reg_imm);
13430 %}
13431 
13432 // Xor Instructions
13433 
13434 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13435   match(Set dst (XorL src1 src2));
13436 
13437   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13438 
13439   ins_cost(INSN_COST);
13440   ins_encode %{
13441     __ eor(as_Register($dst$$reg),
13442            as_Register($src1$$reg),
13443            as_Register($src2$$reg));
13444   %}
13445 
13446   ins_pipe(ialu_reg_reg);
13447 %}
13448 
13449 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13450   match(Set dst (XorL src1 src2));
13451 
13452   ins_cost(INSN_COST);
13453   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13454 
13455   ins_encode %{
13456     __ eor(as_Register($dst$$reg),
13457            as_Register($src1$$reg),
<a name="44" id="anc44"></a><span class="line-modified">13458            (uint64_t)($src2$$constant));</span>
13459   %}
13460 
13461   ins_pipe(ialu_reg_imm);
13462 %}
13463 
13464 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13465 %{
13466   match(Set dst (ConvI2L src));
13467 
13468   ins_cost(INSN_COST);
13469   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13470   ins_encode %{
13471     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13472   %}
13473   ins_pipe(ialu_reg_shift);
13474 %}
13475 
13476 // this pattern occurs in bigmath arithmetic
13477 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13478 %{
13479   match(Set dst (AndL (ConvI2L src) mask));
13480 
13481   ins_cost(INSN_COST);
13482   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13483   ins_encode %{
13484     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13485   %}
13486 
13487   ins_pipe(ialu_reg_shift);
13488 %}
13489 
13490 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13491   match(Set dst (ConvL2I src));
13492 
13493   ins_cost(INSN_COST);
13494   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13495 
13496   ins_encode %{
13497     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13498   %}
13499 
13500   ins_pipe(ialu_reg);
13501 %}
13502 
13503 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13504 %{
13505   match(Set dst (Conv2B src));
13506   effect(KILL cr);
13507 
13508   format %{
13509     &quot;cmpw $src, zr\n\t&quot;
13510     &quot;cset $dst, ne&quot;
13511   %}
13512 
13513   ins_encode %{
13514     __ cmpw(as_Register($src$$reg), zr);
13515     __ cset(as_Register($dst$$reg), Assembler::NE);
13516   %}
13517 
13518   ins_pipe(ialu_reg);
13519 %}
13520 
13521 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13522 %{
13523   match(Set dst (Conv2B src));
13524   effect(KILL cr);
13525 
13526   format %{
13527     &quot;cmp  $src, zr\n\t&quot;
13528     &quot;cset $dst, ne&quot;
13529   %}
13530 
13531   ins_encode %{
13532     __ cmp(as_Register($src$$reg), zr);
13533     __ cset(as_Register($dst$$reg), Assembler::NE);
13534   %}
13535 
13536   ins_pipe(ialu_reg);
13537 %}
13538 
13539 instruct convD2F_reg(vRegF dst, vRegD src) %{
13540   match(Set dst (ConvD2F src));
13541 
13542   ins_cost(INSN_COST * 5);
13543   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13544 
13545   ins_encode %{
13546     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13547   %}
13548 
13549   ins_pipe(fp_d2f);
13550 %}
13551 
13552 instruct convF2D_reg(vRegD dst, vRegF src) %{
13553   match(Set dst (ConvF2D src));
13554 
13555   ins_cost(INSN_COST * 5);
13556   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13557 
13558   ins_encode %{
13559     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13560   %}
13561 
13562   ins_pipe(fp_f2d);
13563 %}
13564 
13565 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13566   match(Set dst (ConvF2I src));
13567 
13568   ins_cost(INSN_COST * 5);
13569   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13570 
13571   ins_encode %{
13572     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13573   %}
13574 
13575   ins_pipe(fp_f2i);
13576 %}
13577 
13578 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13579   match(Set dst (ConvF2L src));
13580 
13581   ins_cost(INSN_COST * 5);
13582   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13583 
13584   ins_encode %{
13585     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13586   %}
13587 
13588   ins_pipe(fp_f2l);
13589 %}
13590 
13591 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13592   match(Set dst (ConvI2F src));
13593 
13594   ins_cost(INSN_COST * 5);
13595   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13596 
13597   ins_encode %{
13598     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13599   %}
13600 
13601   ins_pipe(fp_i2f);
13602 %}
13603 
13604 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13605   match(Set dst (ConvL2F src));
13606 
13607   ins_cost(INSN_COST * 5);
13608   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13609 
13610   ins_encode %{
13611     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13612   %}
13613 
13614   ins_pipe(fp_l2f);
13615 %}
13616 
13617 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13618   match(Set dst (ConvD2I src));
13619 
13620   ins_cost(INSN_COST * 5);
13621   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13622 
13623   ins_encode %{
13624     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13625   %}
13626 
13627   ins_pipe(fp_d2i);
13628 %}
13629 
13630 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13631   match(Set dst (ConvD2L src));
13632 
13633   ins_cost(INSN_COST * 5);
13634   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13635 
13636   ins_encode %{
13637     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13638   %}
13639 
13640   ins_pipe(fp_d2l);
13641 %}
13642 
13643 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13644   match(Set dst (ConvI2D src));
13645 
13646   ins_cost(INSN_COST * 5);
13647   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13648 
13649   ins_encode %{
13650     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13651   %}
13652 
13653   ins_pipe(fp_i2d);
13654 %}
13655 
13656 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13657   match(Set dst (ConvL2D src));
13658 
13659   ins_cost(INSN_COST * 5);
13660   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13661 
13662   ins_encode %{
13663     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13664   %}
13665 
13666   ins_pipe(fp_l2d);
13667 %}
13668 
13669 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13670 
13671 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13672 
13673   match(Set dst (MoveF2I src));
13674 
13675   effect(DEF dst, USE src);
13676 
13677   ins_cost(4 * INSN_COST);
13678 
13679   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13680 
13681   ins_encode %{
13682     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13683   %}
13684 
13685   ins_pipe(iload_reg_reg);
13686 
13687 %}
13688 
13689 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13690 
13691   match(Set dst (MoveI2F src));
13692 
13693   effect(DEF dst, USE src);
13694 
13695   ins_cost(4 * INSN_COST);
13696 
13697   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13698 
13699   ins_encode %{
13700     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13701   %}
13702 
13703   ins_pipe(pipe_class_memory);
13704 
13705 %}
13706 
13707 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13708 
13709   match(Set dst (MoveD2L src));
13710 
13711   effect(DEF dst, USE src);
13712 
13713   ins_cost(4 * INSN_COST);
13714 
13715   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13716 
13717   ins_encode %{
13718     __ ldr($dst$$Register, Address(sp, $src$$disp));
13719   %}
13720 
13721   ins_pipe(iload_reg_reg);
13722 
13723 %}
13724 
13725 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13726 
13727   match(Set dst (MoveL2D src));
13728 
13729   effect(DEF dst, USE src);
13730 
13731   ins_cost(4 * INSN_COST);
13732 
13733   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13734 
13735   ins_encode %{
13736     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13737   %}
13738 
13739   ins_pipe(pipe_class_memory);
13740 
13741 %}
13742 
13743 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13744 
13745   match(Set dst (MoveF2I src));
13746 
13747   effect(DEF dst, USE src);
13748 
13749   ins_cost(INSN_COST);
13750 
13751   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13752 
13753   ins_encode %{
13754     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13755   %}
13756 
13757   ins_pipe(pipe_class_memory);
13758 
13759 %}
13760 
13761 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13762 
13763   match(Set dst (MoveI2F src));
13764 
13765   effect(DEF dst, USE src);
13766 
13767   ins_cost(INSN_COST);
13768 
13769   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13770 
13771   ins_encode %{
13772     __ strw($src$$Register, Address(sp, $dst$$disp));
13773   %}
13774 
13775   ins_pipe(istore_reg_reg);
13776 
13777 %}
13778 
13779 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13780 
13781   match(Set dst (MoveD2L src));
13782 
13783   effect(DEF dst, USE src);
13784 
13785   ins_cost(INSN_COST);
13786 
13787   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13788 
13789   ins_encode %{
13790     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13791   %}
13792 
13793   ins_pipe(pipe_class_memory);
13794 
13795 %}
13796 
13797 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13798 
13799   match(Set dst (MoveL2D src));
13800 
13801   effect(DEF dst, USE src);
13802 
13803   ins_cost(INSN_COST);
13804 
13805   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13806 
13807   ins_encode %{
13808     __ str($src$$Register, Address(sp, $dst$$disp));
13809   %}
13810 
13811   ins_pipe(istore_reg_reg);
13812 
13813 %}
13814 
13815 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13816 
13817   match(Set dst (MoveF2I src));
13818 
13819   effect(DEF dst, USE src);
13820 
13821   ins_cost(INSN_COST);
13822 
13823   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13824 
13825   ins_encode %{
13826     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13827   %}
13828 
13829   ins_pipe(fp_f2i);
13830 
13831 %}
13832 
13833 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13834 
13835   match(Set dst (MoveI2F src));
13836 
13837   effect(DEF dst, USE src);
13838 
13839   ins_cost(INSN_COST);
13840 
13841   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13842 
13843   ins_encode %{
13844     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13845   %}
13846 
13847   ins_pipe(fp_i2f);
13848 
13849 %}
13850 
13851 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13852 
13853   match(Set dst (MoveD2L src));
13854 
13855   effect(DEF dst, USE src);
13856 
13857   ins_cost(INSN_COST);
13858 
13859   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13860 
13861   ins_encode %{
13862     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13863   %}
13864 
13865   ins_pipe(fp_d2l);
13866 
13867 %}
13868 
13869 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13870 
13871   match(Set dst (MoveL2D src));
13872 
13873   effect(DEF dst, USE src);
13874 
13875   ins_cost(INSN_COST);
13876 
13877   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13878 
13879   ins_encode %{
13880     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13881   %}
13882 
13883   ins_pipe(fp_l2d);
13884 
13885 %}
13886 
13887 // ============================================================================
13888 // clearing of an array
13889 
13890 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13891 %{
13892   match(Set dummy (ClearArray cnt base));
13893   effect(USE_KILL cnt, USE_KILL base);
13894 
13895   ins_cost(4 * INSN_COST);
13896   format %{ &quot;ClearArray $cnt, $base&quot; %}
13897 
13898   ins_encode %{
13899     __ zero_words($base$$Register, $cnt$$Register);
13900   %}
13901 
13902   ins_pipe(pipe_class_memory);
13903 %}
13904 
13905 instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13906 %{
<a name="45" id="anc45"></a><span class="line-modified">13907   predicate((uint64_t)n-&gt;in(2)-&gt;get_long()</span>
<span class="line-modified">13908             &lt; (uint64_t)(BlockZeroingLowLimit &gt;&gt; LogBytesPerWord));</span>
13909   match(Set dummy (ClearArray cnt base));
13910   effect(USE_KILL base);
13911 
13912   ins_cost(4 * INSN_COST);
13913   format %{ &quot;ClearArray $cnt, $base&quot; %}
13914 
13915   ins_encode %{
<a name="46" id="anc46"></a><span class="line-modified">13916     __ zero_words($base$$Register, (uint64_t)$cnt$$constant);</span>
13917   %}
13918 
13919   ins_pipe(pipe_class_memory);
13920 %}
13921 
13922 // ============================================================================
13923 // Overflow Math Instructions
13924 
13925 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13926 %{
13927   match(Set cr (OverflowAddI op1 op2));
13928 
13929   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13930   ins_cost(INSN_COST);
13931   ins_encode %{
13932     __ cmnw($op1$$Register, $op2$$Register);
13933   %}
13934 
13935   ins_pipe(icmp_reg_reg);
13936 %}
13937 
13938 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13939 %{
13940   match(Set cr (OverflowAddI op1 op2));
13941 
13942   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13943   ins_cost(INSN_COST);
13944   ins_encode %{
13945     __ cmnw($op1$$Register, $op2$$constant);
13946   %}
13947 
13948   ins_pipe(icmp_reg_imm);
13949 %}
13950 
13951 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13952 %{
13953   match(Set cr (OverflowAddL op1 op2));
13954 
<a name="47" id="anc47"></a><span class="line-modified">13955   format %{ &quot;cmn   $op1, $op2\t# overflow check int64_t&quot; %}</span>
13956   ins_cost(INSN_COST);
13957   ins_encode %{
13958     __ cmn($op1$$Register, $op2$$Register);
13959   %}
13960 
13961   ins_pipe(icmp_reg_reg);
13962 %}
13963 
13964 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13965 %{
13966   match(Set cr (OverflowAddL op1 op2));
13967 
<a name="48" id="anc48"></a><span class="line-modified">13968   format %{ &quot;cmn   $op1, $op2\t# overflow check int64_t&quot; %}</span>
13969   ins_cost(INSN_COST);
13970   ins_encode %{
13971     __ cmn($op1$$Register, $op2$$constant);
13972   %}
13973 
13974   ins_pipe(icmp_reg_imm);
13975 %}
13976 
13977 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13978 %{
13979   match(Set cr (OverflowSubI op1 op2));
13980 
13981   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13982   ins_cost(INSN_COST);
13983   ins_encode %{
13984     __ cmpw($op1$$Register, $op2$$Register);
13985   %}
13986 
13987   ins_pipe(icmp_reg_reg);
13988 %}
13989 
13990 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13991 %{
13992   match(Set cr (OverflowSubI op1 op2));
13993 
13994   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13995   ins_cost(INSN_COST);
13996   ins_encode %{
13997     __ cmpw($op1$$Register, $op2$$constant);
13998   %}
13999 
14000   ins_pipe(icmp_reg_imm);
14001 %}
14002 
14003 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14004 %{
14005   match(Set cr (OverflowSubL op1 op2));
14006 
<a name="49" id="anc49"></a><span class="line-modified">14007   format %{ &quot;cmp   $op1, $op2\t# overflow check int64_t&quot; %}</span>
14008   ins_cost(INSN_COST);
14009   ins_encode %{
14010     __ cmp($op1$$Register, $op2$$Register);
14011   %}
14012 
14013   ins_pipe(icmp_reg_reg);
14014 %}
14015 
14016 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14017 %{
14018   match(Set cr (OverflowSubL op1 op2));
14019 
<a name="50" id="anc50"></a><span class="line-modified">14020   format %{ &quot;cmp   $op1, $op2\t# overflow check int64_t&quot; %}</span>
14021   ins_cost(INSN_COST);
14022   ins_encode %{
14023     __ subs(zr, $op1$$Register, $op2$$constant);
14024   %}
14025 
14026   ins_pipe(icmp_reg_imm);
14027 %}
14028 
14029 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14030 %{
14031   match(Set cr (OverflowSubI zero op1));
14032 
14033   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14034   ins_cost(INSN_COST);
14035   ins_encode %{
14036     __ cmpw(zr, $op1$$Register);
14037   %}
14038 
14039   ins_pipe(icmp_reg_imm);
14040 %}
14041 
14042 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14043 %{
14044   match(Set cr (OverflowSubL zero op1));
14045 
<a name="51" id="anc51"></a><span class="line-modified">14046   format %{ &quot;cmp   zr, $op1\t# overflow check int64_t&quot; %}</span>
14047   ins_cost(INSN_COST);
14048   ins_encode %{
14049     __ cmp(zr, $op1$$Register);
14050   %}
14051 
14052   ins_pipe(icmp_reg_imm);
14053 %}
14054 
14055 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14056 %{
14057   match(Set cr (OverflowMulI op1 op2));
14058 
14059   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14060             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14061             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14062             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14063             &quot;cmpw  rscratch1, #1&quot; %}
14064   ins_cost(5 * INSN_COST);
14065   ins_encode %{
14066     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14067     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14068     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14069     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14070     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14071   %}
14072 
14073   ins_pipe(pipe_slow);
14074 %}
14075 
14076 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14077 %{
14078   match(If cmp (OverflowMulI op1 op2));
14079   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14080             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14081   effect(USE labl, KILL cr);
14082 
14083   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14084             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14085             &quot;b$cmp   $labl&quot; %}
14086   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14087   ins_encode %{
14088     Label* L = $labl$$label;
14089     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14090     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14091     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14092     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14093   %}
14094 
14095   ins_pipe(pipe_serial);
14096 %}
14097 
14098 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14099 %{
14100   match(Set cr (OverflowMulL op1 op2));
14101 
<a name="52" id="anc52"></a><span class="line-modified">14102   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check int64_t\n\t&quot;</span>
14103             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14104             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14105             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14106             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14107             &quot;cmpw  rscratch1, #1&quot; %}
14108   ins_cost(6 * INSN_COST);
14109   ins_encode %{
14110     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14111     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14112     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14113     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14114     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14115     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14116   %}
14117 
14118   ins_pipe(pipe_slow);
14119 %}
14120 
14121 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14122 %{
14123   match(If cmp (OverflowMulL op1 op2));
14124   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14125             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14126   effect(USE labl, KILL cr);
14127 
<a name="53" id="anc53"></a><span class="line-modified">14128   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check int64_t\n\t&quot;</span>
14129             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14130             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14131             &quot;b$cmp $labl&quot; %}
14132   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14133   ins_encode %{
14134     Label* L = $labl$$label;
14135     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14136     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14137     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14138     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14139     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14140   %}
14141 
14142   ins_pipe(pipe_serial);
14143 %}
14144 
14145 // ============================================================================
14146 // Compare Instructions
14147 
14148 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14149 %{
14150   match(Set cr (CmpI op1 op2));
14151 
14152   effect(DEF cr, USE op1, USE op2);
14153 
14154   ins_cost(INSN_COST);
14155   format %{ &quot;cmpw  $op1, $op2&quot; %}
14156 
14157   ins_encode(aarch64_enc_cmpw(op1, op2));
14158 
14159   ins_pipe(icmp_reg_reg);
14160 %}
14161 
14162 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14163 %{
14164   match(Set cr (CmpI op1 zero));
14165 
14166   effect(DEF cr, USE op1);
14167 
14168   ins_cost(INSN_COST);
14169   format %{ &quot;cmpw $op1, 0&quot; %}
14170 
14171   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14172 
14173   ins_pipe(icmp_reg_imm);
14174 %}
14175 
14176 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14177 %{
14178   match(Set cr (CmpI op1 op2));
14179 
14180   effect(DEF cr, USE op1);
14181 
14182   ins_cost(INSN_COST);
14183   format %{ &quot;cmpw  $op1, $op2&quot; %}
14184 
14185   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14186 
14187   ins_pipe(icmp_reg_imm);
14188 %}
14189 
14190 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14191 %{
14192   match(Set cr (CmpI op1 op2));
14193 
14194   effect(DEF cr, USE op1);
14195 
14196   ins_cost(INSN_COST * 2);
14197   format %{ &quot;cmpw  $op1, $op2&quot; %}
14198 
14199   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14200 
14201   ins_pipe(icmp_reg_imm);
14202 %}
14203 
14204 // Unsigned compare Instructions; really, same as signed compare
14205 // except it should only be used to feed an If or a CMovI which takes a
14206 // cmpOpU.
14207 
14208 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14209 %{
14210   match(Set cr (CmpU op1 op2));
14211 
14212   effect(DEF cr, USE op1, USE op2);
14213 
14214   ins_cost(INSN_COST);
14215   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14216 
14217   ins_encode(aarch64_enc_cmpw(op1, op2));
14218 
14219   ins_pipe(icmp_reg_reg);
14220 %}
14221 
14222 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14223 %{
14224   match(Set cr (CmpU op1 zero));
14225 
14226   effect(DEF cr, USE op1);
14227 
14228   ins_cost(INSN_COST);
14229   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14230 
14231   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14232 
14233   ins_pipe(icmp_reg_imm);
14234 %}
14235 
14236 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14237 %{
14238   match(Set cr (CmpU op1 op2));
14239 
14240   effect(DEF cr, USE op1);
14241 
14242   ins_cost(INSN_COST);
14243   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14244 
14245   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14246 
14247   ins_pipe(icmp_reg_imm);
14248 %}
14249 
14250 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14251 %{
14252   match(Set cr (CmpU op1 op2));
14253 
14254   effect(DEF cr, USE op1);
14255 
14256   ins_cost(INSN_COST * 2);
14257   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14258 
14259   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14260 
14261   ins_pipe(icmp_reg_imm);
14262 %}
14263 
14264 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14265 %{
14266   match(Set cr (CmpL op1 op2));
14267 
14268   effect(DEF cr, USE op1, USE op2);
14269 
14270   ins_cost(INSN_COST);
14271   format %{ &quot;cmp  $op1, $op2&quot; %}
14272 
14273   ins_encode(aarch64_enc_cmp(op1, op2));
14274 
14275   ins_pipe(icmp_reg_reg);
14276 %}
14277 
14278 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14279 %{
14280   match(Set cr (CmpL op1 zero));
14281 
14282   effect(DEF cr, USE op1);
14283 
14284   ins_cost(INSN_COST);
14285   format %{ &quot;tst  $op1&quot; %}
14286 
14287   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14288 
14289   ins_pipe(icmp_reg_imm);
14290 %}
14291 
14292 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14293 %{
14294   match(Set cr (CmpL op1 op2));
14295 
14296   effect(DEF cr, USE op1);
14297 
14298   ins_cost(INSN_COST);
14299   format %{ &quot;cmp  $op1, $op2&quot; %}
14300 
14301   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14302 
14303   ins_pipe(icmp_reg_imm);
14304 %}
14305 
14306 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14307 %{
14308   match(Set cr (CmpL op1 op2));
14309 
14310   effect(DEF cr, USE op1);
14311 
14312   ins_cost(INSN_COST * 2);
14313   format %{ &quot;cmp  $op1, $op2&quot; %}
14314 
14315   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14316 
14317   ins_pipe(icmp_reg_imm);
14318 %}
14319 
14320 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14321 %{
14322   match(Set cr (CmpUL op1 op2));
14323 
14324   effect(DEF cr, USE op1, USE op2);
14325 
14326   ins_cost(INSN_COST);
14327   format %{ &quot;cmp  $op1, $op2&quot; %}
14328 
14329   ins_encode(aarch64_enc_cmp(op1, op2));
14330 
14331   ins_pipe(icmp_reg_reg);
14332 %}
14333 
14334 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14335 %{
14336   match(Set cr (CmpUL op1 zero));
14337 
14338   effect(DEF cr, USE op1);
14339 
14340   ins_cost(INSN_COST);
14341   format %{ &quot;tst  $op1&quot; %}
14342 
14343   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14344 
14345   ins_pipe(icmp_reg_imm);
14346 %}
14347 
14348 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14349 %{
14350   match(Set cr (CmpUL op1 op2));
14351 
14352   effect(DEF cr, USE op1);
14353 
14354   ins_cost(INSN_COST);
14355   format %{ &quot;cmp  $op1, $op2&quot; %}
14356 
14357   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14358 
14359   ins_pipe(icmp_reg_imm);
14360 %}
14361 
14362 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14363 %{
14364   match(Set cr (CmpUL op1 op2));
14365 
14366   effect(DEF cr, USE op1);
14367 
14368   ins_cost(INSN_COST * 2);
14369   format %{ &quot;cmp  $op1, $op2&quot; %}
14370 
14371   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14372 
14373   ins_pipe(icmp_reg_imm);
14374 %}
14375 
14376 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14377 %{
14378   match(Set cr (CmpP op1 op2));
14379 
14380   effect(DEF cr, USE op1, USE op2);
14381 
14382   ins_cost(INSN_COST);
14383   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14384 
14385   ins_encode(aarch64_enc_cmpp(op1, op2));
14386 
14387   ins_pipe(icmp_reg_reg);
14388 %}
14389 
14390 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14391 %{
14392   match(Set cr (CmpN op1 op2));
14393 
14394   effect(DEF cr, USE op1, USE op2);
14395 
14396   ins_cost(INSN_COST);
14397   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14398 
14399   ins_encode(aarch64_enc_cmpn(op1, op2));
14400 
14401   ins_pipe(icmp_reg_reg);
14402 %}
14403 
14404 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14405 %{
14406   match(Set cr (CmpP op1 zero));
14407 
14408   effect(DEF cr, USE op1, USE zero);
14409 
14410   ins_cost(INSN_COST);
14411   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14412 
14413   ins_encode(aarch64_enc_testp(op1));
14414 
14415   ins_pipe(icmp_reg_imm);
14416 %}
14417 
14418 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14419 %{
14420   match(Set cr (CmpN op1 zero));
14421 
14422   effect(DEF cr, USE op1, USE zero);
14423 
14424   ins_cost(INSN_COST);
14425   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14426 
14427   ins_encode(aarch64_enc_testn(op1));
14428 
14429   ins_pipe(icmp_reg_imm);
14430 %}
14431 
14432 // FP comparisons
14433 //
14434 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14435 // using normal cmpOp. See declaration of rFlagsReg for details.
14436 
14437 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14438 %{
14439   match(Set cr (CmpF src1 src2));
14440 
14441   ins_cost(3 * INSN_COST);
14442   format %{ &quot;fcmps $src1, $src2&quot; %}
14443 
14444   ins_encode %{
14445     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14446   %}
14447 
14448   ins_pipe(pipe_class_compare);
14449 %}
14450 
14451 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14452 %{
14453   match(Set cr (CmpF src1 src2));
14454 
14455   ins_cost(3 * INSN_COST);
14456   format %{ &quot;fcmps $src1, 0.0&quot; %}
14457 
14458   ins_encode %{
14459     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14460   %}
14461 
14462   ins_pipe(pipe_class_compare);
14463 %}
14464 // FROM HERE
14465 
14466 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14467 %{
14468   match(Set cr (CmpD src1 src2));
14469 
14470   ins_cost(3 * INSN_COST);
14471   format %{ &quot;fcmpd $src1, $src2&quot; %}
14472 
14473   ins_encode %{
14474     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14475   %}
14476 
14477   ins_pipe(pipe_class_compare);
14478 %}
14479 
14480 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14481 %{
14482   match(Set cr (CmpD src1 src2));
14483 
14484   ins_cost(3 * INSN_COST);
14485   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14486 
14487   ins_encode %{
14488     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14489   %}
14490 
14491   ins_pipe(pipe_class_compare);
14492 %}
14493 
14494 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14495 %{
14496   match(Set dst (CmpF3 src1 src2));
14497   effect(KILL cr);
14498 
14499   ins_cost(5 * INSN_COST);
14500   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14501             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14502             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14503   %}
14504 
14505   ins_encode %{
14506     Label done;
14507     FloatRegister s1 = as_FloatRegister($src1$$reg);
14508     FloatRegister s2 = as_FloatRegister($src2$$reg);
14509     Register d = as_Register($dst$$reg);
14510     __ fcmps(s1, s2);
14511     // installs 0 if EQ else -1
14512     __ csinvw(d, zr, zr, Assembler::EQ);
14513     // keeps -1 if less or unordered else installs 1
14514     __ csnegw(d, d, d, Assembler::LT);
14515     __ bind(done);
14516   %}
14517 
14518   ins_pipe(pipe_class_default);
14519 
14520 %}
14521 
14522 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14523 %{
14524   match(Set dst (CmpD3 src1 src2));
14525   effect(KILL cr);
14526 
14527   ins_cost(5 * INSN_COST);
14528   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14529             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14530             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14531   %}
14532 
14533   ins_encode %{
14534     Label done;
14535     FloatRegister s1 = as_FloatRegister($src1$$reg);
14536     FloatRegister s2 = as_FloatRegister($src2$$reg);
14537     Register d = as_Register($dst$$reg);
14538     __ fcmpd(s1, s2);
14539     // installs 0 if EQ else -1
14540     __ csinvw(d, zr, zr, Assembler::EQ);
14541     // keeps -1 if less or unordered else installs 1
14542     __ csnegw(d, d, d, Assembler::LT);
14543     __ bind(done);
14544   %}
14545   ins_pipe(pipe_class_default);
14546 
14547 %}
14548 
14549 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14550 %{
14551   match(Set dst (CmpF3 src1 zero));
14552   effect(KILL cr);
14553 
14554   ins_cost(5 * INSN_COST);
14555   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14556             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14557             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14558   %}
14559 
14560   ins_encode %{
14561     Label done;
14562     FloatRegister s1 = as_FloatRegister($src1$$reg);
14563     Register d = as_Register($dst$$reg);
14564     __ fcmps(s1, 0.0);
14565     // installs 0 if EQ else -1
14566     __ csinvw(d, zr, zr, Assembler::EQ);
14567     // keeps -1 if less or unordered else installs 1
14568     __ csnegw(d, d, d, Assembler::LT);
14569     __ bind(done);
14570   %}
14571 
14572   ins_pipe(pipe_class_default);
14573 
14574 %}
14575 
14576 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14577 %{
14578   match(Set dst (CmpD3 src1 zero));
14579   effect(KILL cr);
14580 
14581   ins_cost(5 * INSN_COST);
14582   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14583             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14584             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14585   %}
14586 
14587   ins_encode %{
14588     Label done;
14589     FloatRegister s1 = as_FloatRegister($src1$$reg);
14590     Register d = as_Register($dst$$reg);
14591     __ fcmpd(s1, 0.0);
14592     // installs 0 if EQ else -1
14593     __ csinvw(d, zr, zr, Assembler::EQ);
14594     // keeps -1 if less or unordered else installs 1
14595     __ csnegw(d, d, d, Assembler::LT);
14596     __ bind(done);
14597   %}
14598   ins_pipe(pipe_class_default);
14599 
14600 %}
14601 
14602 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14603 %{
14604   match(Set dst (CmpLTMask p q));
14605   effect(KILL cr);
14606 
14607   ins_cost(3 * INSN_COST);
14608 
14609   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14610             &quot;csetw $dst, lt\n\t&quot;
14611             &quot;subw $dst, zr, $dst&quot;
14612   %}
14613 
14614   ins_encode %{
14615     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14616     __ csetw(as_Register($dst$$reg), Assembler::LT);
14617     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14618   %}
14619 
14620   ins_pipe(ialu_reg_reg);
14621 %}
14622 
14623 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14624 %{
14625   match(Set dst (CmpLTMask src zero));
14626   effect(KILL cr);
14627 
14628   ins_cost(INSN_COST);
14629 
14630   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14631 
14632   ins_encode %{
14633     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14634   %}
14635 
14636   ins_pipe(ialu_reg_shift);
14637 %}
14638 
14639 // ============================================================================
14640 // Max and Min
14641 
14642 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14643 %{
14644   effect( DEF dst, USE src1, USE src2, USE cr );
14645 
14646   ins_cost(INSN_COST * 2);
14647   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14648 
14649   ins_encode %{
14650     __ cselw(as_Register($dst$$reg),
14651              as_Register($src1$$reg),
14652              as_Register($src2$$reg),
14653              Assembler::LT);
14654   %}
14655 
14656   ins_pipe(icond_reg_reg);
14657 %}
14658 
14659 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14660 %{
14661   match(Set dst (MinI src1 src2));
14662   ins_cost(INSN_COST * 3);
14663 
14664   expand %{
14665     rFlagsReg cr;
14666     compI_reg_reg(cr, src1, src2);
14667     cmovI_reg_reg_lt(dst, src1, src2, cr);
14668   %}
14669 
14670 %}
14671 // FROM HERE
14672 
14673 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14674 %{
14675   effect( DEF dst, USE src1, USE src2, USE cr );
14676 
14677   ins_cost(INSN_COST * 2);
14678   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14679 
14680   ins_encode %{
14681     __ cselw(as_Register($dst$$reg),
14682              as_Register($src1$$reg),
14683              as_Register($src2$$reg),
14684              Assembler::GT);
14685   %}
14686 
14687   ins_pipe(icond_reg_reg);
14688 %}
14689 
14690 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14691 %{
14692   match(Set dst (MaxI src1 src2));
14693   ins_cost(INSN_COST * 3);
14694   expand %{
14695     rFlagsReg cr;
14696     compI_reg_reg(cr, src1, src2);
14697     cmovI_reg_reg_gt(dst, src1, src2, cr);
14698   %}
14699 %}
14700 
14701 // ============================================================================
14702 // Branch Instructions
14703 
14704 // Direct Branch.
14705 instruct branch(label lbl)
14706 %{
14707   match(Goto);
14708 
14709   effect(USE lbl);
14710 
14711   ins_cost(BRANCH_COST);
14712   format %{ &quot;b  $lbl&quot; %}
14713 
14714   ins_encode(aarch64_enc_b(lbl));
14715 
14716   ins_pipe(pipe_branch);
14717 %}
14718 
14719 // Conditional Near Branch
14720 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14721 %{
14722   // Same match rule as `branchConFar&#39;.
14723   match(If cmp cr);
14724 
14725   effect(USE lbl);
14726 
14727   ins_cost(BRANCH_COST);
14728   // If set to 1 this indicates that the current instruction is a
14729   // short variant of a long branch. This avoids using this
14730   // instruction in first-pass matching. It will then only be used in
14731   // the `Shorten_branches&#39; pass.
14732   // ins_short_branch(1);
14733   format %{ &quot;b$cmp  $lbl&quot; %}
14734 
14735   ins_encode(aarch64_enc_br_con(cmp, lbl));
14736 
14737   ins_pipe(pipe_branch_cond);
14738 %}
14739 
14740 // Conditional Near Branch Unsigned
14741 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14742 %{
14743   // Same match rule as `branchConFar&#39;.
14744   match(If cmp cr);
14745 
14746   effect(USE lbl);
14747 
14748   ins_cost(BRANCH_COST);
14749   // If set to 1 this indicates that the current instruction is a
14750   // short variant of a long branch. This avoids using this
14751   // instruction in first-pass matching. It will then only be used in
14752   // the `Shorten_branches&#39; pass.
14753   // ins_short_branch(1);
14754   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14755 
14756   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14757 
14758   ins_pipe(pipe_branch_cond);
14759 %}
14760 
14761 // Make use of CBZ and CBNZ.  These instructions, as well as being
14762 // shorter than (cmp; branch), have the additional benefit of not
14763 // killing the flags.
14764 
14765 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14766   match(If cmp (CmpI op1 op2));
14767   effect(USE labl);
14768 
14769   ins_cost(BRANCH_COST);
14770   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14771   ins_encode %{
14772     Label* L = $labl$$label;
14773     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14774     if (cond == Assembler::EQ)
14775       __ cbzw($op1$$Register, *L);
14776     else
14777       __ cbnzw($op1$$Register, *L);
14778   %}
14779   ins_pipe(pipe_cmp_branch);
14780 %}
14781 
14782 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14783   match(If cmp (CmpL op1 op2));
14784   effect(USE labl);
14785 
14786   ins_cost(BRANCH_COST);
14787   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14788   ins_encode %{
14789     Label* L = $labl$$label;
14790     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14791     if (cond == Assembler::EQ)
14792       __ cbz($op1$$Register, *L);
14793     else
14794       __ cbnz($op1$$Register, *L);
14795   %}
14796   ins_pipe(pipe_cmp_branch);
14797 %}
14798 
14799 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14800   match(If cmp (CmpP op1 op2));
14801   effect(USE labl);
14802 
14803   ins_cost(BRANCH_COST);
14804   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14805   ins_encode %{
14806     Label* L = $labl$$label;
14807     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14808     if (cond == Assembler::EQ)
14809       __ cbz($op1$$Register, *L);
14810     else
14811       __ cbnz($op1$$Register, *L);
14812   %}
14813   ins_pipe(pipe_cmp_branch);
14814 %}
14815 
14816 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14817   match(If cmp (CmpN op1 op2));
14818   effect(USE labl);
14819 
14820   ins_cost(BRANCH_COST);
14821   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14822   ins_encode %{
14823     Label* L = $labl$$label;
14824     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14825     if (cond == Assembler::EQ)
14826       __ cbzw($op1$$Register, *L);
14827     else
14828       __ cbnzw($op1$$Register, *L);
14829   %}
14830   ins_pipe(pipe_cmp_branch);
14831 %}
14832 
14833 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14834   match(If cmp (CmpP (DecodeN oop) zero));
14835   effect(USE labl);
14836 
14837   ins_cost(BRANCH_COST);
14838   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14839   ins_encode %{
14840     Label* L = $labl$$label;
14841     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14842     if (cond == Assembler::EQ)
14843       __ cbzw($oop$$Register, *L);
14844     else
14845       __ cbnzw($oop$$Register, *L);
14846   %}
14847   ins_pipe(pipe_cmp_branch);
14848 %}
14849 
14850 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14851   match(If cmp (CmpU op1 op2));
14852   effect(USE labl);
14853 
14854   ins_cost(BRANCH_COST);
14855   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14856   ins_encode %{
14857     Label* L = $labl$$label;
14858     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14859     if (cond == Assembler::EQ || cond == Assembler::LS)
14860       __ cbzw($op1$$Register, *L);
14861     else
14862       __ cbnzw($op1$$Register, *L);
14863   %}
14864   ins_pipe(pipe_cmp_branch);
14865 %}
14866 
14867 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14868   match(If cmp (CmpUL op1 op2));
14869   effect(USE labl);
14870 
14871   ins_cost(BRANCH_COST);
14872   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14873   ins_encode %{
14874     Label* L = $labl$$label;
14875     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14876     if (cond == Assembler::EQ || cond == Assembler::LS)
14877       __ cbz($op1$$Register, *L);
14878     else
14879       __ cbnz($op1$$Register, *L);
14880   %}
14881   ins_pipe(pipe_cmp_branch);
14882 %}
14883 
14884 // Test bit and Branch
14885 
14886 // Patterns for short (&lt; 32KiB) variants
14887 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14888   match(If cmp (CmpL op1 op2));
14889   effect(USE labl);
14890 
14891   ins_cost(BRANCH_COST);
<a name="54" id="anc54"></a><span class="line-modified">14892   format %{ &quot;cb$cmp   $op1, $labl # int64_t&quot; %}</span>
14893   ins_encode %{
14894     Label* L = $labl$$label;
14895     Assembler::Condition cond =
14896       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14897     __ tbr(cond, $op1$$Register, 63, *L);
14898   %}
14899   ins_pipe(pipe_cmp_branch);
14900   ins_short_branch(1);
14901 %}
14902 
14903 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14904   match(If cmp (CmpI op1 op2));
14905   effect(USE labl);
14906 
14907   ins_cost(BRANCH_COST);
14908   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14909   ins_encode %{
14910     Label* L = $labl$$label;
14911     Assembler::Condition cond =
14912       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14913     __ tbr(cond, $op1$$Register, 31, *L);
14914   %}
14915   ins_pipe(pipe_cmp_branch);
14916   ins_short_branch(1);
14917 %}
14918 
14919 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14920   match(If cmp (CmpL (AndL op1 op2) op3));
14921   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14922   effect(USE labl);
14923 
14924   ins_cost(BRANCH_COST);
14925   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14926   ins_encode %{
14927     Label* L = $labl$$label;
14928     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14929     int bit = exact_log2($op2$$constant);
14930     __ tbr(cond, $op1$$Register, bit, *L);
14931   %}
14932   ins_pipe(pipe_cmp_branch);
14933   ins_short_branch(1);
14934 %}
14935 
14936 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14937   match(If cmp (CmpI (AndI op1 op2) op3));
14938   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14939   effect(USE labl);
14940 
14941   ins_cost(BRANCH_COST);
14942   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14943   ins_encode %{
14944     Label* L = $labl$$label;
14945     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14946     int bit = exact_log2($op2$$constant);
14947     __ tbr(cond, $op1$$Register, bit, *L);
14948   %}
14949   ins_pipe(pipe_cmp_branch);
14950   ins_short_branch(1);
14951 %}
14952 
14953 // And far variants
14954 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14955   match(If cmp (CmpL op1 op2));
14956   effect(USE labl);
14957 
14958   ins_cost(BRANCH_COST);
<a name="55" id="anc55"></a><span class="line-modified">14959   format %{ &quot;cb$cmp   $op1, $labl # int64_t&quot; %}</span>
14960   ins_encode %{
14961     Label* L = $labl$$label;
14962     Assembler::Condition cond =
14963       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14964     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14965   %}
14966   ins_pipe(pipe_cmp_branch);
14967 %}
14968 
14969 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14970   match(If cmp (CmpI op1 op2));
14971   effect(USE labl);
14972 
14973   ins_cost(BRANCH_COST);
14974   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14975   ins_encode %{
14976     Label* L = $labl$$label;
14977     Assembler::Condition cond =
14978       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14979     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
14980   %}
14981   ins_pipe(pipe_cmp_branch);
14982 %}
14983 
14984 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14985   match(If cmp (CmpL (AndL op1 op2) op3));
14986   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14987   effect(USE labl);
14988 
14989   ins_cost(BRANCH_COST);
14990   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14991   ins_encode %{
14992     Label* L = $labl$$label;
14993     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14994     int bit = exact_log2($op2$$constant);
14995     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14996   %}
14997   ins_pipe(pipe_cmp_branch);
14998 %}
14999 
15000 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15001   match(If cmp (CmpI (AndI op1 op2) op3));
15002   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15003   effect(USE labl);
15004 
15005   ins_cost(BRANCH_COST);
15006   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15007   ins_encode %{
15008     Label* L = $labl$$label;
15009     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15010     int bit = exact_log2($op2$$constant);
15011     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15012   %}
15013   ins_pipe(pipe_cmp_branch);
15014 %}
15015 
15016 // Test bits
15017 
15018 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15019   match(Set cr (CmpL (AndL op1 op2) op3));
15020   predicate(Assembler::operand_valid_for_logical_immediate
15021             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15022 
15023   ins_cost(INSN_COST);
<a name="56" id="anc56"></a><span class="line-modified">15024   format %{ &quot;tst $op1, $op2 # int64_t&quot; %}</span>
15025   ins_encode %{
15026     __ tst($op1$$Register, $op2$$constant);
15027   %}
15028   ins_pipe(ialu_reg_reg);
15029 %}
15030 
15031 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15032   match(Set cr (CmpI (AndI op1 op2) op3));
15033   predicate(Assembler::operand_valid_for_logical_immediate
15034             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15035 
15036   ins_cost(INSN_COST);
15037   format %{ &quot;tst $op1, $op2 # int&quot; %}
15038   ins_encode %{
15039     __ tstw($op1$$Register, $op2$$constant);
15040   %}
15041   ins_pipe(ialu_reg_reg);
15042 %}
15043 
15044 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15045   match(Set cr (CmpL (AndL op1 op2) op3));
15046 
15047   ins_cost(INSN_COST);
<a name="57" id="anc57"></a><span class="line-modified">15048   format %{ &quot;tst $op1, $op2 # int64_t&quot; %}</span>
15049   ins_encode %{
15050     __ tst($op1$$Register, $op2$$Register);
15051   %}
15052   ins_pipe(ialu_reg_reg);
15053 %}
15054 
15055 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15056   match(Set cr (CmpI (AndI op1 op2) op3));
15057 
15058   ins_cost(INSN_COST);
15059   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15060   ins_encode %{
15061     __ tstw($op1$$Register, $op2$$Register);
15062   %}
15063   ins_pipe(ialu_reg_reg);
15064 %}
15065 
15066 
15067 // Conditional Far Branch
15068 // Conditional Far Branch Unsigned
15069 // TODO: fixme
15070 
15071 // counted loop end branch near
15072 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15073 %{
15074   match(CountedLoopEnd cmp cr);
15075 
15076   effect(USE lbl);
15077 
15078   ins_cost(BRANCH_COST);
15079   // short variant.
15080   // ins_short_branch(1);
15081   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15082 
15083   ins_encode(aarch64_enc_br_con(cmp, lbl));
15084 
15085   ins_pipe(pipe_branch);
15086 %}
15087 
15088 // counted loop end branch near Unsigned
15089 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15090 %{
15091   match(CountedLoopEnd cmp cr);
15092 
15093   effect(USE lbl);
15094 
15095   ins_cost(BRANCH_COST);
15096   // short variant.
15097   // ins_short_branch(1);
15098   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15099 
15100   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15101 
15102   ins_pipe(pipe_branch);
15103 %}
15104 
15105 // counted loop end branch far
15106 // counted loop end branch far unsigned
15107 // TODO: fixme
15108 
15109 // ============================================================================
15110 // inlined locking and unlocking
15111 
15112 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15113 %{
15114   match(Set cr (FastLock object box));
15115   effect(TEMP tmp, TEMP tmp2);
15116 
15117   // TODO
15118   // identify correct cost
15119   ins_cost(5 * INSN_COST);
15120   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15121 
15122   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15123 
15124   ins_pipe(pipe_serial);
15125 %}
15126 
15127 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15128 %{
15129   match(Set cr (FastUnlock object box));
15130   effect(TEMP tmp, TEMP tmp2);
15131 
15132   ins_cost(5 * INSN_COST);
15133   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15134 
15135   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15136 
15137   ins_pipe(pipe_serial);
15138 %}
15139 
15140 
15141 // ============================================================================
15142 // Safepoint Instructions
15143 
15144 // TODO
15145 // provide a near and far version of this code
15146 
15147 instruct safePoint(rFlagsReg cr, iRegP poll)
15148 %{
15149   match(SafePoint poll);
15150   effect(KILL cr);
15151 
15152   format %{
15153     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15154   %}
15155   ins_encode %{
15156     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15157   %}
15158   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15159 %}
15160 
15161 
15162 // ============================================================================
15163 // Procedure Call/Return Instructions
15164 
15165 // Call Java Static Instruction
15166 
15167 instruct CallStaticJavaDirect(method meth)
15168 %{
15169   match(CallStaticJava);
15170 
15171   effect(USE meth);
15172 
15173   ins_cost(CALL_COST);
15174 
15175   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15176 
15177   ins_encode( aarch64_enc_java_static_call(meth),
15178               aarch64_enc_call_epilog );
15179 
15180   ins_pipe(pipe_class_call);
15181 %}
15182 
15183 // TO HERE
15184 
15185 // Call Java Dynamic Instruction
15186 instruct CallDynamicJavaDirect(method meth)
15187 %{
15188   match(CallDynamicJava);
15189 
15190   effect(USE meth);
15191 
15192   ins_cost(CALL_COST);
15193 
15194   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15195 
15196   ins_encode( aarch64_enc_java_dynamic_call(meth),
15197                aarch64_enc_call_epilog );
15198 
15199   ins_pipe(pipe_class_call);
15200 %}
15201 
15202 // Call Runtime Instruction
15203 
15204 instruct CallRuntimeDirect(method meth)
15205 %{
15206   match(CallRuntime);
15207 
15208   effect(USE meth);
15209 
15210   ins_cost(CALL_COST);
15211 
15212   format %{ &quot;CALL, runtime $meth&quot; %}
15213 
15214   ins_encode( aarch64_enc_java_to_runtime(meth) );
15215 
15216   ins_pipe(pipe_class_call);
15217 %}
15218 
15219 // Call Runtime Instruction
15220 
15221 instruct CallLeafDirect(method meth)
15222 %{
15223   match(CallLeaf);
15224 
15225   effect(USE meth);
15226 
15227   ins_cost(CALL_COST);
15228 
15229   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15230 
15231   ins_encode( aarch64_enc_java_to_runtime(meth) );
15232 
15233   ins_pipe(pipe_class_call);
15234 %}
15235 
15236 // Call Runtime Instruction
15237 
15238 instruct CallLeafNoFPDirect(method meth)
15239 %{
15240   match(CallLeafNoFP);
15241 
15242   effect(USE meth);
15243 
15244   ins_cost(CALL_COST);
15245 
15246   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15247 
15248   ins_encode( aarch64_enc_java_to_runtime(meth) );
15249 
15250   ins_pipe(pipe_class_call);
15251 %}
15252 
15253 // Tail Call; Jump from runtime stub to Java code.
15254 // Also known as an &#39;interprocedural jump&#39;.
15255 // Target of jump will eventually return to caller.
15256 // TailJump below removes the return address.
15257 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15258 %{
15259   match(TailCall jump_target method_oop);
15260 
15261   ins_cost(CALL_COST);
15262 
15263   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15264 
15265   ins_encode(aarch64_enc_tail_call(jump_target));
15266 
15267   ins_pipe(pipe_class_call);
15268 %}
15269 
15270 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15271 %{
15272   match(TailJump jump_target ex_oop);
15273 
15274   ins_cost(CALL_COST);
15275 
15276   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15277 
15278   ins_encode(aarch64_enc_tail_jmp(jump_target));
15279 
15280   ins_pipe(pipe_class_call);
15281 %}
15282 
15283 // Create exception oop: created by stack-crawling runtime code.
15284 // Created exception is now available to this handler, and is setup
15285 // just prior to jumping to this handler. No code emitted.
15286 // TODO check
15287 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15288 instruct CreateException(iRegP_R0 ex_oop)
15289 %{
15290   match(Set ex_oop (CreateEx));
15291 
15292   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15293 
15294   size(0);
15295 
15296   ins_encode( /*empty*/ );
15297 
15298   ins_pipe(pipe_class_empty);
15299 %}
15300 
15301 // Rethrow exception: The exception oop will come in the first
15302 // argument position. Then JUMP (not call) to the rethrow stub code.
15303 instruct RethrowException() %{
15304   match(Rethrow);
15305   ins_cost(CALL_COST);
15306 
15307   format %{ &quot;b rethrow_stub&quot; %}
15308 
15309   ins_encode( aarch64_enc_rethrow() );
15310 
15311   ins_pipe(pipe_class_call);
15312 %}
15313 
15314 
15315 // Return Instruction
15316 // epilog node loads ret address into lr as part of frame pop
15317 instruct Ret()
15318 %{
15319   match(Return);
15320 
15321   format %{ &quot;ret\t// return register&quot; %}
15322 
15323   ins_encode( aarch64_enc_ret() );
15324 
15325   ins_pipe(pipe_branch);
15326 %}
15327 
15328 // Die now.
15329 instruct ShouldNotReachHere() %{
15330   match(Halt);
15331 
15332   ins_cost(CALL_COST);
15333   format %{ &quot;ShouldNotReachHere&quot; %}
15334 
15335   ins_encode %{
15336     // +1 so NativeInstruction::is_sigill_zombie_not_entrant() doesn&#39;t
15337     // return true
15338     __ dpcs1(0xdead + 1);
15339   %}
15340 
15341   ins_pipe(pipe_class_default);
15342 %}
15343 
15344 // ============================================================================
15345 // Partial Subtype Check
15346 //
15347 // superklass array for an instance of the superklass.  Set a hidden
15348 // internal cache on a hit (cache is checked with exposed code in
15349 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15350 // encoding ALSO sets flags.
15351 
15352 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15353 %{
15354   match(Set result (PartialSubtypeCheck sub super));
15355   effect(KILL cr, KILL temp);
15356 
15357   ins_cost(1100);  // slightly larger than the next version
15358   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15359 
15360   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15361 
15362   opcode(0x1); // Force zero of result reg on hit
15363 
15364   ins_pipe(pipe_class_memory);
15365 %}
15366 
15367 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15368 %{
15369   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15370   effect(KILL temp, KILL result);
15371 
15372   ins_cost(1100);  // slightly larger than the next version
15373   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15374 
15375   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15376 
15377   opcode(0x0); // Don&#39;t zero result reg on hit
15378 
15379   ins_pipe(pipe_class_memory);
15380 %}
15381 
15382 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15383                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15384 %{
15385   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15386   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15387   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15388 
15389   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15390   ins_encode %{
15391     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15392     __ string_compare($str1$$Register, $str2$$Register,
15393                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15394                       $tmp1$$Register, $tmp2$$Register,
15395                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15396   %}
15397   ins_pipe(pipe_class_memory);
15398 %}
15399 
15400 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15401                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15402 %{
15403   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15404   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15405   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15406 
15407   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15408   ins_encode %{
15409     __ string_compare($str1$$Register, $str2$$Register,
15410                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15411                       $tmp1$$Register, $tmp2$$Register,
15412                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15413   %}
15414   ins_pipe(pipe_class_memory);
15415 %}
15416 
15417 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15418                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15419                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15420 %{
15421   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15422   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15423   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15424          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15425 
15426   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15427   ins_encode %{
15428     __ string_compare($str1$$Register, $str2$$Register,
15429                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15430                       $tmp1$$Register, $tmp2$$Register,
15431                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15432                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15433   %}
15434   ins_pipe(pipe_class_memory);
15435 %}
15436 
15437 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15438                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15439                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15440 %{
15441   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15442   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15443   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15444          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15445 
15446   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15447   ins_encode %{
15448     __ string_compare($str1$$Register, $str2$$Register,
15449                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15450                       $tmp1$$Register, $tmp2$$Register,
15451                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15452                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15453   %}
15454   ins_pipe(pipe_class_memory);
15455 %}
15456 
15457 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15458        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15459        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15460 %{
15461   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15462   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15463   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15464          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15465   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15466 
15467   ins_encode %{
15468     __ string_indexof($str1$$Register, $str2$$Register,
15469                       $cnt1$$Register, $cnt2$$Register,
15470                       $tmp1$$Register, $tmp2$$Register,
15471                       $tmp3$$Register, $tmp4$$Register,
15472                       $tmp5$$Register, $tmp6$$Register,
15473                       -1, $result$$Register, StrIntrinsicNode::UU);
15474   %}
15475   ins_pipe(pipe_class_memory);
15476 %}
15477 
15478 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15479        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15480        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15481 %{
15482   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15483   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15484   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15485          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15486   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15487 
15488   ins_encode %{
15489     __ string_indexof($str1$$Register, $str2$$Register,
15490                       $cnt1$$Register, $cnt2$$Register,
15491                       $tmp1$$Register, $tmp2$$Register,
15492                       $tmp3$$Register, $tmp4$$Register,
15493                       $tmp5$$Register, $tmp6$$Register,
15494                       -1, $result$$Register, StrIntrinsicNode::LL);
15495   %}
15496   ins_pipe(pipe_class_memory);
15497 %}
15498 
15499 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15500        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15501        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15502 %{
15503   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15504   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15505   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15506          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15507   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15508 
15509   ins_encode %{
15510     __ string_indexof($str1$$Register, $str2$$Register,
15511                       $cnt1$$Register, $cnt2$$Register,
15512                       $tmp1$$Register, $tmp2$$Register,
15513                       $tmp3$$Register, $tmp4$$Register,
15514                       $tmp5$$Register, $tmp6$$Register,
15515                       -1, $result$$Register, StrIntrinsicNode::UL);
15516   %}
15517   ins_pipe(pipe_class_memory);
15518 %}
15519 
15520 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15521                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15522                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15523 %{
15524   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15525   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15526   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15527          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15528   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15529 
15530   ins_encode %{
15531     int icnt2 = (int)$int_cnt2$$constant;
15532     __ string_indexof($str1$$Register, $str2$$Register,
15533                       $cnt1$$Register, zr,
15534                       $tmp1$$Register, $tmp2$$Register,
15535                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15536                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15537   %}
15538   ins_pipe(pipe_class_memory);
15539 %}
15540 
15541 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15542                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15543                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15544 %{
15545   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15546   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15547   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15548          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15549   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15550 
15551   ins_encode %{
15552     int icnt2 = (int)$int_cnt2$$constant;
15553     __ string_indexof($str1$$Register, $str2$$Register,
15554                       $cnt1$$Register, zr,
15555                       $tmp1$$Register, $tmp2$$Register,
15556                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15557                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15558   %}
15559   ins_pipe(pipe_class_memory);
15560 %}
15561 
15562 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15563                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15564                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15565 %{
15566   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15567   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15568   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15569          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15570   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15571 
15572   ins_encode %{
15573     int icnt2 = (int)$int_cnt2$$constant;
15574     __ string_indexof($str1$$Register, $str2$$Register,
15575                       $cnt1$$Register, zr,
15576                       $tmp1$$Register, $tmp2$$Register,
15577                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15578                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15579   %}
15580   ins_pipe(pipe_class_memory);
15581 %}
15582 
15583 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15584                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15585                               iRegINoSp tmp3, rFlagsReg cr)
15586 %{
15587   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15588   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15589          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15590 
15591   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15592 
15593   ins_encode %{
15594     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15595                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15596                            $tmp3$$Register);
15597   %}
15598   ins_pipe(pipe_class_memory);
15599 %}
15600 
15601 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15602                         iRegI_R0 result, rFlagsReg cr)
15603 %{
15604   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15605   match(Set result (StrEquals (Binary str1 str2) cnt));
15606   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15607 
15608   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15609   ins_encode %{
15610     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15611     __ string_equals($str1$$Register, $str2$$Register,
15612                      $result$$Register, $cnt$$Register, 1);
15613   %}
15614   ins_pipe(pipe_class_memory);
15615 %}
15616 
15617 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15618                         iRegI_R0 result, rFlagsReg cr)
15619 %{
15620   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15621   match(Set result (StrEquals (Binary str1 str2) cnt));
15622   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15623 
15624   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15625   ins_encode %{
15626     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15627     __ string_equals($str1$$Register, $str2$$Register,
15628                      $result$$Register, $cnt$$Register, 2);
15629   %}
15630   ins_pipe(pipe_class_memory);
15631 %}
15632 
15633 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15634                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15635                        iRegP_R10 tmp, rFlagsReg cr)
15636 %{
15637   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15638   match(Set result (AryEq ary1 ary2));
15639   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15640 
15641   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15642   ins_encode %{
15643     __ arrays_equals($ary1$$Register, $ary2$$Register,
15644                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15645                      $result$$Register, $tmp$$Register, 1);
15646     %}
15647   ins_pipe(pipe_class_memory);
15648 %}
15649 
15650 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15651                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15652                        iRegP_R10 tmp, rFlagsReg cr)
15653 %{
15654   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15655   match(Set result (AryEq ary1 ary2));
15656   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15657 
15658   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15659   ins_encode %{
15660     __ arrays_equals($ary1$$Register, $ary2$$Register,
15661                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15662                      $result$$Register, $tmp$$Register, 2);
15663   %}
15664   ins_pipe(pipe_class_memory);
15665 %}
15666 
15667 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15668 %{
15669   match(Set result (HasNegatives ary1 len));
15670   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15671   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15672   ins_encode %{
15673     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15674   %}
15675   ins_pipe( pipe_slow );
15676 %}
15677 
15678 // fast char[] to byte[] compression
15679 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15680                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15681                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15682                          iRegI_R0 result, rFlagsReg cr)
15683 %{
15684   match(Set result (StrCompressedCopy src (Binary dst len)));
15685   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15686 
15687   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15688   ins_encode %{
15689     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15690                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15691                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15692                            $result$$Register);
15693   %}
15694   ins_pipe( pipe_slow );
15695 %}
15696 
15697 // fast byte[] to char[] inflation
15698 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15699                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15700 %{
15701   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15702   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15703 
15704   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15705   ins_encode %{
15706     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15707                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15708   %}
15709   ins_pipe(pipe_class_memory);
15710 %}
15711 
15712 // encode char[] to byte[] in ISO_8859_1
15713 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15714                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15715                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15716                           iRegI_R0 result, rFlagsReg cr)
15717 %{
15718   match(Set result (EncodeISOArray src (Binary dst len)));
15719   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15720          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15721 
15722   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15723   ins_encode %{
15724     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15725          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15726          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15727   %}
15728   ins_pipe( pipe_class_memory );
15729 %}
15730 
15731 // ============================================================================
15732 // This name is KNOWN by the ADLC and cannot be changed.
15733 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15734 // for this guy.
15735 instruct tlsLoadP(thread_RegP dst)
15736 %{
15737   match(Set dst (ThreadLocal));
15738 
15739   ins_cost(0);
15740 
15741   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15742 
15743   size(0);
15744 
15745   ins_encode( /*empty*/ );
15746 
15747   ins_pipe(pipe_class_empty);
15748 %}
15749 
15750 // ====================VECTOR INSTRUCTIONS=====================================
15751 
15752 // Load vector (32 bits)
15753 instruct loadV4(vecD dst, vmem4 mem)
15754 %{
15755   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15756   match(Set dst (LoadVector mem));
15757   ins_cost(4 * INSN_COST);
15758   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15759   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15760   ins_pipe(vload_reg_mem64);
15761 %}
15762 
15763 // Load vector (64 bits)
15764 instruct loadV8(vecD dst, vmem8 mem)
15765 %{
15766   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15767   match(Set dst (LoadVector mem));
15768   ins_cost(4 * INSN_COST);
15769   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15770   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15771   ins_pipe(vload_reg_mem64);
15772 %}
15773 
15774 // Load Vector (128 bits)
15775 instruct loadV16(vecX dst, vmem16 mem)
15776 %{
15777   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15778   match(Set dst (LoadVector mem));
15779   ins_cost(4 * INSN_COST);
15780   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15781   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15782   ins_pipe(vload_reg_mem128);
15783 %}
15784 
15785 // Store Vector (32 bits)
15786 instruct storeV4(vecD src, vmem4 mem)
15787 %{
15788   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15789   match(Set mem (StoreVector mem src));
15790   ins_cost(4 * INSN_COST);
15791   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15792   ins_encode( aarch64_enc_strvS(src, mem) );
15793   ins_pipe(vstore_reg_mem64);
15794 %}
15795 
15796 // Store Vector (64 bits)
15797 instruct storeV8(vecD src, vmem8 mem)
15798 %{
15799   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15800   match(Set mem (StoreVector mem src));
15801   ins_cost(4 * INSN_COST);
15802   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15803   ins_encode( aarch64_enc_strvD(src, mem) );
15804   ins_pipe(vstore_reg_mem64);
15805 %}
15806 
15807 // Store Vector (128 bits)
15808 instruct storeV16(vecX src, vmem16 mem)
15809 %{
15810   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15811   match(Set mem (StoreVector mem src));
15812   ins_cost(4 * INSN_COST);
15813   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15814   ins_encode( aarch64_enc_strvQ(src, mem) );
15815   ins_pipe(vstore_reg_mem128);
15816 %}
15817 
15818 instruct replicate8B(vecD dst, iRegIorL2I src)
15819 %{
15820   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15821             n-&gt;as_Vector()-&gt;length() == 8);
15822   match(Set dst (ReplicateB src));
15823   ins_cost(INSN_COST);
15824   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15825   ins_encode %{
15826     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15827   %}
15828   ins_pipe(vdup_reg_reg64);
15829 %}
15830 
15831 instruct replicate16B(vecX dst, iRegIorL2I src)
15832 %{
15833   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15834   match(Set dst (ReplicateB src));
15835   ins_cost(INSN_COST);
15836   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15837   ins_encode %{
15838     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15839   %}
15840   ins_pipe(vdup_reg_reg128);
15841 %}
15842 
15843 instruct replicate8B_imm(vecD dst, immI con)
15844 %{
15845   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15846             n-&gt;as_Vector()-&gt;length() == 8);
15847   match(Set dst (ReplicateB con));
15848   ins_cost(INSN_COST);
15849   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15850   ins_encode %{
15851     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15852   %}
15853   ins_pipe(vmovi_reg_imm64);
15854 %}
15855 
15856 instruct replicate16B_imm(vecX dst, immI con)
15857 %{
15858   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15859   match(Set dst (ReplicateB con));
15860   ins_cost(INSN_COST);
15861   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15862   ins_encode %{
15863     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15864   %}
15865   ins_pipe(vmovi_reg_imm128);
15866 %}
15867 
15868 instruct replicate4S(vecD dst, iRegIorL2I src)
15869 %{
15870   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15871             n-&gt;as_Vector()-&gt;length() == 4);
15872   match(Set dst (ReplicateS src));
15873   ins_cost(INSN_COST);
15874   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15875   ins_encode %{
15876     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15877   %}
15878   ins_pipe(vdup_reg_reg64);
15879 %}
15880 
15881 instruct replicate8S(vecX dst, iRegIorL2I src)
15882 %{
15883   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15884   match(Set dst (ReplicateS src));
15885   ins_cost(INSN_COST);
15886   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15887   ins_encode %{
15888     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15889   %}
15890   ins_pipe(vdup_reg_reg128);
15891 %}
15892 
15893 instruct replicate4S_imm(vecD dst, immI con)
15894 %{
15895   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15896             n-&gt;as_Vector()-&gt;length() == 4);
15897   match(Set dst (ReplicateS con));
15898   ins_cost(INSN_COST);
15899   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15900   ins_encode %{
15901     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15902   %}
15903   ins_pipe(vmovi_reg_imm64);
15904 %}
15905 
15906 instruct replicate8S_imm(vecX dst, immI con)
15907 %{
15908   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15909   match(Set dst (ReplicateS con));
15910   ins_cost(INSN_COST);
15911   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15912   ins_encode %{
15913     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15914   %}
15915   ins_pipe(vmovi_reg_imm128);
15916 %}
15917 
15918 instruct replicate2I(vecD dst, iRegIorL2I src)
15919 %{
15920   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15921   match(Set dst (ReplicateI src));
15922   ins_cost(INSN_COST);
15923   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15924   ins_encode %{
15925     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15926   %}
15927   ins_pipe(vdup_reg_reg64);
15928 %}
15929 
15930 instruct replicate4I(vecX dst, iRegIorL2I src)
15931 %{
15932   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15933   match(Set dst (ReplicateI src));
15934   ins_cost(INSN_COST);
15935   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15936   ins_encode %{
15937     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15938   %}
15939   ins_pipe(vdup_reg_reg128);
15940 %}
15941 
15942 instruct replicate2I_imm(vecD dst, immI con)
15943 %{
15944   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15945   match(Set dst (ReplicateI con));
15946   ins_cost(INSN_COST);
15947   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15948   ins_encode %{
15949     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15950   %}
15951   ins_pipe(vmovi_reg_imm64);
15952 %}
15953 
15954 instruct replicate4I_imm(vecX dst, immI con)
15955 %{
15956   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15957   match(Set dst (ReplicateI con));
15958   ins_cost(INSN_COST);
15959   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15960   ins_encode %{
15961     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15962   %}
15963   ins_pipe(vmovi_reg_imm128);
15964 %}
15965 
15966 instruct replicate2L(vecX dst, iRegL src)
15967 %{
15968   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15969   match(Set dst (ReplicateL src));
15970   ins_cost(INSN_COST);
15971   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
15972   ins_encode %{
15973     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
15974   %}
15975   ins_pipe(vdup_reg_reg128);
15976 %}
15977 
15978 instruct replicate2L_zero(vecX dst, immI0 zero)
15979 %{
15980   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15981   match(Set dst (ReplicateI zero));
15982   ins_cost(INSN_COST);
15983   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
15984   ins_encode %{
15985     __ eor(as_FloatRegister($dst$$reg), __ T16B,
15986            as_FloatRegister($dst$$reg),
15987            as_FloatRegister($dst$$reg));
15988   %}
15989   ins_pipe(vmovi_reg_imm128);
15990 %}
15991 
15992 instruct replicate2F(vecD dst, vRegF src)
15993 %{
15994   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15995   match(Set dst (ReplicateF src));
15996   ins_cost(INSN_COST);
15997   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
15998   ins_encode %{
15999     __ dup(as_FloatRegister($dst$$reg), __ T2S,
16000            as_FloatRegister($src$$reg));
16001   %}
16002   ins_pipe(vdup_reg_freg64);
16003 %}
16004 
16005 instruct replicate4F(vecX dst, vRegF src)
16006 %{
16007   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16008   match(Set dst (ReplicateF src));
16009   ins_cost(INSN_COST);
16010   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16011   ins_encode %{
16012     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16013            as_FloatRegister($src$$reg));
16014   %}
16015   ins_pipe(vdup_reg_freg128);
16016 %}
16017 
16018 instruct replicate2D(vecX dst, vRegD src)
16019 %{
16020   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16021   match(Set dst (ReplicateD src));
16022   ins_cost(INSN_COST);
16023   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16024   ins_encode %{
16025     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16026            as_FloatRegister($src$$reg));
16027   %}
16028   ins_pipe(vdup_reg_dreg128);
16029 %}
16030 
16031 // ====================REDUCTION ARITHMETIC====================================
16032 
16033 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp, iRegINoSp tmp2)
16034 %{
16035   match(Set dst (AddReductionVI src1 src2));
16036   ins_cost(INSN_COST);
16037   effect(TEMP tmp, TEMP tmp2);
16038   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16039             &quot;umov  $tmp2, $src2, S, 1\n\t&quot;
16040             &quot;addw  $dst, $src1, $tmp\n\t&quot;
16041             &quot;addw  $dst, $dst, $tmp2\t add reduction2i&quot;
16042   %}
16043   ins_encode %{
16044     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16045     __ umov($tmp2$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16046     __ addw($dst$$Register, $src1$$Register, $tmp$$Register);
16047     __ addw($dst$$Register, $dst$$Register, $tmp2$$Register);
16048   %}
16049   ins_pipe(pipe_class_default);
16050 %}
16051 
16052 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16053 %{
16054   match(Set dst (AddReductionVI src1 src2));
16055   ins_cost(INSN_COST);
16056   effect(TEMP tmp, TEMP tmp2);
16057   format %{ &quot;addv  $tmp, T4S, $src2\n\t&quot;
16058             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16059             &quot;addw  $dst, $tmp2, $src1\t add reduction4i&quot;
16060   %}
16061   ins_encode %{
16062     __ addv(as_FloatRegister($tmp$$reg), __ T4S,
16063             as_FloatRegister($src2$$reg));
16064     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16065     __ addw($dst$$Register, $tmp2$$Register, $src1$$Register);
16066   %}
16067   ins_pipe(pipe_class_default);
16068 %}
16069 
16070 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp)
16071 %{
16072   match(Set dst (MulReductionVI src1 src2));
16073   ins_cost(INSN_COST);
16074   effect(TEMP tmp, TEMP dst);
16075   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16076             &quot;mul   $dst, $tmp, $src1\n\t&quot;
16077             &quot;umov  $tmp, $src2, S, 1\n\t&quot;
16078             &quot;mul   $dst, $tmp, $dst\t mul reduction2i\n\t&quot;
16079   %}
16080   ins_encode %{
16081     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16082     __ mul($dst$$Register, $tmp$$Register, $src1$$Register);
16083     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16084     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16085   %}
16086   ins_pipe(pipe_class_default);
16087 %}
16088 
16089 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16090 %{
16091   match(Set dst (MulReductionVI src1 src2));
16092   ins_cost(INSN_COST);
16093   effect(TEMP tmp, TEMP tmp2, TEMP dst);
16094   format %{ &quot;ins   $tmp, $src2, 0, 1\n\t&quot;
16095             &quot;mul   $tmp, $tmp, $src2\n\t&quot;
16096             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16097             &quot;mul   $dst, $tmp2, $src1\n\t&quot;
16098             &quot;umov  $tmp2, $tmp, S, 1\n\t&quot;
16099             &quot;mul   $dst, $tmp2, $dst\t mul reduction4i\n\t&quot;
16100   %}
16101   ins_encode %{
16102     __ ins(as_FloatRegister($tmp$$reg), __ D,
16103            as_FloatRegister($src2$$reg), 0, 1);
16104     __ mulv(as_FloatRegister($tmp$$reg), __ T2S,
16105            as_FloatRegister($tmp$$reg), as_FloatRegister($src2$$reg));
16106     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16107     __ mul($dst$$Register, $tmp2$$Register, $src1$$Register);
16108     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 1);
16109     __ mul($dst$$Register, $tmp2$$Register, $dst$$Register);
16110   %}
16111   ins_pipe(pipe_class_default);
16112 %}
16113 
16114 instruct reduce_add2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16115 %{
16116   match(Set dst (AddReductionVF src1 src2));
16117   ins_cost(INSN_COST);
16118   effect(TEMP tmp, TEMP dst);
16119   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16120             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16121             &quot;fadds $dst, $dst, $tmp\t add reduction2f&quot;
16122   %}
16123   ins_encode %{
16124     __ fadds(as_FloatRegister($dst$$reg),
16125              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16126     __ ins(as_FloatRegister($tmp$$reg), __ S,
16127            as_FloatRegister($src2$$reg), 0, 1);
16128     __ fadds(as_FloatRegister($dst$$reg),
16129              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16130   %}
16131   ins_pipe(pipe_class_default);
16132 %}
16133 
16134 instruct reduce_add4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16135 %{
16136   match(Set dst (AddReductionVF src1 src2));
16137   ins_cost(INSN_COST);
16138   effect(TEMP tmp, TEMP dst);
16139   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16140             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16141             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16142             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16143             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16144             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16145             &quot;fadds $dst, $dst, $tmp\t add reduction4f&quot;
16146   %}
16147   ins_encode %{
16148     __ fadds(as_FloatRegister($dst$$reg),
16149              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16150     __ ins(as_FloatRegister($tmp$$reg), __ S,
16151            as_FloatRegister($src2$$reg), 0, 1);
16152     __ fadds(as_FloatRegister($dst$$reg),
16153              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16154     __ ins(as_FloatRegister($tmp$$reg), __ S,
16155            as_FloatRegister($src2$$reg), 0, 2);
16156     __ fadds(as_FloatRegister($dst$$reg),
16157              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16158     __ ins(as_FloatRegister($tmp$$reg), __ S,
16159            as_FloatRegister($src2$$reg), 0, 3);
16160     __ fadds(as_FloatRegister($dst$$reg),
16161              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16162   %}
16163   ins_pipe(pipe_class_default);
16164 %}
16165 
16166 instruct reduce_mul2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16167 %{
16168   match(Set dst (MulReductionVF src1 src2));
16169   ins_cost(INSN_COST);
16170   effect(TEMP tmp, TEMP dst);
16171   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16172             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16173             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16174   %}
16175   ins_encode %{
16176     __ fmuls(as_FloatRegister($dst$$reg),
16177              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16178     __ ins(as_FloatRegister($tmp$$reg), __ S,
16179            as_FloatRegister($src2$$reg), 0, 1);
16180     __ fmuls(as_FloatRegister($dst$$reg),
16181              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16182   %}
16183   ins_pipe(pipe_class_default);
16184 %}
16185 
16186 instruct reduce_mul4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16187 %{
16188   match(Set dst (MulReductionVF src1 src2));
16189   ins_cost(INSN_COST);
16190   effect(TEMP tmp, TEMP dst);
16191   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16192             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16193             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16194             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16195             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16196             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16197             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16198   %}
16199   ins_encode %{
16200     __ fmuls(as_FloatRegister($dst$$reg),
16201              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16202     __ ins(as_FloatRegister($tmp$$reg), __ S,
16203            as_FloatRegister($src2$$reg), 0, 1);
16204     __ fmuls(as_FloatRegister($dst$$reg),
16205              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16206     __ ins(as_FloatRegister($tmp$$reg), __ S,
16207            as_FloatRegister($src2$$reg), 0, 2);
16208     __ fmuls(as_FloatRegister($dst$$reg),
16209              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16210     __ ins(as_FloatRegister($tmp$$reg), __ S,
16211            as_FloatRegister($src2$$reg), 0, 3);
16212     __ fmuls(as_FloatRegister($dst$$reg),
16213              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16214   %}
16215   ins_pipe(pipe_class_default);
16216 %}
16217 
16218 instruct reduce_add2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16219 %{
16220   match(Set dst (AddReductionVD src1 src2));
16221   ins_cost(INSN_COST);
16222   effect(TEMP tmp, TEMP dst);
16223   format %{ &quot;faddd $dst, $src1, $src2\n\t&quot;
16224             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16225             &quot;faddd $dst, $dst, $tmp\t add reduction2d&quot;
16226   %}
16227   ins_encode %{
16228     __ faddd(as_FloatRegister($dst$$reg),
16229              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16230     __ ins(as_FloatRegister($tmp$$reg), __ D,
16231            as_FloatRegister($src2$$reg), 0, 1);
16232     __ faddd(as_FloatRegister($dst$$reg),
16233              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16234   %}
16235   ins_pipe(pipe_class_default);
16236 %}
16237 
16238 instruct reduce_mul2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16239 %{
16240   match(Set dst (MulReductionVD src1 src2));
16241   ins_cost(INSN_COST);
16242   effect(TEMP tmp, TEMP dst);
16243   format %{ &quot;fmuld $dst, $src1, $src2\n\t&quot;
16244             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16245             &quot;fmuld $dst, $dst, $tmp\t add reduction2d&quot;
16246   %}
16247   ins_encode %{
16248     __ fmuld(as_FloatRegister($dst$$reg),
16249              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16250     __ ins(as_FloatRegister($tmp$$reg), __ D,
16251            as_FloatRegister($src2$$reg), 0, 1);
16252     __ fmuld(as_FloatRegister($dst$$reg),
16253              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16254   %}
16255   ins_pipe(pipe_class_default);
16256 %}
16257 
16258 instruct reduce_max2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16259   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16260   match(Set dst (MaxReductionV src1 src2));
16261   ins_cost(INSN_COST);
16262   effect(TEMP_DEF dst, TEMP tmp);
16263   format %{ &quot;fmaxs $dst, $src1, $src2\n\t&quot;
16264             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16265             &quot;fmaxs $dst, $dst, $tmp\t max reduction2F&quot; %}
16266   ins_encode %{
16267     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16268     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16269     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16270   %}
16271   ins_pipe(pipe_class_default);
16272 %}
16273 
16274 instruct reduce_max4F(vRegF dst, vRegF src1, vecX src2) %{
16275   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16276   match(Set dst (MaxReductionV src1 src2));
16277   ins_cost(INSN_COST);
16278   effect(TEMP_DEF dst);
16279   format %{ &quot;fmaxv $dst, T4S, $src2\n\t&quot;
16280             &quot;fmaxs $dst, $dst, $src1\t max reduction4F&quot; %}
16281   ins_encode %{
16282     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16283     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16284   %}
16285   ins_pipe(pipe_class_default);
16286 %}
16287 
16288 instruct reduce_max2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16289   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16290   match(Set dst (MaxReductionV src1 src2));
16291   ins_cost(INSN_COST);
16292   effect(TEMP_DEF dst, TEMP tmp);
16293   format %{ &quot;fmaxd $dst, $src1, $src2\n\t&quot;
16294             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16295             &quot;fmaxd $dst, $dst, $tmp\t max reduction2D&quot; %}
16296   ins_encode %{
16297     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16298     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16299     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16300   %}
16301   ins_pipe(pipe_class_default);
16302 %}
16303 
16304 instruct reduce_min2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16305   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16306   match(Set dst (MinReductionV src1 src2));
16307   ins_cost(INSN_COST);
16308   effect(TEMP_DEF dst, TEMP tmp);
16309   format %{ &quot;fmins $dst, $src1, $src2\n\t&quot;
16310             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16311             &quot;fmins $dst, $dst, $tmp\t min reduction2F&quot; %}
16312   ins_encode %{
16313     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16314     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16315     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16316   %}
16317   ins_pipe(pipe_class_default);
16318 %}
16319 
16320 instruct reduce_min4F(vRegF dst, vRegF src1, vecX src2) %{
16321   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16322   match(Set dst (MinReductionV src1 src2));
16323   ins_cost(INSN_COST);
16324   effect(TEMP_DEF dst);
16325   format %{ &quot;fminv $dst, T4S, $src2\n\t&quot;
16326             &quot;fmins $dst, $dst, $src1\t min reduction4F&quot; %}
16327   ins_encode %{
16328     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16329     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16330   %}
16331   ins_pipe(pipe_class_default);
16332 %}
16333 
16334 instruct reduce_min2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16335   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16336   match(Set dst (MinReductionV src1 src2));
16337   ins_cost(INSN_COST);
16338   effect(TEMP_DEF dst, TEMP tmp);
16339   format %{ &quot;fmind $dst, $src1, $src2\n\t&quot;
16340             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16341             &quot;fmind $dst, $dst, $tmp\t min reduction2D&quot; %}
16342   ins_encode %{
16343     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16344     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16345     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16346   %}
16347   ins_pipe(pipe_class_default);
16348 %}
16349 
16350 // ====================VECTOR ARITHMETIC=======================================
16351 
16352 // --------------------------------- ADD --------------------------------------
16353 
16354 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16355 %{
16356   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16357             n-&gt;as_Vector()-&gt;length() == 8);
16358   match(Set dst (AddVB src1 src2));
16359   ins_cost(INSN_COST);
16360   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16361   ins_encode %{
16362     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16363             as_FloatRegister($src1$$reg),
16364             as_FloatRegister($src2$$reg));
16365   %}
16366   ins_pipe(vdop64);
16367 %}
16368 
16369 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16370 %{
16371   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16372   match(Set dst (AddVB src1 src2));
16373   ins_cost(INSN_COST);
16374   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16375   ins_encode %{
16376     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16377             as_FloatRegister($src1$$reg),
16378             as_FloatRegister($src2$$reg));
16379   %}
16380   ins_pipe(vdop128);
16381 %}
16382 
16383 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16384 %{
16385   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16386             n-&gt;as_Vector()-&gt;length() == 4);
16387   match(Set dst (AddVS src1 src2));
16388   ins_cost(INSN_COST);
16389   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16390   ins_encode %{
16391     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16392             as_FloatRegister($src1$$reg),
16393             as_FloatRegister($src2$$reg));
16394   %}
16395   ins_pipe(vdop64);
16396 %}
16397 
16398 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16399 %{
16400   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16401   match(Set dst (AddVS src1 src2));
16402   ins_cost(INSN_COST);
16403   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16404   ins_encode %{
16405     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16406             as_FloatRegister($src1$$reg),
16407             as_FloatRegister($src2$$reg));
16408   %}
16409   ins_pipe(vdop128);
16410 %}
16411 
16412 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16413 %{
16414   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16415   match(Set dst (AddVI src1 src2));
16416   ins_cost(INSN_COST);
16417   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16418   ins_encode %{
16419     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16420             as_FloatRegister($src1$$reg),
16421             as_FloatRegister($src2$$reg));
16422   %}
16423   ins_pipe(vdop64);
16424 %}
16425 
16426 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16427 %{
16428   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16429   match(Set dst (AddVI src1 src2));
16430   ins_cost(INSN_COST);
16431   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16432   ins_encode %{
16433     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16434             as_FloatRegister($src1$$reg),
16435             as_FloatRegister($src2$$reg));
16436   %}
16437   ins_pipe(vdop128);
16438 %}
16439 
16440 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16441 %{
16442   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16443   match(Set dst (AddVL src1 src2));
16444   ins_cost(INSN_COST);
16445   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16446   ins_encode %{
16447     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16448             as_FloatRegister($src1$$reg),
16449             as_FloatRegister($src2$$reg));
16450   %}
16451   ins_pipe(vdop128);
16452 %}
16453 
16454 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16455 %{
16456   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16457   match(Set dst (AddVF src1 src2));
16458   ins_cost(INSN_COST);
16459   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16460   ins_encode %{
16461     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16462             as_FloatRegister($src1$$reg),
16463             as_FloatRegister($src2$$reg));
16464   %}
16465   ins_pipe(vdop_fp64);
16466 %}
16467 
16468 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16469 %{
16470   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16471   match(Set dst (AddVF src1 src2));
16472   ins_cost(INSN_COST);
16473   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16474   ins_encode %{
16475     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16476             as_FloatRegister($src1$$reg),
16477             as_FloatRegister($src2$$reg));
16478   %}
16479   ins_pipe(vdop_fp128);
16480 %}
16481 
16482 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16483 %{
16484   match(Set dst (AddVD src1 src2));
16485   ins_cost(INSN_COST);
16486   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16487   ins_encode %{
16488     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16489             as_FloatRegister($src1$$reg),
16490             as_FloatRegister($src2$$reg));
16491   %}
16492   ins_pipe(vdop_fp128);
16493 %}
16494 
16495 // --------------------------------- SUB --------------------------------------
16496 
16497 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16498 %{
16499   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16500             n-&gt;as_Vector()-&gt;length() == 8);
16501   match(Set dst (SubVB src1 src2));
16502   ins_cost(INSN_COST);
16503   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16504   ins_encode %{
16505     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16506             as_FloatRegister($src1$$reg),
16507             as_FloatRegister($src2$$reg));
16508   %}
16509   ins_pipe(vdop64);
16510 %}
16511 
16512 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16513 %{
16514   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16515   match(Set dst (SubVB src1 src2));
16516   ins_cost(INSN_COST);
16517   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16518   ins_encode %{
16519     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16520             as_FloatRegister($src1$$reg),
16521             as_FloatRegister($src2$$reg));
16522   %}
16523   ins_pipe(vdop128);
16524 %}
16525 
16526 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16527 %{
16528   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16529             n-&gt;as_Vector()-&gt;length() == 4);
16530   match(Set dst (SubVS src1 src2));
16531   ins_cost(INSN_COST);
16532   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16533   ins_encode %{
16534     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16535             as_FloatRegister($src1$$reg),
16536             as_FloatRegister($src2$$reg));
16537   %}
16538   ins_pipe(vdop64);
16539 %}
16540 
16541 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16542 %{
16543   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16544   match(Set dst (SubVS src1 src2));
16545   ins_cost(INSN_COST);
16546   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16547   ins_encode %{
16548     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16549             as_FloatRegister($src1$$reg),
16550             as_FloatRegister($src2$$reg));
16551   %}
16552   ins_pipe(vdop128);
16553 %}
16554 
16555 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16556 %{
16557   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16558   match(Set dst (SubVI src1 src2));
16559   ins_cost(INSN_COST);
16560   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16561   ins_encode %{
16562     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16563             as_FloatRegister($src1$$reg),
16564             as_FloatRegister($src2$$reg));
16565   %}
16566   ins_pipe(vdop64);
16567 %}
16568 
16569 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16570 %{
16571   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16572   match(Set dst (SubVI src1 src2));
16573   ins_cost(INSN_COST);
16574   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16575   ins_encode %{
16576     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16577             as_FloatRegister($src1$$reg),
16578             as_FloatRegister($src2$$reg));
16579   %}
16580   ins_pipe(vdop128);
16581 %}
16582 
16583 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16584 %{
16585   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16586   match(Set dst (SubVL src1 src2));
16587   ins_cost(INSN_COST);
16588   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16589   ins_encode %{
16590     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16591             as_FloatRegister($src1$$reg),
16592             as_FloatRegister($src2$$reg));
16593   %}
16594   ins_pipe(vdop128);
16595 %}
16596 
16597 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16598 %{
16599   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16600   match(Set dst (SubVF src1 src2));
16601   ins_cost(INSN_COST);
16602   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16603   ins_encode %{
16604     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16605             as_FloatRegister($src1$$reg),
16606             as_FloatRegister($src2$$reg));
16607   %}
16608   ins_pipe(vdop_fp64);
16609 %}
16610 
16611 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16612 %{
16613   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16614   match(Set dst (SubVF src1 src2));
16615   ins_cost(INSN_COST);
16616   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16617   ins_encode %{
16618     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16619             as_FloatRegister($src1$$reg),
16620             as_FloatRegister($src2$$reg));
16621   %}
16622   ins_pipe(vdop_fp128);
16623 %}
16624 
16625 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16626 %{
16627   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16628   match(Set dst (SubVD src1 src2));
16629   ins_cost(INSN_COST);
16630   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16631   ins_encode %{
16632     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16633             as_FloatRegister($src1$$reg),
16634             as_FloatRegister($src2$$reg));
16635   %}
16636   ins_pipe(vdop_fp128);
16637 %}
16638 
16639 // --------------------------------- MUL --------------------------------------
16640 
16641 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16642 %{
16643   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16644             n-&gt;as_Vector()-&gt;length() == 4);
16645   match(Set dst (MulVS src1 src2));
16646   ins_cost(INSN_COST);
16647   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16648   ins_encode %{
16649     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16650             as_FloatRegister($src1$$reg),
16651             as_FloatRegister($src2$$reg));
16652   %}
16653   ins_pipe(vmul64);
16654 %}
16655 
16656 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16657 %{
16658   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16659   match(Set dst (MulVS src1 src2));
16660   ins_cost(INSN_COST);
16661   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16662   ins_encode %{
16663     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16664             as_FloatRegister($src1$$reg),
16665             as_FloatRegister($src2$$reg));
16666   %}
16667   ins_pipe(vmul128);
16668 %}
16669 
16670 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16671 %{
16672   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16673   match(Set dst (MulVI src1 src2));
16674   ins_cost(INSN_COST);
16675   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16676   ins_encode %{
16677     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16678             as_FloatRegister($src1$$reg),
16679             as_FloatRegister($src2$$reg));
16680   %}
16681   ins_pipe(vmul64);
16682 %}
16683 
16684 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16685 %{
16686   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16687   match(Set dst (MulVI src1 src2));
16688   ins_cost(INSN_COST);
16689   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16690   ins_encode %{
16691     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16692             as_FloatRegister($src1$$reg),
16693             as_FloatRegister($src2$$reg));
16694   %}
16695   ins_pipe(vmul128);
16696 %}
16697 
16698 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16699 %{
16700   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16701   match(Set dst (MulVF src1 src2));
16702   ins_cost(INSN_COST);
16703   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16704   ins_encode %{
16705     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16706             as_FloatRegister($src1$$reg),
16707             as_FloatRegister($src2$$reg));
16708   %}
16709   ins_pipe(vmuldiv_fp64);
16710 %}
16711 
16712 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16713 %{
16714   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16715   match(Set dst (MulVF src1 src2));
16716   ins_cost(INSN_COST);
16717   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16718   ins_encode %{
16719     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16720             as_FloatRegister($src1$$reg),
16721             as_FloatRegister($src2$$reg));
16722   %}
16723   ins_pipe(vmuldiv_fp128);
16724 %}
16725 
16726 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16727 %{
16728   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16729   match(Set dst (MulVD src1 src2));
16730   ins_cost(INSN_COST);
16731   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16732   ins_encode %{
16733     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16734             as_FloatRegister($src1$$reg),
16735             as_FloatRegister($src2$$reg));
16736   %}
16737   ins_pipe(vmuldiv_fp128);
16738 %}
16739 
16740 // --------------------------------- MLA --------------------------------------
16741 
16742 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16743 %{
16744   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16745             n-&gt;as_Vector()-&gt;length() == 4);
16746   match(Set dst (AddVS dst (MulVS src1 src2)));
16747   ins_cost(INSN_COST);
16748   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16749   ins_encode %{
16750     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16751             as_FloatRegister($src1$$reg),
16752             as_FloatRegister($src2$$reg));
16753   %}
16754   ins_pipe(vmla64);
16755 %}
16756 
16757 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16758 %{
16759   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16760   match(Set dst (AddVS dst (MulVS src1 src2)));
16761   ins_cost(INSN_COST);
16762   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16763   ins_encode %{
16764     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16765             as_FloatRegister($src1$$reg),
16766             as_FloatRegister($src2$$reg));
16767   %}
16768   ins_pipe(vmla128);
16769 %}
16770 
16771 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16772 %{
16773   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16774   match(Set dst (AddVI dst (MulVI src1 src2)));
16775   ins_cost(INSN_COST);
16776   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16777   ins_encode %{
16778     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16779             as_FloatRegister($src1$$reg),
16780             as_FloatRegister($src2$$reg));
16781   %}
16782   ins_pipe(vmla64);
16783 %}
16784 
16785 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16786 %{
16787   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16788   match(Set dst (AddVI dst (MulVI src1 src2)));
16789   ins_cost(INSN_COST);
16790   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16791   ins_encode %{
16792     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16793             as_FloatRegister($src1$$reg),
16794             as_FloatRegister($src2$$reg));
16795   %}
16796   ins_pipe(vmla128);
16797 %}
16798 
16799 // dst + src1 * src2
16800 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16801   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16802   match(Set dst (FmaVF  dst (Binary src1 src2)));
16803   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16804   ins_cost(INSN_COST);
16805   ins_encode %{
16806     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16807             as_FloatRegister($src1$$reg),
16808             as_FloatRegister($src2$$reg));
16809   %}
16810   ins_pipe(vmuldiv_fp64);
16811 %}
16812 
16813 // dst + src1 * src2
16814 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16815   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16816   match(Set dst (FmaVF  dst (Binary src1 src2)));
16817   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16818   ins_cost(INSN_COST);
16819   ins_encode %{
16820     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16821             as_FloatRegister($src1$$reg),
16822             as_FloatRegister($src2$$reg));
16823   %}
16824   ins_pipe(vmuldiv_fp128);
16825 %}
16826 
16827 // dst + src1 * src2
16828 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16829   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16830   match(Set dst (FmaVD  dst (Binary src1 src2)));
16831   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16832   ins_cost(INSN_COST);
16833   ins_encode %{
16834     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16835             as_FloatRegister($src1$$reg),
16836             as_FloatRegister($src2$$reg));
16837   %}
16838   ins_pipe(vmuldiv_fp128);
16839 %}
16840 
16841 // --------------------------------- MLS --------------------------------------
16842 
16843 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16844 %{
16845   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16846             n-&gt;as_Vector()-&gt;length() == 4);
16847   match(Set dst (SubVS dst (MulVS src1 src2)));
16848   ins_cost(INSN_COST);
16849   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16850   ins_encode %{
16851     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16852             as_FloatRegister($src1$$reg),
16853             as_FloatRegister($src2$$reg));
16854   %}
16855   ins_pipe(vmla64);
16856 %}
16857 
16858 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16859 %{
16860   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16861   match(Set dst (SubVS dst (MulVS src1 src2)));
16862   ins_cost(INSN_COST);
16863   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16864   ins_encode %{
16865     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16866             as_FloatRegister($src1$$reg),
16867             as_FloatRegister($src2$$reg));
16868   %}
16869   ins_pipe(vmla128);
16870 %}
16871 
16872 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16873 %{
16874   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16875   match(Set dst (SubVI dst (MulVI src1 src2)));
16876   ins_cost(INSN_COST);
16877   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16878   ins_encode %{
16879     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16880             as_FloatRegister($src1$$reg),
16881             as_FloatRegister($src2$$reg));
16882   %}
16883   ins_pipe(vmla64);
16884 %}
16885 
16886 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16887 %{
16888   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16889   match(Set dst (SubVI dst (MulVI src1 src2)));
16890   ins_cost(INSN_COST);
16891   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16892   ins_encode %{
16893     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16894             as_FloatRegister($src1$$reg),
16895             as_FloatRegister($src2$$reg));
16896   %}
16897   ins_pipe(vmla128);
16898 %}
16899 
16900 // dst - src1 * src2
16901 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16902   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16903   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16904   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16905   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16906   ins_cost(INSN_COST);
16907   ins_encode %{
16908     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16909             as_FloatRegister($src1$$reg),
16910             as_FloatRegister($src2$$reg));
16911   %}
16912   ins_pipe(vmuldiv_fp64);
16913 %}
16914 
16915 // dst - src1 * src2
16916 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16917   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16918   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16919   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16920   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16921   ins_cost(INSN_COST);
16922   ins_encode %{
16923     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16924             as_FloatRegister($src1$$reg),
16925             as_FloatRegister($src2$$reg));
16926   %}
16927   ins_pipe(vmuldiv_fp128);
16928 %}
16929 
16930 // dst - src1 * src2
16931 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16932   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16933   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16934   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16935   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16936   ins_cost(INSN_COST);
16937   ins_encode %{
16938     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16939             as_FloatRegister($src1$$reg),
16940             as_FloatRegister($src2$$reg));
16941   %}
16942   ins_pipe(vmuldiv_fp128);
16943 %}
16944 
16945 // --------------------------------- DIV --------------------------------------
16946 
16947 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
16948 %{
16949   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16950   match(Set dst (DivVF src1 src2));
16951   ins_cost(INSN_COST);
16952   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16953   ins_encode %{
16954     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
16955             as_FloatRegister($src1$$reg),
16956             as_FloatRegister($src2$$reg));
16957   %}
16958   ins_pipe(vmuldiv_fp64);
16959 %}
16960 
16961 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
16962 %{
16963   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16964   match(Set dst (DivVF src1 src2));
16965   ins_cost(INSN_COST);
16966   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16967   ins_encode %{
16968     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
16969             as_FloatRegister($src1$$reg),
16970             as_FloatRegister($src2$$reg));
16971   %}
16972   ins_pipe(vmuldiv_fp128);
16973 %}
16974 
16975 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
16976 %{
16977   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16978   match(Set dst (DivVD src1 src2));
16979   ins_cost(INSN_COST);
16980   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
16981   ins_encode %{
16982     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
16983             as_FloatRegister($src1$$reg),
16984             as_FloatRegister($src2$$reg));
16985   %}
16986   ins_pipe(vmuldiv_fp128);
16987 %}
16988 
16989 // --------------------------------- SQRT -------------------------------------
16990 
16991 instruct vsqrt2D(vecX dst, vecX src)
16992 %{
16993   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16994   match(Set dst (SqrtVD src));
16995   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
16996   ins_encode %{
16997     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
16998              as_FloatRegister($src$$reg));
16999   %}
17000   ins_pipe(vsqrt_fp128);
17001 %}
17002 
17003 // --------------------------------- ABS --------------------------------------
17004 
17005 instruct vabs2F(vecD dst, vecD src)
17006 %{
17007   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17008   match(Set dst (AbsVF src));
17009   ins_cost(INSN_COST * 3);
17010   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17011   ins_encode %{
17012     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17013             as_FloatRegister($src$$reg));
17014   %}
17015   ins_pipe(vunop_fp64);
17016 %}
17017 
17018 instruct vabs4F(vecX dst, vecX src)
17019 %{
17020   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17021   match(Set dst (AbsVF src));
17022   ins_cost(INSN_COST * 3);
17023   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17024   ins_encode %{
17025     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17026             as_FloatRegister($src$$reg));
17027   %}
17028   ins_pipe(vunop_fp128);
17029 %}
17030 
17031 instruct vabs2D(vecX dst, vecX src)
17032 %{
17033   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17034   match(Set dst (AbsVD src));
17035   ins_cost(INSN_COST * 3);
17036   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17037   ins_encode %{
17038     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17039             as_FloatRegister($src$$reg));
17040   %}
17041   ins_pipe(vunop_fp128);
17042 %}
17043 
17044 // --------------------------------- NEG --------------------------------------
17045 
17046 instruct vneg2F(vecD dst, vecD src)
17047 %{
17048   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17049   match(Set dst (NegVF src));
17050   ins_cost(INSN_COST * 3);
17051   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17052   ins_encode %{
17053     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17054             as_FloatRegister($src$$reg));
17055   %}
17056   ins_pipe(vunop_fp64);
17057 %}
17058 
17059 instruct vneg4F(vecX dst, vecX src)
17060 %{
17061   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17062   match(Set dst (NegVF src));
17063   ins_cost(INSN_COST * 3);
17064   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17065   ins_encode %{
17066     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17067             as_FloatRegister($src$$reg));
17068   %}
17069   ins_pipe(vunop_fp128);
17070 %}
17071 
17072 instruct vneg2D(vecX dst, vecX src)
17073 %{
17074   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17075   match(Set dst (NegVD src));
17076   ins_cost(INSN_COST * 3);
17077   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17078   ins_encode %{
17079     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17080             as_FloatRegister($src$$reg));
17081   %}
17082   ins_pipe(vunop_fp128);
17083 %}
17084 
17085 // --------------------------------- AND --------------------------------------
17086 
17087 instruct vand8B(vecD dst, vecD src1, vecD src2)
17088 %{
17089   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17090             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17091   match(Set dst (AndV src1 src2));
17092   ins_cost(INSN_COST);
17093   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17094   ins_encode %{
17095     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17096             as_FloatRegister($src1$$reg),
17097             as_FloatRegister($src2$$reg));
17098   %}
17099   ins_pipe(vlogical64);
17100 %}
17101 
17102 instruct vand16B(vecX dst, vecX src1, vecX src2)
17103 %{
17104   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17105   match(Set dst (AndV src1 src2));
17106   ins_cost(INSN_COST);
17107   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17108   ins_encode %{
17109     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17110             as_FloatRegister($src1$$reg),
17111             as_FloatRegister($src2$$reg));
17112   %}
17113   ins_pipe(vlogical128);
17114 %}
17115 
17116 // --------------------------------- OR ---------------------------------------
17117 
17118 instruct vor8B(vecD dst, vecD src1, vecD src2)
17119 %{
17120   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17121             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17122   match(Set dst (OrV src1 src2));
17123   ins_cost(INSN_COST);
17124   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17125   ins_encode %{
17126     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17127             as_FloatRegister($src1$$reg),
17128             as_FloatRegister($src2$$reg));
17129   %}
17130   ins_pipe(vlogical64);
17131 %}
17132 
17133 instruct vor16B(vecX dst, vecX src1, vecX src2)
17134 %{
17135   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17136   match(Set dst (OrV src1 src2));
17137   ins_cost(INSN_COST);
17138   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17139   ins_encode %{
17140     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17141             as_FloatRegister($src1$$reg),
17142             as_FloatRegister($src2$$reg));
17143   %}
17144   ins_pipe(vlogical128);
17145 %}
17146 
17147 // --------------------------------- XOR --------------------------------------
17148 
17149 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17150 %{
17151   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17152             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17153   match(Set dst (XorV src1 src2));
17154   ins_cost(INSN_COST);
17155   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17156   ins_encode %{
17157     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17158             as_FloatRegister($src1$$reg),
17159             as_FloatRegister($src2$$reg));
17160   %}
17161   ins_pipe(vlogical64);
17162 %}
17163 
17164 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17165 %{
17166   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17167   match(Set dst (XorV src1 src2));
17168   ins_cost(INSN_COST);
17169   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17170   ins_encode %{
17171     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17172             as_FloatRegister($src1$$reg),
17173             as_FloatRegister($src2$$reg));
17174   %}
17175   ins_pipe(vlogical128);
17176 %}
17177 
17178 // ------------------------------ Shift ---------------------------------------
17179 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17180   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17181   match(Set dst (LShiftCntV cnt));
17182   match(Set dst (RShiftCntV cnt));
17183   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17184   ins_encode %{
17185     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17186   %}
17187   ins_pipe(vdup_reg_reg64);
17188 %}
17189 
17190 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17191   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17192   match(Set dst (LShiftCntV cnt));
17193   match(Set dst (RShiftCntV cnt));
17194   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17195   ins_encode %{
17196     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17197   %}
17198   ins_pipe(vdup_reg_reg128);
17199 %}
17200 
17201 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17202   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17203             n-&gt;as_Vector()-&gt;length() == 8);
17204   match(Set dst (LShiftVB src shift));
17205   ins_cost(INSN_COST);
17206   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17207   ins_encode %{
17208     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17209             as_FloatRegister($src$$reg),
17210             as_FloatRegister($shift$$reg));
17211   %}
17212   ins_pipe(vshift64);
17213 %}
17214 
17215 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17216   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17217   match(Set dst (LShiftVB src shift));
17218   ins_cost(INSN_COST);
17219   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17220   ins_encode %{
17221     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17222             as_FloatRegister($src$$reg),
17223             as_FloatRegister($shift$$reg));
17224   %}
17225   ins_pipe(vshift128);
17226 %}
17227 
17228 // Right shifts with vector shift count on aarch64 SIMD are implemented
17229 // as left shift by negative shift count.
17230 // There are two cases for vector shift count.
17231 //
17232 // Case 1: The vector shift count is from replication.
17233 //        |            |
17234 //    LoadVector  RShiftCntV
17235 //        |       /
17236 //     RShiftVI
17237 // Note: In inner loop, multiple neg instructions are used, which can be
17238 // moved to outer loop and merge into one neg instruction.
17239 //
17240 // Case 2: The vector shift count is from loading.
17241 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17242 // panama/vectorIntrinsics(JEP 338: Vector API).
17243 //        |            |
17244 //    LoadVector  LoadVector
17245 //        |       /
17246 //     RShiftVI
17247 //
17248 
17249 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17250   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17251             n-&gt;as_Vector()-&gt;length() == 8);
17252   match(Set dst (RShiftVB src shift));
17253   ins_cost(INSN_COST);
17254   effect(TEMP tmp);
17255   format %{ &quot;negr  $tmp,$shift\t&quot;
17256             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17257   ins_encode %{
17258     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17259             as_FloatRegister($shift$$reg));
17260     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17261             as_FloatRegister($src$$reg),
17262             as_FloatRegister($tmp$$reg));
17263   %}
17264   ins_pipe(vshift64);
17265 %}
17266 
17267 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17268   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17269   match(Set dst (RShiftVB src shift));
17270   ins_cost(INSN_COST);
17271   effect(TEMP tmp);
17272   format %{ &quot;negr  $tmp,$shift\t&quot;
17273             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17274   ins_encode %{
17275     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17276             as_FloatRegister($shift$$reg));
17277     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17278             as_FloatRegister($src$$reg),
17279             as_FloatRegister($tmp$$reg));
17280   %}
17281   ins_pipe(vshift128);
17282 %}
17283 
17284 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17285   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17286             n-&gt;as_Vector()-&gt;length() == 8);
17287   match(Set dst (URShiftVB src shift));
17288   ins_cost(INSN_COST);
17289   effect(TEMP tmp);
17290   format %{ &quot;negr  $tmp,$shift\t&quot;
17291             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17292   ins_encode %{
17293     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17294             as_FloatRegister($shift$$reg));
17295     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17296             as_FloatRegister($src$$reg),
17297             as_FloatRegister($tmp$$reg));
17298   %}
17299   ins_pipe(vshift64);
17300 %}
17301 
17302 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17303   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17304   match(Set dst (URShiftVB src shift));
17305   ins_cost(INSN_COST);
17306   effect(TEMP tmp);
17307   format %{ &quot;negr  $tmp,$shift\t&quot;
17308             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17309   ins_encode %{
17310     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17311             as_FloatRegister($shift$$reg));
17312     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17313             as_FloatRegister($src$$reg),
17314             as_FloatRegister($tmp$$reg));
17315   %}
17316   ins_pipe(vshift128);
17317 %}
17318 
17319 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17320   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17321             n-&gt;as_Vector()-&gt;length() == 8);
17322   match(Set dst (LShiftVB src shift));
17323   ins_cost(INSN_COST);
17324   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17325   ins_encode %{
17326     int sh = (int)$shift$$constant;
17327     if (sh &gt;= 8) {
17328       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17329              as_FloatRegister($src$$reg),
17330              as_FloatRegister($src$$reg));
17331     } else {
17332       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17333              as_FloatRegister($src$$reg), sh);
17334     }
17335   %}
17336   ins_pipe(vshift64_imm);
17337 %}
17338 
17339 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17340   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17341   match(Set dst (LShiftVB src shift));
17342   ins_cost(INSN_COST);
17343   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17344   ins_encode %{
17345     int sh = (int)$shift$$constant;
17346     if (sh &gt;= 8) {
17347       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17348              as_FloatRegister($src$$reg),
17349              as_FloatRegister($src$$reg));
17350     } else {
17351       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17352              as_FloatRegister($src$$reg), sh);
17353     }
17354   %}
17355   ins_pipe(vshift128_imm);
17356 %}
17357 
17358 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17359   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17360             n-&gt;as_Vector()-&gt;length() == 8);
17361   match(Set dst (RShiftVB src shift));
17362   ins_cost(INSN_COST);
17363   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17364   ins_encode %{
17365     int sh = (int)$shift$$constant;
17366     if (sh &gt;= 8) sh = 7;
17367     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17368            as_FloatRegister($src$$reg), sh);
17369   %}
17370   ins_pipe(vshift64_imm);
17371 %}
17372 
17373 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17374   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17375   match(Set dst (RShiftVB src shift));
17376   ins_cost(INSN_COST);
17377   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17378   ins_encode %{
17379     int sh = (int)$shift$$constant;
17380     if (sh &gt;= 8) sh = 7;
17381     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17382            as_FloatRegister($src$$reg), sh);
17383   %}
17384   ins_pipe(vshift128_imm);
17385 %}
17386 
17387 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17388   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17389             n-&gt;as_Vector()-&gt;length() == 8);
17390   match(Set dst (URShiftVB src shift));
17391   ins_cost(INSN_COST);
17392   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17393   ins_encode %{
17394     int sh = (int)$shift$$constant;
17395     if (sh &gt;= 8) {
17396       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17397              as_FloatRegister($src$$reg),
17398              as_FloatRegister($src$$reg));
17399     } else {
17400       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17401              as_FloatRegister($src$$reg), sh);
17402     }
17403   %}
17404   ins_pipe(vshift64_imm);
17405 %}
17406 
17407 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17408   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17409   match(Set dst (URShiftVB src shift));
17410   ins_cost(INSN_COST);
17411   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17412   ins_encode %{
17413     int sh = (int)$shift$$constant;
17414     if (sh &gt;= 8) {
17415       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17416              as_FloatRegister($src$$reg),
17417              as_FloatRegister($src$$reg));
17418     } else {
17419       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17420              as_FloatRegister($src$$reg), sh);
17421     }
17422   %}
17423   ins_pipe(vshift128_imm);
17424 %}
17425 
17426 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17427   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17428             n-&gt;as_Vector()-&gt;length() == 4);
17429   match(Set dst (LShiftVS src shift));
17430   ins_cost(INSN_COST);
17431   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17432   ins_encode %{
17433     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17434             as_FloatRegister($src$$reg),
17435             as_FloatRegister($shift$$reg));
17436   %}
17437   ins_pipe(vshift64);
17438 %}
17439 
17440 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17441   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17442   match(Set dst (LShiftVS src shift));
17443   ins_cost(INSN_COST);
17444   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17445   ins_encode %{
17446     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17447             as_FloatRegister($src$$reg),
17448             as_FloatRegister($shift$$reg));
17449   %}
17450   ins_pipe(vshift128);
17451 %}
17452 
17453 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17454   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17455             n-&gt;as_Vector()-&gt;length() == 4);
17456   match(Set dst (RShiftVS src shift));
17457   ins_cost(INSN_COST);
17458   effect(TEMP tmp);
17459   format %{ &quot;negr  $tmp,$shift\t&quot;
17460             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17461   ins_encode %{
17462     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17463             as_FloatRegister($shift$$reg));
17464     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17465             as_FloatRegister($src$$reg),
17466             as_FloatRegister($tmp$$reg));
17467   %}
17468   ins_pipe(vshift64);
17469 %}
17470 
17471 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17472   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17473   match(Set dst (RShiftVS src shift));
17474   ins_cost(INSN_COST);
17475   effect(TEMP tmp);
17476   format %{ &quot;negr  $tmp,$shift\t&quot;
17477             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17478   ins_encode %{
17479     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17480             as_FloatRegister($shift$$reg));
17481     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17482             as_FloatRegister($src$$reg),
17483             as_FloatRegister($tmp$$reg));
17484   %}
17485   ins_pipe(vshift128);
17486 %}
17487 
17488 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17489   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17490             n-&gt;as_Vector()-&gt;length() == 4);
17491   match(Set dst (URShiftVS src shift));
17492   ins_cost(INSN_COST);
17493   effect(TEMP tmp);
17494   format %{ &quot;negr  $tmp,$shift\t&quot;
17495             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17496   ins_encode %{
17497     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17498             as_FloatRegister($shift$$reg));
17499     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17500             as_FloatRegister($src$$reg),
17501             as_FloatRegister($tmp$$reg));
17502   %}
17503   ins_pipe(vshift64);
17504 %}
17505 
17506 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17507   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17508   match(Set dst (URShiftVS src shift));
17509   ins_cost(INSN_COST);
17510   effect(TEMP tmp);
17511   format %{ &quot;negr  $tmp,$shift\t&quot;
17512             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17513   ins_encode %{
17514     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17515             as_FloatRegister($shift$$reg));
17516     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17517             as_FloatRegister($src$$reg),
17518             as_FloatRegister($tmp$$reg));
17519   %}
17520   ins_pipe(vshift128);
17521 %}
17522 
17523 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17524   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17525             n-&gt;as_Vector()-&gt;length() == 4);
17526   match(Set dst (LShiftVS src shift));
17527   ins_cost(INSN_COST);
17528   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17529   ins_encode %{
17530     int sh = (int)$shift$$constant;
17531     if (sh &gt;= 16) {
17532       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17533              as_FloatRegister($src$$reg),
17534              as_FloatRegister($src$$reg));
17535     } else {
17536       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17537              as_FloatRegister($src$$reg), sh);
17538     }
17539   %}
17540   ins_pipe(vshift64_imm);
17541 %}
17542 
17543 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17544   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17545   match(Set dst (LShiftVS src shift));
17546   ins_cost(INSN_COST);
17547   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17548   ins_encode %{
17549     int sh = (int)$shift$$constant;
17550     if (sh &gt;= 16) {
17551       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17552              as_FloatRegister($src$$reg),
17553              as_FloatRegister($src$$reg));
17554     } else {
17555       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17556              as_FloatRegister($src$$reg), sh);
17557     }
17558   %}
17559   ins_pipe(vshift128_imm);
17560 %}
17561 
17562 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17563   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17564             n-&gt;as_Vector()-&gt;length() == 4);
17565   match(Set dst (RShiftVS src shift));
17566   ins_cost(INSN_COST);
17567   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17568   ins_encode %{
17569     int sh = (int)$shift$$constant;
17570     if (sh &gt;= 16) sh = 15;
17571     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17572            as_FloatRegister($src$$reg), sh);
17573   %}
17574   ins_pipe(vshift64_imm);
17575 %}
17576 
17577 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17578   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17579   match(Set dst (RShiftVS src shift));
17580   ins_cost(INSN_COST);
17581   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17582   ins_encode %{
17583     int sh = (int)$shift$$constant;
17584     if (sh &gt;= 16) sh = 15;
17585     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17586            as_FloatRegister($src$$reg), sh);
17587   %}
17588   ins_pipe(vshift128_imm);
17589 %}
17590 
17591 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17592   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17593             n-&gt;as_Vector()-&gt;length() == 4);
17594   match(Set dst (URShiftVS src shift));
17595   ins_cost(INSN_COST);
17596   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17597   ins_encode %{
17598     int sh = (int)$shift$$constant;
17599     if (sh &gt;= 16) {
17600       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17601              as_FloatRegister($src$$reg),
17602              as_FloatRegister($src$$reg));
17603     } else {
17604       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17605              as_FloatRegister($src$$reg), sh);
17606     }
17607   %}
17608   ins_pipe(vshift64_imm);
17609 %}
17610 
17611 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17612   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17613   match(Set dst (URShiftVS src shift));
17614   ins_cost(INSN_COST);
17615   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17616   ins_encode %{
17617     int sh = (int)$shift$$constant;
17618     if (sh &gt;= 16) {
17619       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17620              as_FloatRegister($src$$reg),
17621              as_FloatRegister($src$$reg));
17622     } else {
17623       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17624              as_FloatRegister($src$$reg), sh);
17625     }
17626   %}
17627   ins_pipe(vshift128_imm);
17628 %}
17629 
17630 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17631   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17632   match(Set dst (LShiftVI src shift));
17633   ins_cost(INSN_COST);
17634   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17635   ins_encode %{
17636     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17637             as_FloatRegister($src$$reg),
17638             as_FloatRegister($shift$$reg));
17639   %}
17640   ins_pipe(vshift64);
17641 %}
17642 
17643 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17644   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17645   match(Set dst (LShiftVI src shift));
17646   ins_cost(INSN_COST);
17647   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17648   ins_encode %{
17649     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17650             as_FloatRegister($src$$reg),
17651             as_FloatRegister($shift$$reg));
17652   %}
17653   ins_pipe(vshift128);
17654 %}
17655 
17656 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17657   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17658   match(Set dst (RShiftVI src shift));
17659   ins_cost(INSN_COST);
17660   effect(TEMP tmp);
17661   format %{ &quot;negr  $tmp,$shift\t&quot;
17662             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17663   ins_encode %{
17664     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17665             as_FloatRegister($shift$$reg));
17666     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17667             as_FloatRegister($src$$reg),
17668             as_FloatRegister($tmp$$reg));
17669   %}
17670   ins_pipe(vshift64);
17671 %}
17672 
17673 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17674   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17675   match(Set dst (RShiftVI src shift));
17676   ins_cost(INSN_COST);
17677   effect(TEMP tmp);
17678   format %{ &quot;negr  $tmp,$shift\t&quot;
17679             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17680   ins_encode %{
17681     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17682             as_FloatRegister($shift$$reg));
17683     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17684             as_FloatRegister($src$$reg),
17685             as_FloatRegister($tmp$$reg));
17686   %}
17687   ins_pipe(vshift128);
17688 %}
17689 
17690 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17691   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17692   match(Set dst (URShiftVI src shift));
17693   ins_cost(INSN_COST);
17694   effect(TEMP tmp);
17695   format %{ &quot;negr  $tmp,$shift\t&quot;
17696             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17697   ins_encode %{
17698     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17699             as_FloatRegister($shift$$reg));
17700     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17701             as_FloatRegister($src$$reg),
17702             as_FloatRegister($tmp$$reg));
17703   %}
17704   ins_pipe(vshift64);
17705 %}
17706 
17707 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17708   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17709   match(Set dst (URShiftVI src shift));
17710   ins_cost(INSN_COST);
17711   effect(TEMP tmp);
17712   format %{ &quot;negr  $tmp,$shift\t&quot;
17713             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17714   ins_encode %{
17715     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17716             as_FloatRegister($shift$$reg));
17717     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17718             as_FloatRegister($src$$reg),
17719             as_FloatRegister($tmp$$reg));
17720   %}
17721   ins_pipe(vshift128);
17722 %}
17723 
17724 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17725   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17726   match(Set dst (LShiftVI src shift));
17727   ins_cost(INSN_COST);
17728   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17729   ins_encode %{
17730     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17731            as_FloatRegister($src$$reg),
17732            (int)$shift$$constant);
17733   %}
17734   ins_pipe(vshift64_imm);
17735 %}
17736 
17737 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17738   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17739   match(Set dst (LShiftVI src shift));
17740   ins_cost(INSN_COST);
17741   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17742   ins_encode %{
17743     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17744            as_FloatRegister($src$$reg),
17745            (int)$shift$$constant);
17746   %}
17747   ins_pipe(vshift128_imm);
17748 %}
17749 
17750 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17751   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17752   match(Set dst (RShiftVI src shift));
17753   ins_cost(INSN_COST);
17754   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17755   ins_encode %{
17756     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17757             as_FloatRegister($src$$reg),
17758             (int)$shift$$constant);
17759   %}
17760   ins_pipe(vshift64_imm);
17761 %}
17762 
17763 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17764   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17765   match(Set dst (RShiftVI src shift));
17766   ins_cost(INSN_COST);
17767   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17768   ins_encode %{
17769     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17770             as_FloatRegister($src$$reg),
17771             (int)$shift$$constant);
17772   %}
17773   ins_pipe(vshift128_imm);
17774 %}
17775 
17776 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17777   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17778   match(Set dst (URShiftVI src shift));
17779   ins_cost(INSN_COST);
17780   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17781   ins_encode %{
17782     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17783             as_FloatRegister($src$$reg),
17784             (int)$shift$$constant);
17785   %}
17786   ins_pipe(vshift64_imm);
17787 %}
17788 
17789 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17790   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17791   match(Set dst (URShiftVI src shift));
17792   ins_cost(INSN_COST);
17793   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17794   ins_encode %{
17795     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17796             as_FloatRegister($src$$reg),
17797             (int)$shift$$constant);
17798   %}
17799   ins_pipe(vshift128_imm);
17800 %}
17801 
17802 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17803   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17804   match(Set dst (LShiftVL src shift));
17805   ins_cost(INSN_COST);
17806   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17807   ins_encode %{
17808     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17809             as_FloatRegister($src$$reg),
17810             as_FloatRegister($shift$$reg));
17811   %}
17812   ins_pipe(vshift128);
17813 %}
17814 
17815 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17816   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17817   match(Set dst (RShiftVL src shift));
17818   ins_cost(INSN_COST);
17819   effect(TEMP tmp);
17820   format %{ &quot;negr  $tmp,$shift\t&quot;
17821             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17822   ins_encode %{
17823     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17824             as_FloatRegister($shift$$reg));
17825     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17826             as_FloatRegister($src$$reg),
17827             as_FloatRegister($tmp$$reg));
17828   %}
17829   ins_pipe(vshift128);
17830 %}
17831 
17832 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17833   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17834   match(Set dst (URShiftVL src shift));
17835   ins_cost(INSN_COST);
17836   effect(TEMP tmp);
17837   format %{ &quot;negr  $tmp,$shift\t&quot;
17838             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17839   ins_encode %{
17840     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17841             as_FloatRegister($shift$$reg));
17842     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17843             as_FloatRegister($src$$reg),
17844             as_FloatRegister($tmp$$reg));
17845   %}
17846   ins_pipe(vshift128);
17847 %}
17848 
17849 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17850   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17851   match(Set dst (LShiftVL src shift));
17852   ins_cost(INSN_COST);
17853   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17854   ins_encode %{
17855     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17856            as_FloatRegister($src$$reg),
17857            (int)$shift$$constant);
17858   %}
17859   ins_pipe(vshift128_imm);
17860 %}
17861 
17862 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17863   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17864   match(Set dst (RShiftVL src shift));
17865   ins_cost(INSN_COST);
17866   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17867   ins_encode %{
17868     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17869             as_FloatRegister($src$$reg),
17870             (int)$shift$$constant);
17871   %}
17872   ins_pipe(vshift128_imm);
17873 %}
17874 
17875 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17876   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17877   match(Set dst (URShiftVL src shift));
17878   ins_cost(INSN_COST);
17879   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
17880   ins_encode %{
17881     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
17882             as_FloatRegister($src$$reg),
17883             (int)$shift$$constant);
17884   %}
17885   ins_pipe(vshift128_imm);
17886 %}
17887 
17888 instruct vmax2F(vecD dst, vecD src1, vecD src2)
17889 %{
17890   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17891   match(Set dst (MaxV src1 src2));
17892   ins_cost(INSN_COST);
17893   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
17894   ins_encode %{
17895     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
17896             as_FloatRegister($src1$$reg),
17897             as_FloatRegister($src2$$reg));
17898   %}
17899   ins_pipe(vdop_fp64);
17900 %}
17901 
17902 instruct vmax4F(vecX dst, vecX src1, vecX src2)
17903 %{
17904   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17905   match(Set dst (MaxV src1 src2));
17906   ins_cost(INSN_COST);
17907   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
17908   ins_encode %{
17909     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
17910             as_FloatRegister($src1$$reg),
17911             as_FloatRegister($src2$$reg));
17912   %}
17913   ins_pipe(vdop_fp128);
17914 %}
17915 
17916 instruct vmax2D(vecX dst, vecX src1, vecX src2)
17917 %{
17918   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17919   match(Set dst (MaxV src1 src2));
17920   ins_cost(INSN_COST);
17921   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
17922   ins_encode %{
17923     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
17924             as_FloatRegister($src1$$reg),
17925             as_FloatRegister($src2$$reg));
17926   %}
17927   ins_pipe(vdop_fp128);
17928 %}
17929 
17930 instruct vmin2F(vecD dst, vecD src1, vecD src2)
17931 %{
17932   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17933   match(Set dst (MinV src1 src2));
17934   ins_cost(INSN_COST);
17935   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
17936   ins_encode %{
17937     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
17938             as_FloatRegister($src1$$reg),
17939             as_FloatRegister($src2$$reg));
17940   %}
17941   ins_pipe(vdop_fp64);
17942 %}
17943 
17944 instruct vmin4F(vecX dst, vecX src1, vecX src2)
17945 %{
17946   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17947   match(Set dst (MinV src1 src2));
17948   ins_cost(INSN_COST);
17949   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
17950   ins_encode %{
17951     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
17952             as_FloatRegister($src1$$reg),
17953             as_FloatRegister($src2$$reg));
17954   %}
17955   ins_pipe(vdop_fp128);
17956 %}
17957 
17958 instruct vmin2D(vecX dst, vecX src1, vecX src2)
17959 %{
17960   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17961   match(Set dst (MinV src1 src2));
17962   ins_cost(INSN_COST);
17963   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
17964   ins_encode %{
17965     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
17966             as_FloatRegister($src1$$reg),
17967             as_FloatRegister($src2$$reg));
17968   %}
17969   ins_pipe(vdop_fp128);
17970 %}
17971 
17972 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
17973   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17974   match(Set dst (RoundDoubleModeV src rmode));
17975   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
17976   ins_encode %{
17977     switch ($rmode$$constant) {
17978       case RoundDoubleModeNode::rmode_rint:
17979         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
17980                   as_FloatRegister($src$$reg));
17981         break;
17982       case RoundDoubleModeNode::rmode_floor:
17983         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
17984                   as_FloatRegister($src$$reg));
17985         break;
17986       case RoundDoubleModeNode::rmode_ceil:
17987         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
17988                   as_FloatRegister($src$$reg));
17989         break;
17990     }
17991   %}
17992   ins_pipe(vdop_fp128);
17993 %}
17994 
17995 //----------PEEPHOLE RULES-----------------------------------------------------
17996 // These must follow all instruction definitions as they use the names
17997 // defined in the instructions definitions.
17998 //
17999 // peepmatch ( root_instr_name [preceding_instruction]* );
18000 //
18001 // peepconstraint %{
18002 // (instruction_number.operand_name relational_op instruction_number.operand_name
18003 //  [, ...] );
18004 // // instruction numbers are zero-based using left to right order in peepmatch
18005 //
18006 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18007 // // provide an instruction_number.operand_name for each operand that appears
18008 // // in the replacement instruction&#39;s match rule
18009 //
18010 // ---------VM FLAGS---------------------------------------------------------
18011 //
18012 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18013 //
18014 // Each peephole rule is given an identifying number starting with zero and
18015 // increasing by one in the order seen by the parser.  An individual peephole
18016 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18017 // on the command-line.
18018 //
18019 // ---------CURRENT LIMITATIONS----------------------------------------------
18020 //
18021 // Only match adjacent instructions in same basic block
18022 // Only equality constraints
18023 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18024 // Only one replacement instruction
18025 //
18026 // ---------EXAMPLE----------------------------------------------------------
18027 //
18028 // // pertinent parts of existing instructions in architecture description
18029 // instruct movI(iRegINoSp dst, iRegI src)
18030 // %{
18031 //   match(Set dst (CopyI src));
18032 // %}
18033 //
18034 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18035 // %{
18036 //   match(Set dst (AddI dst src));
18037 //   effect(KILL cr);
18038 // %}
18039 //
18040 // // Change (inc mov) to lea
18041 // peephole %{
18042 //   // increment preceeded by register-register move
18043 //   peepmatch ( incI_iReg movI );
18044 //   // require that the destination register of the increment
18045 //   // match the destination register of the move
18046 //   peepconstraint ( 0.dst == 1.dst );
18047 //   // construct a replacement instruction that sets
18048 //   // the destination to ( move&#39;s source register + one )
18049 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18050 // %}
18051 //
18052 
18053 // Implementation no longer uses movX instructions since
18054 // machine-independent system no longer uses CopyX nodes.
18055 //
18056 // peephole
18057 // %{
18058 //   peepmatch (incI_iReg movI);
18059 //   peepconstraint (0.dst == 1.dst);
18060 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18061 // %}
18062 
18063 // peephole
18064 // %{
18065 //   peepmatch (decI_iReg movI);
18066 //   peepconstraint (0.dst == 1.dst);
18067 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18068 // %}
18069 
18070 // peephole
18071 // %{
18072 //   peepmatch (addI_iReg_imm movI);
18073 //   peepconstraint (0.dst == 1.dst);
18074 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18075 // %}
18076 
18077 // peephole
18078 // %{
18079 //   peepmatch (incL_iReg movL);
18080 //   peepconstraint (0.dst == 1.dst);
18081 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18082 // %}
18083 
18084 // peephole
18085 // %{
18086 //   peepmatch (decL_iReg movL);
18087 //   peepconstraint (0.dst == 1.dst);
18088 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18089 // %}
18090 
18091 // peephole
18092 // %{
18093 //   peepmatch (addL_iReg_imm movL);
18094 //   peepconstraint (0.dst == 1.dst);
18095 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18096 // %}
18097 
18098 // peephole
18099 // %{
18100 //   peepmatch (addP_iReg_imm movP);
18101 //   peepconstraint (0.dst == 1.dst);
18102 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18103 // %}
18104 
18105 // // Change load of spilled value to only a spill
18106 // instruct storeI(memory mem, iRegI src)
18107 // %{
18108 //   match(Set mem (StoreI mem src));
18109 // %}
18110 //
18111 // instruct loadI(iRegINoSp dst, memory mem)
18112 // %{
18113 //   match(Set dst (LoadI mem));
18114 // %}
18115 //
18116 
18117 //----------SMARTSPILL RULES---------------------------------------------------
18118 // These must follow all instruction definitions as they use the names
18119 // defined in the instructions definitions.
18120 
18121 // Local Variables:
18122 // mode: c++
18123 // End:
<a name="58" id="anc58"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="58" type="hidden" />
</body>
</html>